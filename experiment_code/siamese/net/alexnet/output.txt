I0317 09:28:35.664536  3513 caffe.cpp:185] Using GPUs 0
I0317 09:28:35.673429  3513 caffe.cpp:190] GPU 0: GRID K520
I0317 09:28:35.812325  3513 solver.cpp:48] Initializing solver from parameters: 
test_iter: 250
test_interval: 250
base_lr: 0.01
display: 20
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 5000
snapshot_prefix: "./caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "./siamese_alexnet_train.prototxt"
I0317 09:28:35.812517  3513 solver.cpp:91] Creating training net from net file: ./siamese_alexnet_train.prototxt
I0317 09:28:35.814039  3513 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer pair_data
I0317 09:28:35.814103  3513 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer siamese_accuracy
I0317 09:28:35.814538  3513 net.cpp:49] Initializing net from parameters: 
name: "SiameseAlexNet"
state {
  phase: TRAIN
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/ubuntu/fyp/data/data-fyp/siamese_train_leveldb"
    batch_size: 64
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 3
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "conv1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "norm1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "conv2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "norm2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv3_p"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "conv5_p"
  type: "Convolution"
  bottom: "conv4_p"
  top: "conv5_p"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_p"
  type: "ReLU"
  bottom: "conv5_p"
  top: "conv5_p"
}
layer {
  name: "pool5_p"
  type: "Pooling"
  bottom: "conv5_p"
  top: "pool5_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_p"
  type: "InnerProduct"
  bottom: "pool5_p"
  top: "fc6_p"
  param {
    name: "fc6_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_p"
  type: "ReLU"
  bottom: "fc6_p"
  top: "fc6_p"
}
layer {
  name: "drop6_p"
  type: "Dropout"
  bottom: "fc6_p"
  top: "fc6_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_p"
  type: "InnerProduct"
  bottom: "fc6_p"
  top: "fc7_p"
  param {
    name: "fc7_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_p"
  type: "InnerProduct"
  bottom: "fc7_p"
  top: "fc8_p"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "fc8"
  bottom: "fc8_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0317 09:28:35.814796  3513 layer_factory.hpp:77] Creating layer pair_data
I0317 09:28:35.815731  3513 net.cpp:91] Creating Layer pair_data
I0317 09:28:35.815752  3513 net.cpp:399] pair_data -> pair_data
I0317 09:28:35.815790  3513 net.cpp:399] pair_data -> sim
I0317 09:28:35.823587  3517 db_leveldb.cpp:18] Opened leveldb /home/ubuntu/fyp/data/data-fyp/siamese_train_leveldb
I0317 09:28:35.836833  3513 data_layer.cpp:41] output data size: 64,6,227,227
I0317 09:28:35.982453  3513 net.cpp:141] Setting up pair_data
I0317 09:28:35.982552  3513 net.cpp:148] Top shape: 64 6 227 227 (19787136)
I0317 09:28:35.982564  3513 net.cpp:148] Top shape: 64 (64)
I0317 09:28:35.982570  3513 net.cpp:156] Memory required for data: 79148800
I0317 09:28:35.982594  3513 layer_factory.hpp:77] Creating layer slice_pair
I0317 09:28:35.982681  3513 net.cpp:91] Creating Layer slice_pair
I0317 09:28:35.982698  3513 net.cpp:425] slice_pair <- pair_data
I0317 09:28:35.982715  3513 net.cpp:399] slice_pair -> data
I0317 09:28:35.982733  3513 net.cpp:399] slice_pair -> data_p
I0317 09:28:35.982808  3513 net.cpp:141] Setting up slice_pair
I0317 09:28:35.982825  3513 net.cpp:148] Top shape: 64 3 227 227 (9893568)
I0317 09:28:35.982831  3513 net.cpp:148] Top shape: 64 3 227 227 (9893568)
I0317 09:28:35.982836  3513 net.cpp:156] Memory required for data: 158297344
I0317 09:28:35.982841  3513 layer_factory.hpp:77] Creating layer conv1
I0317 09:28:35.982870  3513 net.cpp:91] Creating Layer conv1
I0317 09:28:35.982877  3513 net.cpp:425] conv1 <- data
I0317 09:28:35.982916  3513 net.cpp:399] conv1 -> conv1
I0317 09:28:36.210146  3513 net.cpp:141] Setting up conv1
I0317 09:28:36.210196  3513 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0317 09:28:36.210203  3513 net.cpp:156] Memory required for data: 232639744
I0317 09:28:36.210232  3513 layer_factory.hpp:77] Creating layer relu1
I0317 09:28:36.210263  3513 net.cpp:91] Creating Layer relu1
I0317 09:28:36.210276  3513 net.cpp:425] relu1 <- conv1
I0317 09:28:36.210292  3513 net.cpp:386] relu1 -> conv1 (in-place)
I0317 09:28:36.210489  3513 net.cpp:141] Setting up relu1
I0317 09:28:36.210513  3513 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0317 09:28:36.210525  3513 net.cpp:156] Memory required for data: 306982144
I0317 09:28:36.210536  3513 layer_factory.hpp:77] Creating layer norm1
I0317 09:28:36.210566  3513 net.cpp:91] Creating Layer norm1
I0317 09:28:36.210587  3513 net.cpp:425] norm1 <- conv1
I0317 09:28:36.210615  3513 net.cpp:399] norm1 -> norm1
I0317 09:28:36.210916  3513 net.cpp:141] Setting up norm1
I0317 09:28:36.210942  3513 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0317 09:28:36.210952  3513 net.cpp:156] Memory required for data: 381324544
I0317 09:28:36.210963  3513 layer_factory.hpp:77] Creating layer pool1
I0317 09:28:36.210981  3513 net.cpp:91] Creating Layer pool1
I0317 09:28:36.210993  3513 net.cpp:425] pool1 <- norm1
I0317 09:28:36.211006  3513 net.cpp:399] pool1 -> pool1
I0317 09:28:36.211082  3513 net.cpp:141] Setting up pool1
I0317 09:28:36.211107  3513 net.cpp:148] Top shape: 64 96 27 27 (4478976)
I0317 09:28:36.211117  3513 net.cpp:156] Memory required for data: 399240448
I0317 09:28:36.211128  3513 layer_factory.hpp:77] Creating layer conv2
I0317 09:28:36.211155  3513 net.cpp:91] Creating Layer conv2
I0317 09:28:36.211175  3513 net.cpp:425] conv2 <- pool1
I0317 09:28:36.211194  3513 net.cpp:399] conv2 -> conv2
I0317 09:28:36.223637  3513 net.cpp:141] Setting up conv2
I0317 09:28:36.223687  3513 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0317 09:28:36.223698  3513 net.cpp:156] Memory required for data: 447016192
I0317 09:28:36.223726  3513 layer_factory.hpp:77] Creating layer relu2
I0317 09:28:36.223748  3513 net.cpp:91] Creating Layer relu2
I0317 09:28:36.223759  3513 net.cpp:425] relu2 <- conv2
I0317 09:28:36.223783  3513 net.cpp:386] relu2 -> conv2 (in-place)
I0317 09:28:36.224067  3513 net.cpp:141] Setting up relu2
I0317 09:28:36.224093  3513 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0317 09:28:36.224104  3513 net.cpp:156] Memory required for data: 494791936
I0317 09:28:36.224115  3513 layer_factory.hpp:77] Creating layer norm2
I0317 09:28:36.224143  3513 net.cpp:91] Creating Layer norm2
I0317 09:28:36.224154  3513 net.cpp:425] norm2 <- conv2
I0317 09:28:36.224169  3513 net.cpp:399] norm2 -> norm2
I0317 09:28:36.224468  3513 net.cpp:141] Setting up norm2
I0317 09:28:36.224496  3513 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0317 09:28:36.224506  3513 net.cpp:156] Memory required for data: 542567680
I0317 09:28:36.224516  3513 layer_factory.hpp:77] Creating layer pool2
I0317 09:28:36.224534  3513 net.cpp:91] Creating Layer pool2
I0317 09:28:36.224545  3513 net.cpp:425] pool2 <- norm2
I0317 09:28:36.224565  3513 net.cpp:399] pool2 -> pool2
I0317 09:28:36.224635  3513 net.cpp:141] Setting up pool2
I0317 09:28:36.224659  3513 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0317 09:28:36.224669  3513 net.cpp:156] Memory required for data: 553643264
I0317 09:28:36.224680  3513 layer_factory.hpp:77] Creating layer conv3
I0317 09:28:36.224709  3513 net.cpp:91] Creating Layer conv3
I0317 09:28:36.224723  3513 net.cpp:425] conv3 <- pool2
I0317 09:28:36.224746  3513 net.cpp:399] conv3 -> conv3
I0317 09:28:36.255393  3513 net.cpp:141] Setting up conv3
I0317 09:28:36.255445  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:36.255456  3513 net.cpp:156] Memory required for data: 570256640
I0317 09:28:36.255486  3513 layer_factory.hpp:77] Creating layer relu3
I0317 09:28:36.255507  3513 net.cpp:91] Creating Layer relu3
I0317 09:28:36.255519  3513 net.cpp:425] relu3 <- conv3
I0317 09:28:36.255580  3513 net.cpp:386] relu3 -> conv3 (in-place)
I0317 09:28:36.255852  3513 net.cpp:141] Setting up relu3
I0317 09:28:36.255877  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:36.255888  3513 net.cpp:156] Memory required for data: 586870016
I0317 09:28:36.255899  3513 layer_factory.hpp:77] Creating layer conv4
I0317 09:28:36.255931  3513 net.cpp:91] Creating Layer conv4
I0317 09:28:36.255946  3513 net.cpp:425] conv4 <- conv3
I0317 09:28:36.255964  3513 net.cpp:399] conv4 -> conv4
I0317 09:28:36.279741  3513 net.cpp:141] Setting up conv4
I0317 09:28:36.279788  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:36.279798  3513 net.cpp:156] Memory required for data: 603483392
I0317 09:28:36.279819  3513 layer_factory.hpp:77] Creating layer relu4
I0317 09:28:36.279842  3513 net.cpp:91] Creating Layer relu4
I0317 09:28:36.279855  3513 net.cpp:425] relu4 <- conv4
I0317 09:28:36.279872  3513 net.cpp:386] relu4 -> conv4 (in-place)
I0317 09:28:36.280139  3513 net.cpp:141] Setting up relu4
I0317 09:28:36.280166  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:36.280177  3513 net.cpp:156] Memory required for data: 620096768
I0317 09:28:36.280189  3513 layer_factory.hpp:77] Creating layer conv5
I0317 09:28:36.280218  3513 net.cpp:91] Creating Layer conv5
I0317 09:28:36.280238  3513 net.cpp:425] conv5 <- conv4
I0317 09:28:36.280261  3513 net.cpp:399] conv5 -> conv5
I0317 09:28:36.299238  3513 net.cpp:141] Setting up conv5
I0317 09:28:36.299266  3513 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0317 09:28:36.299278  3513 net.cpp:156] Memory required for data: 631172352
I0317 09:28:36.299306  3513 layer_factory.hpp:77] Creating layer relu5
I0317 09:28:36.299324  3513 net.cpp:91] Creating Layer relu5
I0317 09:28:36.299335  3513 net.cpp:425] relu5 <- conv5
I0317 09:28:36.299351  3513 net.cpp:386] relu5 -> conv5 (in-place)
I0317 09:28:36.299528  3513 net.cpp:141] Setting up relu5
I0317 09:28:36.299553  3513 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0317 09:28:36.299563  3513 net.cpp:156] Memory required for data: 642247936
I0317 09:28:36.299574  3513 layer_factory.hpp:77] Creating layer pool5
I0317 09:28:36.299600  3513 net.cpp:91] Creating Layer pool5
I0317 09:28:36.299612  3513 net.cpp:425] pool5 <- conv5
I0317 09:28:36.299630  3513 net.cpp:399] pool5 -> pool5
I0317 09:28:36.299707  3513 net.cpp:141] Setting up pool5
I0317 09:28:36.299731  3513 net.cpp:148] Top shape: 64 256 6 6 (589824)
I0317 09:28:36.299741  3513 net.cpp:156] Memory required for data: 644607232
I0317 09:28:36.299751  3513 layer_factory.hpp:77] Creating layer fc6
I0317 09:28:36.299779  3513 net.cpp:91] Creating Layer fc6
I0317 09:28:36.299801  3513 net.cpp:425] fc6 <- pool5
I0317 09:28:36.299824  3513 net.cpp:399] fc6 -> fc6
I0317 09:28:37.563246  3513 net.cpp:141] Setting up fc6
I0317 09:28:37.563308  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:37.563320  3513 net.cpp:156] Memory required for data: 645655808
I0317 09:28:37.563344  3513 layer_factory.hpp:77] Creating layer relu6
I0317 09:28:37.563371  3513 net.cpp:91] Creating Layer relu6
I0317 09:28:37.563385  3513 net.cpp:425] relu6 <- fc6
I0317 09:28:37.563403  3513 net.cpp:386] relu6 -> fc6 (in-place)
I0317 09:28:37.563870  3513 net.cpp:141] Setting up relu6
I0317 09:28:37.563897  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:37.563907  3513 net.cpp:156] Memory required for data: 646704384
I0317 09:28:37.563918  3513 layer_factory.hpp:77] Creating layer drop6
I0317 09:28:37.563943  3513 net.cpp:91] Creating Layer drop6
I0317 09:28:37.563956  3513 net.cpp:425] drop6 <- fc6
I0317 09:28:37.563979  3513 net.cpp:386] drop6 -> fc6 (in-place)
I0317 09:28:37.564072  3513 net.cpp:141] Setting up drop6
I0317 09:28:37.564095  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:37.564119  3513 net.cpp:156] Memory required for data: 647752960
I0317 09:28:37.564131  3513 layer_factory.hpp:77] Creating layer fc7
I0317 09:28:37.564152  3513 net.cpp:91] Creating Layer fc7
I0317 09:28:37.564163  3513 net.cpp:425] fc7 <- fc6
I0317 09:28:37.564220  3513 net.cpp:399] fc7 -> fc7
I0317 09:28:38.127204  3513 net.cpp:141] Setting up fc7
I0317 09:28:38.127279  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:38.127290  3513 net.cpp:156] Memory required for data: 648801536
I0317 09:28:38.127311  3513 layer_factory.hpp:77] Creating layer fc8
I0317 09:28:38.127352  3513 net.cpp:91] Creating Layer fc8
I0317 09:28:38.127367  3513 net.cpp:425] fc8 <- fc7
I0317 09:28:38.127389  3513 net.cpp:399] fc8 -> fc8
I0317 09:28:38.263988  3513 net.cpp:141] Setting up fc8
I0317 09:28:38.264037  3513 net.cpp:148] Top shape: 64 1000 (64000)
I0317 09:28:38.264050  3513 net.cpp:156] Memory required for data: 649057536
I0317 09:28:38.264068  3513 layer_factory.hpp:77] Creating layer conv1_p
I0317 09:28:38.264106  3513 net.cpp:91] Creating Layer conv1_p
I0317 09:28:38.264118  3513 net.cpp:425] conv1_p <- data_p
I0317 09:28:38.264139  3513 net.cpp:399] conv1_p -> conv1_p
I0317 09:28:38.266425  3513 net.cpp:141] Setting up conv1_p
I0317 09:28:38.266453  3513 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0317 09:28:38.266463  3513 net.cpp:156] Memory required for data: 723399936
I0317 09:28:38.266482  3513 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0317 09:28:38.266499  3513 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0317 09:28:38.266510  3513 layer_factory.hpp:77] Creating layer relu1_p
I0317 09:28:38.266530  3513 net.cpp:91] Creating Layer relu1_p
I0317 09:28:38.266541  3513 net.cpp:425] relu1_p <- conv1_p
I0317 09:28:38.266562  3513 net.cpp:386] relu1_p -> conv1_p (in-place)
I0317 09:28:38.266851  3513 net.cpp:141] Setting up relu1_p
I0317 09:28:38.266877  3513 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0317 09:28:38.266888  3513 net.cpp:156] Memory required for data: 797742336
I0317 09:28:38.266899  3513 layer_factory.hpp:77] Creating layer norm1_p
I0317 09:28:38.266921  3513 net.cpp:91] Creating Layer norm1_p
I0317 09:28:38.266933  3513 net.cpp:425] norm1_p <- conv1_p
I0317 09:28:38.266957  3513 net.cpp:399] norm1_p -> norm1_p
I0317 09:28:38.267271  3513 net.cpp:141] Setting up norm1_p
I0317 09:28:38.267297  3513 net.cpp:148] Top shape: 64 96 55 55 (18585600)
I0317 09:28:38.267307  3513 net.cpp:156] Memory required for data: 872084736
I0317 09:28:38.267318  3513 layer_factory.hpp:77] Creating layer pool1_p
I0317 09:28:38.267340  3513 net.cpp:91] Creating Layer pool1_p
I0317 09:28:38.267357  3513 net.cpp:425] pool1_p <- norm1_p
I0317 09:28:38.267374  3513 net.cpp:399] pool1_p -> pool1_p
I0317 09:28:38.267452  3513 net.cpp:141] Setting up pool1_p
I0317 09:28:38.267474  3513 net.cpp:148] Top shape: 64 96 27 27 (4478976)
I0317 09:28:38.267484  3513 net.cpp:156] Memory required for data: 890000640
I0317 09:28:38.267495  3513 layer_factory.hpp:77] Creating layer conv2_p
I0317 09:28:38.267521  3513 net.cpp:91] Creating Layer conv2_p
I0317 09:28:38.267542  3513 net.cpp:425] conv2_p <- pool1_p
I0317 09:28:38.267565  3513 net.cpp:399] conv2_p -> conv2_p
I0317 09:28:38.279418  3513 net.cpp:141] Setting up conv2_p
I0317 09:28:38.279445  3513 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0317 09:28:38.279456  3513 net.cpp:156] Memory required for data: 937776384
I0317 09:28:38.279469  3513 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0317 09:28:38.279484  3513 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0317 09:28:38.279495  3513 layer_factory.hpp:77] Creating layer relu2_p
I0317 09:28:38.279510  3513 net.cpp:91] Creating Layer relu2_p
I0317 09:28:38.279520  3513 net.cpp:425] relu2_p <- conv2_p
I0317 09:28:38.279534  3513 net.cpp:386] relu2_p -> conv2_p (in-place)
I0317 09:28:38.279814  3513 net.cpp:141] Setting up relu2_p
I0317 09:28:38.279840  3513 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0317 09:28:38.279850  3513 net.cpp:156] Memory required for data: 985552128
I0317 09:28:38.279861  3513 layer_factory.hpp:77] Creating layer norm2_p
I0317 09:28:38.279882  3513 net.cpp:91] Creating Layer norm2_p
I0317 09:28:38.279928  3513 net.cpp:425] norm2_p <- conv2_p
I0317 09:28:38.279945  3513 net.cpp:399] norm2_p -> norm2_p
I0317 09:28:38.280163  3513 net.cpp:141] Setting up norm2_p
I0317 09:28:38.280187  3513 net.cpp:148] Top shape: 64 256 27 27 (11943936)
I0317 09:28:38.280197  3513 net.cpp:156] Memory required for data: 1033327872
I0317 09:28:38.280208  3513 layer_factory.hpp:77] Creating layer pool2_p
I0317 09:28:38.280223  3513 net.cpp:91] Creating Layer pool2_p
I0317 09:28:38.280234  3513 net.cpp:425] pool2_p <- norm2_p
I0317 09:28:38.280253  3513 net.cpp:399] pool2_p -> pool2_p
I0317 09:28:38.280323  3513 net.cpp:141] Setting up pool2_p
I0317 09:28:38.280349  3513 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0317 09:28:38.280359  3513 net.cpp:156] Memory required for data: 1044403456
I0317 09:28:38.280369  3513 layer_factory.hpp:77] Creating layer conv3_p
I0317 09:28:38.280395  3513 net.cpp:91] Creating Layer conv3_p
I0317 09:28:38.280407  3513 net.cpp:425] conv3_p <- pool2_p
I0317 09:28:38.280426  3513 net.cpp:399] conv3_p -> conv3_p
I0317 09:28:38.310978  3513 net.cpp:141] Setting up conv3_p
I0317 09:28:38.311007  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:38.311018  3513 net.cpp:156] Memory required for data: 1061016832
I0317 09:28:38.311031  3513 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'conv3', param index 0
I0317 09:28:38.311045  3513 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'conv3', param index 1
I0317 09:28:38.311056  3513 layer_factory.hpp:77] Creating layer relu3_p
I0317 09:28:38.311075  3513 net.cpp:91] Creating Layer relu3_p
I0317 09:28:38.311086  3513 net.cpp:425] relu3_p <- conv3_p
I0317 09:28:38.311100  3513 net.cpp:386] relu3_p -> conv3_p (in-place)
I0317 09:28:38.311377  3513 net.cpp:141] Setting up relu3_p
I0317 09:28:38.311403  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:38.311413  3513 net.cpp:156] Memory required for data: 1077630208
I0317 09:28:38.311422  3513 layer_factory.hpp:77] Creating layer conv4_p
I0317 09:28:38.311460  3513 net.cpp:91] Creating Layer conv4_p
I0317 09:28:38.311480  3513 net.cpp:425] conv4_p <- conv3_p
I0317 09:28:38.311501  3513 net.cpp:399] conv4_p -> conv4_p
I0317 09:28:38.335278  3513 net.cpp:141] Setting up conv4_p
I0317 09:28:38.335307  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:38.335321  3513 net.cpp:156] Memory required for data: 1094243584
I0317 09:28:38.335335  3513 net.cpp:484] Sharing parameters 'conv4_w' owned by layer 'conv4', param index 0
I0317 09:28:38.335348  3513 net.cpp:484] Sharing parameters 'conv4_b' owned by layer 'conv4', param index 1
I0317 09:28:38.335360  3513 layer_factory.hpp:77] Creating layer relu4_p
I0317 09:28:38.335373  3513 net.cpp:91] Creating Layer relu4_p
I0317 09:28:38.335383  3513 net.cpp:425] relu4_p <- conv4_p
I0317 09:28:38.335397  3513 net.cpp:386] relu4_p -> conv4_p (in-place)
I0317 09:28:38.335676  3513 net.cpp:141] Setting up relu4_p
I0317 09:28:38.335701  3513 net.cpp:148] Top shape: 64 384 13 13 (4153344)
I0317 09:28:38.335712  3513 net.cpp:156] Memory required for data: 1110856960
I0317 09:28:38.335722  3513 layer_factory.hpp:77] Creating layer conv5_p
I0317 09:28:38.335749  3513 net.cpp:91] Creating Layer conv5_p
I0317 09:28:38.335762  3513 net.cpp:425] conv5_p <- conv4_p
I0317 09:28:38.335783  3513 net.cpp:399] conv5_p -> conv5_p
I0317 09:28:38.352165  3513 net.cpp:141] Setting up conv5_p
I0317 09:28:38.352193  3513 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0317 09:28:38.352205  3513 net.cpp:156] Memory required for data: 1121932544
I0317 09:28:38.352216  3513 net.cpp:484] Sharing parameters 'conv5_w' owned by layer 'conv5', param index 0
I0317 09:28:38.352231  3513 net.cpp:484] Sharing parameters 'conv5_b' owned by layer 'conv5', param index 1
I0317 09:28:38.352242  3513 layer_factory.hpp:77] Creating layer relu5_p
I0317 09:28:38.352259  3513 net.cpp:91] Creating Layer relu5_p
I0317 09:28:38.352270  3513 net.cpp:425] relu5_p <- conv5_p
I0317 09:28:38.352284  3513 net.cpp:386] relu5_p -> conv5_p (in-place)
I0317 09:28:38.352568  3513 net.cpp:141] Setting up relu5_p
I0317 09:28:38.352607  3513 net.cpp:148] Top shape: 64 256 13 13 (2768896)
I0317 09:28:38.352617  3513 net.cpp:156] Memory required for data: 1133008128
I0317 09:28:38.352628  3513 layer_factory.hpp:77] Creating layer pool5_p
I0317 09:28:38.352644  3513 net.cpp:91] Creating Layer pool5_p
I0317 09:28:38.352655  3513 net.cpp:425] pool5_p <- conv5_p
I0317 09:28:38.352674  3513 net.cpp:399] pool5_p -> pool5_p
I0317 09:28:38.352753  3513 net.cpp:141] Setting up pool5_p
I0317 09:28:38.352777  3513 net.cpp:148] Top shape: 64 256 6 6 (589824)
I0317 09:28:38.352787  3513 net.cpp:156] Memory required for data: 1135367424
I0317 09:28:38.352797  3513 layer_factory.hpp:77] Creating layer fc6_p
I0317 09:28:38.352821  3513 net.cpp:91] Creating Layer fc6_p
I0317 09:28:38.352838  3513 net.cpp:425] fc6_p <- pool5_p
I0317 09:28:38.352859  3513 net.cpp:399] fc6_p -> fc6_p
I0317 09:28:39.619467  3513 net.cpp:141] Setting up fc6_p
I0317 09:28:39.619523  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:39.619535  3513 net.cpp:156] Memory required for data: 1136416000
I0317 09:28:39.619550  3513 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0317 09:28:39.619565  3513 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0317 09:28:39.619575  3513 layer_factory.hpp:77] Creating layer relu6_p
I0317 09:28:39.619601  3513 net.cpp:91] Creating Layer relu6_p
I0317 09:28:39.619614  3513 net.cpp:425] relu6_p <- fc6_p
I0317 09:28:39.619632  3513 net.cpp:386] relu6_p -> fc6_p (in-place)
I0317 09:28:39.619894  3513 net.cpp:141] Setting up relu6_p
I0317 09:28:39.619918  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:39.619930  3513 net.cpp:156] Memory required for data: 1137464576
I0317 09:28:39.619945  3513 layer_factory.hpp:77] Creating layer drop6_p
I0317 09:28:39.619961  3513 net.cpp:91] Creating Layer drop6_p
I0317 09:28:39.619971  3513 net.cpp:425] drop6_p <- fc6_p
I0317 09:28:39.619995  3513 net.cpp:386] drop6_p -> fc6_p (in-place)
I0317 09:28:39.620074  3513 net.cpp:141] Setting up drop6_p
I0317 09:28:39.620095  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:39.620106  3513 net.cpp:156] Memory required for data: 1138513152
I0317 09:28:39.620117  3513 layer_factory.hpp:77] Creating layer fc7_p
I0317 09:28:39.620136  3513 net.cpp:91] Creating Layer fc7_p
I0317 09:28:39.620148  3513 net.cpp:425] fc7_p <- fc6_p
I0317 09:28:39.620168  3513 net.cpp:399] fc7_p -> fc7_p
I0317 09:28:40.187782  3513 net.cpp:141] Setting up fc7_p
I0317 09:28:40.187841  3513 net.cpp:148] Top shape: 64 4096 (262144)
I0317 09:28:40.187855  3513 net.cpp:156] Memory required for data: 1139561728
I0317 09:28:40.187871  3513 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0317 09:28:40.187885  3513 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0317 09:28:40.187896  3513 layer_factory.hpp:77] Creating layer fc8_p
I0317 09:28:40.187922  3513 net.cpp:91] Creating Layer fc8_p
I0317 09:28:40.187942  3513 net.cpp:425] fc8_p <- fc7_p
I0317 09:28:40.187963  3513 net.cpp:399] fc8_p -> fc8_p
I0317 09:28:40.325004  3513 net.cpp:141] Setting up fc8_p
I0317 09:28:40.325057  3513 net.cpp:148] Top shape: 64 1000 (64000)
I0317 09:28:40.325067  3513 net.cpp:156] Memory required for data: 1139817728
I0317 09:28:40.325083  3513 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'fc8', param index 0
I0317 09:28:40.325105  3513 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'fc8', param index 1
I0317 09:28:40.325116  3513 layer_factory.hpp:77] Creating layer loss
I0317 09:28:40.325143  3513 net.cpp:91] Creating Layer loss
I0317 09:28:40.325178  3513 net.cpp:425] loss <- fc8
I0317 09:28:40.325198  3513 net.cpp:425] loss <- fc8_p
I0317 09:28:40.325212  3513 net.cpp:425] loss <- sim
I0317 09:28:40.325250  3513 net.cpp:399] loss -> loss
I0317 09:28:40.325470  3513 net.cpp:141] Setting up loss
I0317 09:28:40.325501  3513 net.cpp:148] Top shape: (1)
I0317 09:28:40.325512  3513 net.cpp:151]     with loss weight 1
I0317 09:28:40.325588  3513 net.cpp:156] Memory required for data: 1139817732
I0317 09:28:40.325601  3513 net.cpp:217] loss needs backward computation.
I0317 09:28:40.325614  3513 net.cpp:217] fc8_p needs backward computation.
I0317 09:28:40.325625  3513 net.cpp:219] fc7_p does not need backward computation.
I0317 09:28:40.325635  3513 net.cpp:219] drop6_p does not need backward computation.
I0317 09:28:40.325651  3513 net.cpp:219] relu6_p does not need backward computation.
I0317 09:28:40.325660  3513 net.cpp:219] fc6_p does not need backward computation.
I0317 09:28:40.325670  3513 net.cpp:219] pool5_p does not need backward computation.
I0317 09:28:40.325681  3513 net.cpp:219] relu5_p does not need backward computation.
I0317 09:28:40.325691  3513 net.cpp:219] conv5_p does not need backward computation.
I0317 09:28:40.325709  3513 net.cpp:219] relu4_p does not need backward computation.
I0317 09:28:40.325719  3513 net.cpp:219] conv4_p does not need backward computation.
I0317 09:28:40.325731  3513 net.cpp:219] relu3_p does not need backward computation.
I0317 09:28:40.325739  3513 net.cpp:219] conv3_p does not need backward computation.
I0317 09:28:40.325750  3513 net.cpp:219] pool2_p does not need backward computation.
I0317 09:28:40.325762  3513 net.cpp:219] norm2_p does not need backward computation.
I0317 09:28:40.325773  3513 net.cpp:219] relu2_p does not need backward computation.
I0317 09:28:40.325781  3513 net.cpp:219] conv2_p does not need backward computation.
I0317 09:28:40.325793  3513 net.cpp:219] pool1_p does not need backward computation.
I0317 09:28:40.325803  3513 net.cpp:219] norm1_p does not need backward computation.
I0317 09:28:40.325826  3513 net.cpp:219] relu1_p does not need backward computation.
I0317 09:28:40.325837  3513 net.cpp:219] conv1_p does not need backward computation.
I0317 09:28:40.325848  3513 net.cpp:217] fc8 needs backward computation.
I0317 09:28:40.325860  3513 net.cpp:219] fc7 does not need backward computation.
I0317 09:28:40.325870  3513 net.cpp:219] drop6 does not need backward computation.
I0317 09:28:40.325886  3513 net.cpp:219] relu6 does not need backward computation.
I0317 09:28:40.325896  3513 net.cpp:219] fc6 does not need backward computation.
I0317 09:28:40.325906  3513 net.cpp:219] pool5 does not need backward computation.
I0317 09:28:40.325917  3513 net.cpp:219] relu5 does not need backward computation.
I0317 09:28:40.325927  3513 net.cpp:219] conv5 does not need backward computation.
I0317 09:28:40.325937  3513 net.cpp:219] relu4 does not need backward computation.
I0317 09:28:40.325947  3513 net.cpp:219] conv4 does not need backward computation.
I0317 09:28:40.325958  3513 net.cpp:219] relu3 does not need backward computation.
I0317 09:28:40.325966  3513 net.cpp:219] conv3 does not need backward computation.
I0317 09:28:40.325976  3513 net.cpp:219] pool2 does not need backward computation.
I0317 09:28:40.325987  3513 net.cpp:219] norm2 does not need backward computation.
I0317 09:28:40.326004  3513 net.cpp:219] relu2 does not need backward computation.
I0317 09:28:40.326015  3513 net.cpp:219] conv2 does not need backward computation.
I0317 09:28:40.326026  3513 net.cpp:219] pool1 does not need backward computation.
I0317 09:28:40.326037  3513 net.cpp:219] norm1 does not need backward computation.
I0317 09:28:40.326048  3513 net.cpp:219] relu1 does not need backward computation.
I0317 09:28:40.326066  3513 net.cpp:219] conv1 does not need backward computation.
I0317 09:28:40.326076  3513 net.cpp:219] slice_pair does not need backward computation.
I0317 09:28:40.326088  3513 net.cpp:219] pair_data does not need backward computation.
I0317 09:28:40.326102  3513 net.cpp:261] This network produces output loss
I0317 09:28:40.363585  3513 net.cpp:274] Network initialization done.
I0317 09:28:40.365180  3513 solver.cpp:181] Creating test net (#0) specified by net file: ./siamese_alexnet_train.prototxt
I0317 09:28:40.365308  3513 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer pair_data
I0317 09:28:40.365770  3513 net.cpp:49] Initializing net from parameters: 
name: "SiameseAlexNet"
state {
  phase: TEST
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/ubuntu/fyp/data/data-fyp/siamese_test_leveldb"
    batch_size: 100
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 3
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    name: "fc6_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    name: "fc7_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "conv1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "norm1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "conv2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "norm2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv3_p"
  param {
    name: "conv3_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    name: "conv4_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv4_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "conv5_p"
  type: "Convolution"
  bottom: "conv4_p"
  top: "conv5_p"
  param {
    name: "conv5_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "conv5_b"
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_p"
  type: "ReLU"
  bottom: "conv5_p"
  top: "conv5_p"
}
layer {
  name: "pool5_p"
  type: "Pooling"
  bottom: "conv5_p"
  top: "pool5_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_p"
  type: "InnerProduct"
  bottom: "pool5_p"
  top: "fc6_p"
  param {
    name: "fc6_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc6_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_p"
  type: "ReLU"
  bottom: "fc6_p"
  top: "fc6_p"
}
layer {
  name: "drop6_p"
  type: "Dropout"
  bottom: "fc6_p"
  top: "fc6_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_p"
  type: "InnerProduct"
  bottom: "fc6_p"
  top: "fc7_p"
  param {
    name: "fc7_w"
    lr_mult: 0
    decay_mult: 1
  }
  param {
    name: "fc7_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc8_p"
  type: "InnerProduct"
  bottom: "fc7_p"
  top: "fc8_p"
  param {
    name: "fc8_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc8_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "siamese_accuracy"
  type: "SiameseAccuracy"
  bottom: "fc8"
  bottom: "fc8_p"
  bottom: "sim"
  top: "siamese_accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "fc8"
  bottom: "fc8_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0317 09:28:40.366170  3513 layer_factory.hpp:77] Creating layer pair_data
I0317 09:28:40.366389  3513 net.cpp:91] Creating Layer pair_data
I0317 09:28:40.366407  3513 net.cpp:399] pair_data -> pair_data
I0317 09:28:40.366439  3513 net.cpp:399] pair_data -> sim
I0317 09:28:40.374105  3519 db_leveldb.cpp:18] Opened leveldb /home/ubuntu/fyp/data/data-fyp/siamese_test_leveldb
I0317 09:28:40.376232  3513 data_layer.cpp:41] output data size: 100,6,227,227
I0317 09:28:40.612112  3513 net.cpp:141] Setting up pair_data
I0317 09:28:40.612162  3513 net.cpp:148] Top shape: 100 6 227 227 (30917400)
I0317 09:28:40.612170  3513 net.cpp:148] Top shape: 100 (100)
I0317 09:28:40.612175  3513 net.cpp:156] Memory required for data: 123670000
I0317 09:28:40.612185  3513 layer_factory.hpp:77] Creating layer sim_pair_data_1_split
I0317 09:28:40.612211  3513 net.cpp:91] Creating Layer sim_pair_data_1_split
I0317 09:28:40.612231  3513 net.cpp:425] sim_pair_data_1_split <- sim
I0317 09:28:40.612246  3513 net.cpp:399] sim_pair_data_1_split -> sim_pair_data_1_split_0
I0317 09:28:40.612262  3513 net.cpp:399] sim_pair_data_1_split -> sim_pair_data_1_split_1
I0317 09:28:40.612351  3513 net.cpp:141] Setting up sim_pair_data_1_split
I0317 09:28:40.612370  3513 net.cpp:148] Top shape: 100 (100)
I0317 09:28:40.612380  3513 net.cpp:148] Top shape: 100 (100)
I0317 09:28:40.612385  3513 net.cpp:156] Memory required for data: 123670800
I0317 09:28:40.612390  3513 layer_factory.hpp:77] Creating layer slice_pair
I0317 09:28:40.612402  3513 net.cpp:91] Creating Layer slice_pair
I0317 09:28:40.612418  3513 net.cpp:425] slice_pair <- pair_data
I0317 09:28:40.612434  3513 net.cpp:399] slice_pair -> data
I0317 09:28:40.612448  3513 net.cpp:399] slice_pair -> data_p
I0317 09:28:40.612519  3513 net.cpp:141] Setting up slice_pair
I0317 09:28:40.612536  3513 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0317 09:28:40.612543  3513 net.cpp:148] Top shape: 100 3 227 227 (15458700)
I0317 09:28:40.612548  3513 net.cpp:156] Memory required for data: 247340400
I0317 09:28:40.612553  3513 layer_factory.hpp:77] Creating layer conv1
I0317 09:28:40.612573  3513 net.cpp:91] Creating Layer conv1
I0317 09:28:40.612586  3513 net.cpp:425] conv1 <- data
I0317 09:28:40.612624  3513 net.cpp:399] conv1 -> conv1
I0317 09:28:40.628304  3513 net.cpp:141] Setting up conv1
I0317 09:28:40.628347  3513 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0317 09:28:40.628353  3513 net.cpp:156] Memory required for data: 363500400
I0317 09:28:40.628373  3513 layer_factory.hpp:77] Creating layer relu1
I0317 09:28:40.628389  3513 net.cpp:91] Creating Layer relu1
I0317 09:28:40.628396  3513 net.cpp:425] relu1 <- conv1
I0317 09:28:40.628407  3513 net.cpp:386] relu1 -> conv1 (in-place)
I0317 09:28:40.628675  3513 net.cpp:141] Setting up relu1
I0317 09:28:40.628697  3513 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0317 09:28:40.628703  3513 net.cpp:156] Memory required for data: 479660400
I0317 09:28:40.628710  3513 layer_factory.hpp:77] Creating layer norm1
I0317 09:28:40.628723  3513 net.cpp:91] Creating Layer norm1
I0317 09:28:40.628729  3513 net.cpp:425] norm1 <- conv1
I0317 09:28:40.628739  3513 net.cpp:399] norm1 -> norm1
I0317 09:28:40.628949  3513 net.cpp:141] Setting up norm1
I0317 09:28:40.628968  3513 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0317 09:28:40.628973  3513 net.cpp:156] Memory required for data: 595820400
I0317 09:28:40.628978  3513 layer_factory.hpp:77] Creating layer pool1
I0317 09:28:40.628993  3513 net.cpp:91] Creating Layer pool1
I0317 09:28:40.629003  3513 net.cpp:425] pool1 <- norm1
I0317 09:28:40.629010  3513 net.cpp:399] pool1 -> pool1
I0317 09:28:40.629075  3513 net.cpp:141] Setting up pool1
I0317 09:28:40.629187  3513 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0317 09:28:40.629201  3513 net.cpp:156] Memory required for data: 623814000
I0317 09:28:40.629207  3513 layer_factory.hpp:77] Creating layer conv2
I0317 09:28:40.629226  3513 net.cpp:91] Creating Layer conv2
I0317 09:28:40.629235  3513 net.cpp:425] conv2 <- pool1
I0317 09:28:40.629247  3513 net.cpp:399] conv2 -> conv2
I0317 09:28:40.641801  3513 net.cpp:141] Setting up conv2
I0317 09:28:40.641855  3513 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0317 09:28:40.641861  3513 net.cpp:156] Memory required for data: 698463600
I0317 09:28:40.641882  3513 layer_factory.hpp:77] Creating layer relu2
I0317 09:28:40.641902  3513 net.cpp:91] Creating Layer relu2
I0317 09:28:40.641911  3513 net.cpp:425] relu2 <- conv2
I0317 09:28:40.641922  3513 net.cpp:386] relu2 -> conv2 (in-place)
I0317 09:28:40.642096  3513 net.cpp:141] Setting up relu2
I0317 09:28:40.642117  3513 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0317 09:28:40.642122  3513 net.cpp:156] Memory required for data: 773113200
I0317 09:28:40.642127  3513 layer_factory.hpp:77] Creating layer norm2
I0317 09:28:40.642141  3513 net.cpp:91] Creating Layer norm2
I0317 09:28:40.642148  3513 net.cpp:425] norm2 <- conv2
I0317 09:28:40.642155  3513 net.cpp:399] norm2 -> norm2
I0317 09:28:40.642455  3513 net.cpp:141] Setting up norm2
I0317 09:28:40.642479  3513 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0317 09:28:40.642485  3513 net.cpp:156] Memory required for data: 847762800
I0317 09:28:40.642491  3513 layer_factory.hpp:77] Creating layer pool2
I0317 09:28:40.642501  3513 net.cpp:91] Creating Layer pool2
I0317 09:28:40.642506  3513 net.cpp:425] pool2 <- norm2
I0317 09:28:40.642518  3513 net.cpp:399] pool2 -> pool2
I0317 09:28:40.642571  3513 net.cpp:141] Setting up pool2
I0317 09:28:40.642590  3513 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0317 09:28:40.642594  3513 net.cpp:156] Memory required for data: 865068400
I0317 09:28:40.642599  3513 layer_factory.hpp:77] Creating layer conv3
I0317 09:28:40.642621  3513 net.cpp:91] Creating Layer conv3
I0317 09:28:40.642633  3513 net.cpp:425] conv3 <- pool2
I0317 09:28:40.642643  3513 net.cpp:399] conv3 -> conv3
I0317 09:28:40.673790  3513 net.cpp:141] Setting up conv3
I0317 09:28:40.673841  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:40.673848  3513 net.cpp:156] Memory required for data: 891026800
I0317 09:28:40.673871  3513 layer_factory.hpp:77] Creating layer relu3
I0317 09:28:40.673885  3513 net.cpp:91] Creating Layer relu3
I0317 09:28:40.673920  3513 net.cpp:425] relu3 <- conv3
I0317 09:28:40.673933  3513 net.cpp:386] relu3 -> conv3 (in-place)
I0317 09:28:40.674216  3513 net.cpp:141] Setting up relu3
I0317 09:28:40.674238  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:40.674244  3513 net.cpp:156] Memory required for data: 916985200
I0317 09:28:40.674250  3513 layer_factory.hpp:77] Creating layer conv4
I0317 09:28:40.674268  3513 net.cpp:91] Creating Layer conv4
I0317 09:28:40.674275  3513 net.cpp:425] conv4 <- conv3
I0317 09:28:40.674284  3513 net.cpp:399] conv4 -> conv4
I0317 09:28:40.698777  3513 net.cpp:141] Setting up conv4
I0317 09:28:40.698837  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:40.698845  3513 net.cpp:156] Memory required for data: 942943600
I0317 09:28:40.698860  3513 layer_factory.hpp:77] Creating layer relu4
I0317 09:28:40.698879  3513 net.cpp:91] Creating Layer relu4
I0317 09:28:40.698886  3513 net.cpp:425] relu4 <- conv4
I0317 09:28:40.698896  3513 net.cpp:386] relu4 -> conv4 (in-place)
I0317 09:28:40.699091  3513 net.cpp:141] Setting up relu4
I0317 09:28:40.699120  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:40.699126  3513 net.cpp:156] Memory required for data: 968902000
I0317 09:28:40.699131  3513 layer_factory.hpp:77] Creating layer conv5
I0317 09:28:40.699151  3513 net.cpp:91] Creating Layer conv5
I0317 09:28:40.699164  3513 net.cpp:425] conv5 <- conv4
I0317 09:28:40.699177  3513 net.cpp:399] conv5 -> conv5
I0317 09:28:40.716339  3513 net.cpp:141] Setting up conv5
I0317 09:28:40.716393  3513 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0317 09:28:40.716401  3513 net.cpp:156] Memory required for data: 986207600
I0317 09:28:40.716424  3513 layer_factory.hpp:77] Creating layer relu5
I0317 09:28:40.716455  3513 net.cpp:91] Creating Layer relu5
I0317 09:28:40.716464  3513 net.cpp:425] relu5 <- conv5
I0317 09:28:40.716475  3513 net.cpp:386] relu5 -> conv5 (in-place)
I0317 09:28:40.716795  3513 net.cpp:141] Setting up relu5
I0317 09:28:40.716820  3513 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0317 09:28:40.716825  3513 net.cpp:156] Memory required for data: 1003513200
I0317 09:28:40.716831  3513 layer_factory.hpp:77] Creating layer pool5
I0317 09:28:40.716846  3513 net.cpp:91] Creating Layer pool5
I0317 09:28:40.716859  3513 net.cpp:425] pool5 <- conv5
I0317 09:28:40.716869  3513 net.cpp:399] pool5 -> pool5
I0317 09:28:40.716943  3513 net.cpp:141] Setting up pool5
I0317 09:28:40.716961  3513 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0317 09:28:40.716966  3513 net.cpp:156] Memory required for data: 1007199600
I0317 09:28:40.716972  3513 layer_factory.hpp:77] Creating layer fc6
I0317 09:28:40.716984  3513 net.cpp:91] Creating Layer fc6
I0317 09:28:40.716990  3513 net.cpp:425] fc6 <- pool5
I0317 09:28:40.717001  3513 net.cpp:399] fc6 -> fc6
I0317 09:28:41.986933  3513 net.cpp:141] Setting up fc6
I0317 09:28:41.986994  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:41.987002  3513 net.cpp:156] Memory required for data: 1008838000
I0317 09:28:41.987020  3513 layer_factory.hpp:77] Creating layer relu6
I0317 09:28:41.987035  3513 net.cpp:91] Creating Layer relu6
I0317 09:28:41.987042  3513 net.cpp:425] relu6 <- fc6
I0317 09:28:41.987053  3513 net.cpp:386] relu6 -> fc6 (in-place)
I0317 09:28:41.987345  3513 net.cpp:141] Setting up relu6
I0317 09:28:41.987366  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:41.987371  3513 net.cpp:156] Memory required for data: 1010476400
I0317 09:28:41.987377  3513 layer_factory.hpp:77] Creating layer drop6
I0317 09:28:41.987391  3513 net.cpp:91] Creating Layer drop6
I0317 09:28:41.987397  3513 net.cpp:425] drop6 <- fc6
I0317 09:28:41.987404  3513 net.cpp:386] drop6 -> fc6 (in-place)
I0317 09:28:41.987447  3513 net.cpp:141] Setting up drop6
I0317 09:28:41.987464  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:41.987471  3513 net.cpp:156] Memory required for data: 1012114800
I0317 09:28:41.987476  3513 layer_factory.hpp:77] Creating layer fc7
I0317 09:28:41.987488  3513 net.cpp:91] Creating Layer fc7
I0317 09:28:41.987524  3513 net.cpp:425] fc7 <- fc6
I0317 09:28:41.987537  3513 net.cpp:399] fc7 -> fc7
I0317 09:28:42.549863  3513 net.cpp:141] Setting up fc7
I0317 09:28:42.549921  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:42.549927  3513 net.cpp:156] Memory required for data: 1013753200
I0317 09:28:42.549943  3513 layer_factory.hpp:77] Creating layer fc8
I0317 09:28:42.549973  3513 net.cpp:91] Creating Layer fc8
I0317 09:28:42.549983  3513 net.cpp:425] fc8 <- fc7
I0317 09:28:42.549993  3513 net.cpp:399] fc8 -> fc8
I0317 09:28:42.686378  3513 net.cpp:141] Setting up fc8
I0317 09:28:42.686419  3513 net.cpp:148] Top shape: 100 1000 (100000)
I0317 09:28:42.686424  3513 net.cpp:156] Memory required for data: 1014153200
I0317 09:28:42.686439  3513 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0317 09:28:42.686451  3513 net.cpp:91] Creating Layer fc8_fc8_0_split
I0317 09:28:42.686457  3513 net.cpp:425] fc8_fc8_0_split <- fc8
I0317 09:28:42.686468  3513 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0317 09:28:42.686480  3513 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0317 09:28:42.686539  3513 net.cpp:141] Setting up fc8_fc8_0_split
I0317 09:28:42.686558  3513 net.cpp:148] Top shape: 100 1000 (100000)
I0317 09:28:42.686564  3513 net.cpp:148] Top shape: 100 1000 (100000)
I0317 09:28:42.686568  3513 net.cpp:156] Memory required for data: 1014953200
I0317 09:28:42.686574  3513 layer_factory.hpp:77] Creating layer conv1_p
I0317 09:28:42.686599  3513 net.cpp:91] Creating Layer conv1_p
I0317 09:28:42.686614  3513 net.cpp:425] conv1_p <- data_p
I0317 09:28:42.686627  3513 net.cpp:399] conv1_p -> conv1_p
I0317 09:28:42.689030  3513 net.cpp:141] Setting up conv1_p
I0317 09:28:42.689055  3513 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0317 09:28:42.689067  3513 net.cpp:156] Memory required for data: 1131113200
I0317 09:28:42.689080  3513 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0317 09:28:42.689090  3513 net.cpp:484] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0317 09:28:42.689095  3513 layer_factory.hpp:77] Creating layer relu1_p
I0317 09:28:42.689103  3513 net.cpp:91] Creating Layer relu1_p
I0317 09:28:42.689110  3513 net.cpp:425] relu1_p <- conv1_p
I0317 09:28:42.689116  3513 net.cpp:386] relu1_p -> conv1_p (in-place)
I0317 09:28:42.689302  3513 net.cpp:141] Setting up relu1_p
I0317 09:28:42.689326  3513 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0317 09:28:42.689332  3513 net.cpp:156] Memory required for data: 1247273200
I0317 09:28:42.689337  3513 layer_factory.hpp:77] Creating layer norm1_p
I0317 09:28:42.689348  3513 net.cpp:91] Creating Layer norm1_p
I0317 09:28:42.689353  3513 net.cpp:425] norm1_p <- conv1_p
I0317 09:28:42.689363  3513 net.cpp:399] norm1_p -> norm1_p
I0317 09:28:42.689677  3513 net.cpp:141] Setting up norm1_p
I0317 09:28:42.689698  3513 net.cpp:148] Top shape: 100 96 55 55 (29040000)
I0317 09:28:42.689704  3513 net.cpp:156] Memory required for data: 1363433200
I0317 09:28:42.689710  3513 layer_factory.hpp:77] Creating layer pool1_p
I0317 09:28:42.689723  3513 net.cpp:91] Creating Layer pool1_p
I0317 09:28:42.689728  3513 net.cpp:425] pool1_p <- norm1_p
I0317 09:28:42.689736  3513 net.cpp:399] pool1_p -> pool1_p
I0317 09:28:42.689798  3513 net.cpp:141] Setting up pool1_p
I0317 09:28:42.689816  3513 net.cpp:148] Top shape: 100 96 27 27 (6998400)
I0317 09:28:42.689821  3513 net.cpp:156] Memory required for data: 1391426800
I0317 09:28:42.689826  3513 layer_factory.hpp:77] Creating layer conv2_p
I0317 09:28:42.689841  3513 net.cpp:91] Creating Layer conv2_p
I0317 09:28:42.689858  3513 net.cpp:425] conv2_p <- pool1_p
I0317 09:28:42.689872  3513 net.cpp:399] conv2_p -> conv2_p
I0317 09:28:42.702046  3513 net.cpp:141] Setting up conv2_p
I0317 09:28:42.702071  3513 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0317 09:28:42.702077  3513 net.cpp:156] Memory required for data: 1466076400
I0317 09:28:42.702085  3513 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0317 09:28:42.702119  3513 net.cpp:484] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0317 09:28:42.702126  3513 layer_factory.hpp:77] Creating layer relu2_p
I0317 09:28:42.702137  3513 net.cpp:91] Creating Layer relu2_p
I0317 09:28:42.702143  3513 net.cpp:425] relu2_p <- conv2_p
I0317 09:28:42.702152  3513 net.cpp:386] relu2_p -> conv2_p (in-place)
I0317 09:28:42.702324  3513 net.cpp:141] Setting up relu2_p
I0317 09:28:42.702344  3513 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0317 09:28:42.702350  3513 net.cpp:156] Memory required for data: 1540726000
I0317 09:28:42.702355  3513 layer_factory.hpp:77] Creating layer norm2_p
I0317 09:28:42.702368  3513 net.cpp:91] Creating Layer norm2_p
I0317 09:28:42.702373  3513 net.cpp:425] norm2_p <- conv2_p
I0317 09:28:42.702383  3513 net.cpp:399] norm2_p -> norm2_p
I0317 09:28:42.702791  3513 net.cpp:141] Setting up norm2_p
I0317 09:28:42.702813  3513 net.cpp:148] Top shape: 100 256 27 27 (18662400)
I0317 09:28:42.702819  3513 net.cpp:156] Memory required for data: 1615375600
I0317 09:28:42.702826  3513 layer_factory.hpp:77] Creating layer pool2_p
I0317 09:28:42.702836  3513 net.cpp:91] Creating Layer pool2_p
I0317 09:28:42.702842  3513 net.cpp:425] pool2_p <- norm2_p
I0317 09:28:42.702850  3513 net.cpp:399] pool2_p -> pool2_p
I0317 09:28:42.702909  3513 net.cpp:141] Setting up pool2_p
I0317 09:28:42.702926  3513 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0317 09:28:42.702931  3513 net.cpp:156] Memory required for data: 1632681200
I0317 09:28:42.702936  3513 layer_factory.hpp:77] Creating layer conv3_p
I0317 09:28:42.702956  3513 net.cpp:91] Creating Layer conv3_p
I0317 09:28:42.702970  3513 net.cpp:425] conv3_p <- pool2_p
I0317 09:28:42.702981  3513 net.cpp:399] conv3_p -> conv3_p
I0317 09:28:42.733355  3513 net.cpp:141] Setting up conv3_p
I0317 09:28:42.733381  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:42.733386  3513 net.cpp:156] Memory required for data: 1658639600
I0317 09:28:42.733393  3513 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'conv3', param index 0
I0317 09:28:42.733400  3513 net.cpp:484] Sharing parameters 'conv3_b' owned by layer 'conv3', param index 1
I0317 09:28:42.733405  3513 layer_factory.hpp:77] Creating layer relu3_p
I0317 09:28:42.733417  3513 net.cpp:91] Creating Layer relu3_p
I0317 09:28:42.733423  3513 net.cpp:425] relu3_p <- conv3_p
I0317 09:28:42.733430  3513 net.cpp:386] relu3_p -> conv3_p (in-place)
I0317 09:28:42.733711  3513 net.cpp:141] Setting up relu3_p
I0317 09:28:42.733732  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:42.733738  3513 net.cpp:156] Memory required for data: 1684598000
I0317 09:28:42.733744  3513 layer_factory.hpp:77] Creating layer conv4_p
I0317 09:28:42.733759  3513 net.cpp:91] Creating Layer conv4_p
I0317 09:28:42.733777  3513 net.cpp:425] conv4_p <- conv3_p
I0317 09:28:42.733790  3513 net.cpp:399] conv4_p -> conv4_p
I0317 09:28:42.757936  3513 net.cpp:141] Setting up conv4_p
I0317 09:28:42.757961  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:42.757967  3513 net.cpp:156] Memory required for data: 1710556400
I0317 09:28:42.757974  3513 net.cpp:484] Sharing parameters 'conv4_w' owned by layer 'conv4', param index 0
I0317 09:28:42.757982  3513 net.cpp:484] Sharing parameters 'conv4_b' owned by layer 'conv4', param index 1
I0317 09:28:42.757987  3513 layer_factory.hpp:77] Creating layer relu4_p
I0317 09:28:42.757997  3513 net.cpp:91] Creating Layer relu4_p
I0317 09:28:42.758003  3513 net.cpp:425] relu4_p <- conv4_p
I0317 09:28:42.758011  3513 net.cpp:386] relu4_p -> conv4_p (in-place)
I0317 09:28:42.758182  3513 net.cpp:141] Setting up relu4_p
I0317 09:28:42.758200  3513 net.cpp:148] Top shape: 100 384 13 13 (6489600)
I0317 09:28:42.758206  3513 net.cpp:156] Memory required for data: 1736514800
I0317 09:28:42.758213  3513 layer_factory.hpp:77] Creating layer conv5_p
I0317 09:28:42.758229  3513 net.cpp:91] Creating Layer conv5_p
I0317 09:28:42.758237  3513 net.cpp:425] conv5_p <- conv4_p
I0317 09:28:42.758246  3513 net.cpp:399] conv5_p -> conv5_p
I0317 09:28:42.774904  3513 net.cpp:141] Setting up conv5_p
I0317 09:28:42.774929  3513 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0317 09:28:42.774935  3513 net.cpp:156] Memory required for data: 1753820400
I0317 09:28:42.774941  3513 net.cpp:484] Sharing parameters 'conv5_w' owned by layer 'conv5', param index 0
I0317 09:28:42.774948  3513 net.cpp:484] Sharing parameters 'conv5_b' owned by layer 'conv5', param index 1
I0317 09:28:42.774953  3513 layer_factory.hpp:77] Creating layer relu5_p
I0317 09:28:42.774965  3513 net.cpp:91] Creating Layer relu5_p
I0317 09:28:42.774971  3513 net.cpp:425] relu5_p <- conv5_p
I0317 09:28:42.774978  3513 net.cpp:386] relu5_p -> conv5_p (in-place)
I0317 09:28:42.775147  3513 net.cpp:141] Setting up relu5_p
I0317 09:28:42.775166  3513 net.cpp:148] Top shape: 100 256 13 13 (4326400)
I0317 09:28:42.775172  3513 net.cpp:156] Memory required for data: 1771126000
I0317 09:28:42.775177  3513 layer_factory.hpp:77] Creating layer pool5_p
I0317 09:28:42.775189  3513 net.cpp:91] Creating Layer pool5_p
I0317 09:28:42.775195  3513 net.cpp:425] pool5_p <- conv5_p
I0317 09:28:42.775203  3513 net.cpp:399] pool5_p -> pool5_p
I0317 09:28:42.775270  3513 net.cpp:141] Setting up pool5_p
I0317 09:28:42.775288  3513 net.cpp:148] Top shape: 100 256 6 6 (921600)
I0317 09:28:42.775293  3513 net.cpp:156] Memory required for data: 1774812400
I0317 09:28:42.775298  3513 layer_factory.hpp:77] Creating layer fc6_p
I0317 09:28:42.775311  3513 net.cpp:91] Creating Layer fc6_p
I0317 09:28:42.775317  3513 net.cpp:425] fc6_p <- pool5_p
I0317 09:28:42.775326  3513 net.cpp:399] fc6_p -> fc6_p
I0317 09:28:44.043890  3513 net.cpp:141] Setting up fc6_p
I0317 09:28:44.043948  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:44.043956  3513 net.cpp:156] Memory required for data: 1776450800
I0317 09:28:44.043967  3513 net.cpp:484] Sharing parameters 'fc6_w' owned by layer 'fc6', param index 0
I0317 09:28:44.043974  3513 net.cpp:484] Sharing parameters 'fc6_b' owned by layer 'fc6', param index 1
I0317 09:28:44.043980  3513 layer_factory.hpp:77] Creating layer relu6_p
I0317 09:28:44.043995  3513 net.cpp:91] Creating Layer relu6_p
I0317 09:28:44.044003  3513 net.cpp:425] relu6_p <- fc6_p
I0317 09:28:44.044014  3513 net.cpp:386] relu6_p -> fc6_p (in-place)
I0317 09:28:44.044508  3513 net.cpp:141] Setting up relu6_p
I0317 09:28:44.044531  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:44.044538  3513 net.cpp:156] Memory required for data: 1778089200
I0317 09:28:44.044543  3513 layer_factory.hpp:77] Creating layer drop6_p
I0317 09:28:44.044556  3513 net.cpp:91] Creating Layer drop6_p
I0317 09:28:44.044562  3513 net.cpp:425] drop6_p <- fc6_p
I0317 09:28:44.044572  3513 net.cpp:386] drop6_p -> fc6_p (in-place)
I0317 09:28:44.044638  3513 net.cpp:141] Setting up drop6_p
I0317 09:28:44.044663  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:44.044673  3513 net.cpp:156] Memory required for data: 1779727600
I0317 09:28:44.044678  3513 layer_factory.hpp:77] Creating layer fc7_p
I0317 09:28:44.044695  3513 net.cpp:91] Creating Layer fc7_p
I0317 09:28:44.044723  3513 net.cpp:425] fc7_p <- fc6_p
I0317 09:28:44.044736  3513 net.cpp:399] fc7_p -> fc7_p
I0317 09:28:44.611433  3513 net.cpp:141] Setting up fc7_p
I0317 09:28:44.611491  3513 net.cpp:148] Top shape: 100 4096 (409600)
I0317 09:28:44.611500  3513 net.cpp:156] Memory required for data: 1781366000
I0317 09:28:44.611511  3513 net.cpp:484] Sharing parameters 'fc7_w' owned by layer 'fc7', param index 0
I0317 09:28:44.611519  3513 net.cpp:484] Sharing parameters 'fc7_b' owned by layer 'fc7', param index 1
I0317 09:28:44.611526  3513 layer_factory.hpp:77] Creating layer fc8_p
I0317 09:28:44.611548  3513 net.cpp:91] Creating Layer fc8_p
I0317 09:28:44.611557  3513 net.cpp:425] fc8_p <- fc7_p
I0317 09:28:44.611572  3513 net.cpp:399] fc8_p -> fc8_p
I0317 09:28:44.748157  3513 net.cpp:141] Setting up fc8_p
I0317 09:28:44.748203  3513 net.cpp:148] Top shape: 100 1000 (100000)
I0317 09:28:44.748208  3513 net.cpp:156] Memory required for data: 1781766000
I0317 09:28:44.748245  3513 net.cpp:484] Sharing parameters 'fc8_w' owned by layer 'fc8', param index 0
I0317 09:28:44.748255  3513 net.cpp:484] Sharing parameters 'fc8_b' owned by layer 'fc8', param index 1
I0317 09:28:44.748260  3513 layer_factory.hpp:77] Creating layer fc8_p_fc8_p_0_split
I0317 09:28:44.748273  3513 net.cpp:91] Creating Layer fc8_p_fc8_p_0_split
I0317 09:28:44.748280  3513 net.cpp:425] fc8_p_fc8_p_0_split <- fc8_p
I0317 09:28:44.748291  3513 net.cpp:399] fc8_p_fc8_p_0_split -> fc8_p_fc8_p_0_split_0
I0317 09:28:44.748311  3513 net.cpp:399] fc8_p_fc8_p_0_split -> fc8_p_fc8_p_0_split_1
I0317 09:28:44.748399  3513 net.cpp:141] Setting up fc8_p_fc8_p_0_split
I0317 09:28:44.748417  3513 net.cpp:148] Top shape: 100 1000 (100000)
I0317 09:28:44.748423  3513 net.cpp:148] Top shape: 100 1000 (100000)
I0317 09:28:44.748437  3513 net.cpp:156] Memory required for data: 1782566000
I0317 09:28:44.748446  3513 layer_factory.hpp:77] Creating layer siamese_accuracy
I0317 09:28:44.748472  3513 net.cpp:91] Creating Layer siamese_accuracy
I0317 09:28:44.748487  3513 net.cpp:425] siamese_accuracy <- fc8_fc8_0_split_0
I0317 09:28:44.748502  3513 net.cpp:425] siamese_accuracy <- fc8_p_fc8_p_0_split_0
I0317 09:28:44.748512  3513 net.cpp:425] siamese_accuracy <- sim_pair_data_1_split_0
I0317 09:28:44.748522  3513 net.cpp:399] siamese_accuracy -> siamese_accuracy
I0317 09:28:44.748718  3513 net.cpp:141] Setting up siamese_accuracy
I0317 09:28:44.748736  3513 net.cpp:148] Top shape: (1)
I0317 09:28:44.748742  3513 net.cpp:151]     with loss weight 1
I0317 09:28:44.748760  3513 net.cpp:156] Memory required for data: 1782566004
I0317 09:28:44.748766  3513 layer_factory.hpp:77] Creating layer loss
I0317 09:28:44.748785  3513 net.cpp:91] Creating Layer loss
I0317 09:28:44.748805  3513 net.cpp:425] loss <- fc8_fc8_0_split_1
I0317 09:28:44.748813  3513 net.cpp:425] loss <- fc8_p_fc8_p_0_split_1
I0317 09:28:44.748819  3513 net.cpp:425] loss <- sim_pair_data_1_split_1
I0317 09:28:44.748829  3513 net.cpp:399] loss -> loss
I0317 09:28:44.748970  3513 net.cpp:141] Setting up loss
I0317 09:28:44.748987  3513 net.cpp:148] Top shape: (1)
I0317 09:28:44.748993  3513 net.cpp:151]     with loss weight 1
I0317 09:28:44.749001  3513 net.cpp:156] Memory required for data: 1782566008
I0317 09:28:44.749007  3513 net.cpp:217] loss needs backward computation.
I0317 09:28:44.749013  3513 net.cpp:217] siamese_accuracy needs backward computation.
I0317 09:28:44.749022  3513 net.cpp:217] fc8_p_fc8_p_0_split needs backward computation.
I0317 09:28:44.749027  3513 net.cpp:217] fc8_p needs backward computation.
I0317 09:28:44.749032  3513 net.cpp:219] fc7_p does not need backward computation.
I0317 09:28:44.749037  3513 net.cpp:219] drop6_p does not need backward computation.
I0317 09:28:44.749043  3513 net.cpp:219] relu6_p does not need backward computation.
I0317 09:28:44.749047  3513 net.cpp:219] fc6_p does not need backward computation.
I0317 09:28:44.749053  3513 net.cpp:219] pool5_p does not need backward computation.
I0317 09:28:44.749058  3513 net.cpp:219] relu5_p does not need backward computation.
I0317 09:28:44.749063  3513 net.cpp:219] conv5_p does not need backward computation.
I0317 09:28:44.749068  3513 net.cpp:219] relu4_p does not need backward computation.
I0317 09:28:44.749073  3513 net.cpp:219] conv4_p does not need backward computation.
I0317 09:28:44.749078  3513 net.cpp:219] relu3_p does not need backward computation.
I0317 09:28:44.749083  3513 net.cpp:219] conv3_p does not need backward computation.
I0317 09:28:44.749089  3513 net.cpp:219] pool2_p does not need backward computation.
I0317 09:28:44.749094  3513 net.cpp:219] norm2_p does not need backward computation.
I0317 09:28:44.749099  3513 net.cpp:219] relu2_p does not need backward computation.
I0317 09:28:44.749104  3513 net.cpp:219] conv2_p does not need backward computation.
I0317 09:28:44.749109  3513 net.cpp:219] pool1_p does not need backward computation.
I0317 09:28:44.749114  3513 net.cpp:219] norm1_p does not need backward computation.
I0317 09:28:44.749120  3513 net.cpp:219] relu1_p does not need backward computation.
I0317 09:28:44.749136  3513 net.cpp:219] conv1_p does not need backward computation.
I0317 09:28:44.749143  3513 net.cpp:217] fc8_fc8_0_split needs backward computation.
I0317 09:28:44.749148  3513 net.cpp:217] fc8 needs backward computation.
I0317 09:28:44.749168  3513 net.cpp:219] fc7 does not need backward computation.
I0317 09:28:44.749176  3513 net.cpp:219] drop6 does not need backward computation.
I0317 09:28:44.749181  3513 net.cpp:219] relu6 does not need backward computation.
I0317 09:28:44.749186  3513 net.cpp:219] fc6 does not need backward computation.
I0317 09:28:44.749191  3513 net.cpp:219] pool5 does not need backward computation.
I0317 09:28:44.749197  3513 net.cpp:219] relu5 does not need backward computation.
I0317 09:28:44.749202  3513 net.cpp:219] conv5 does not need backward computation.
I0317 09:28:44.749207  3513 net.cpp:219] relu4 does not need backward computation.
I0317 09:28:44.749212  3513 net.cpp:219] conv4 does not need backward computation.
I0317 09:28:44.749217  3513 net.cpp:219] relu3 does not need backward computation.
I0317 09:28:44.749222  3513 net.cpp:219] conv3 does not need backward computation.
I0317 09:28:44.749228  3513 net.cpp:219] pool2 does not need backward computation.
I0317 09:28:44.749233  3513 net.cpp:219] norm2 does not need backward computation.
I0317 09:28:44.749238  3513 net.cpp:219] relu2 does not need backward computation.
I0317 09:28:44.749243  3513 net.cpp:219] conv2 does not need backward computation.
I0317 09:28:44.749248  3513 net.cpp:219] pool1 does not need backward computation.
I0317 09:28:44.749253  3513 net.cpp:219] norm1 does not need backward computation.
I0317 09:28:44.749258  3513 net.cpp:219] relu1 does not need backward computation.
I0317 09:28:44.749264  3513 net.cpp:219] conv1 does not need backward computation.
I0317 09:28:44.749269  3513 net.cpp:219] slice_pair does not need backward computation.
I0317 09:28:44.749274  3513 net.cpp:219] sim_pair_data_1_split does not need backward computation.
I0317 09:28:44.749280  3513 net.cpp:219] pair_data does not need backward computation.
I0317 09:28:44.749284  3513 net.cpp:261] This network produces output loss
I0317 09:28:44.749289  3513 net.cpp:261] This network produces output siamese_accuracy
I0317 09:28:44.786432  3513 net.cpp:274] Network initialization done.
I0317 09:28:44.786731  3513 solver.cpp:60] Solver scaffolding done.
I0317 09:28:44.787555  3513 caffe.cpp:209] Resuming from caffe_alexnet_train_iter_13673.solverstate
I0317 09:28:46.275812  3513 sgd_solver.cpp:318] SGDSolver: restoring history
I0317 09:28:46.454973  3513 caffe.cpp:219] Starting Optimization
I0317 09:28:46.455032  3513 solver.cpp:279] Solving SiameseAlexNet
I0317 09:28:46.455039  3513 solver.cpp:280] Learning Rate Policy: step
I0317 09:28:49.397117  3513 solver.cpp:228] Iteration 13680, loss = 0.00475583
I0317 09:28:49.397202  3513 solver.cpp:244]     Train net output #0: loss = 0.00475583 (* 1 = 0.00475583 loss)
I0317 09:28:49.397215  3513 sgd_solver.cpp:106] Iteration 13680, lr = 0.01
I0317 09:28:56.649735  3513 solver.cpp:228] Iteration 13700, loss = 0.00740921
I0317 09:28:56.649804  3513 solver.cpp:244]     Train net output #0: loss = 0.00740921 (* 1 = 0.00740921 loss)
I0317 09:28:56.649818  3513 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0317 09:29:03.938259  3513 solver.cpp:228] Iteration 13720, loss = 0.00425929
I0317 09:29:03.938328  3513 solver.cpp:244]     Train net output #0: loss = 0.00425929 (* 1 = 0.00425929 loss)
I0317 09:29:03.938343  3513 sgd_solver.cpp:106] Iteration 13720, lr = 0.01
I0317 09:29:11.246635  3513 solver.cpp:228] Iteration 13740, loss = 0.00846623
I0317 09:29:11.246779  3513 solver.cpp:244]     Train net output #0: loss = 0.00846623 (* 1 = 0.00846623 loss)
I0317 09:29:11.246793  3513 sgd_solver.cpp:106] Iteration 13740, lr = 0.01
I0317 09:29:14.534806  3513 solver.cpp:337] Iteration 13750, Testing net (#0)
I0317 09:31:08.466011  3513 solver.cpp:404]     Test net output #0: loss = 0.0622261 (* 1 = 0.0622261 loss)
I0317 09:31:08.466264  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 09:31:12.410889  3513 solver.cpp:228] Iteration 13760, loss = 0.00591141
I0317 09:31:12.410954  3513 solver.cpp:244]     Train net output #0: loss = 0.00591141 (* 1 = 0.00591141 loss)
I0317 09:31:12.410969  3513 sgd_solver.cpp:106] Iteration 13760, lr = 0.01
I0317 09:31:19.676445  3513 solver.cpp:228] Iteration 13780, loss = 0.0107268
I0317 09:31:19.676508  3513 solver.cpp:244]     Train net output #0: loss = 0.0107268 (* 1 = 0.0107268 loss)
I0317 09:31:19.676522  3513 sgd_solver.cpp:106] Iteration 13780, lr = 0.01
I0317 09:31:26.968411  3513 solver.cpp:228] Iteration 13800, loss = 0.00295827
I0317 09:31:26.968478  3513 solver.cpp:244]     Train net output #0: loss = 0.00295827 (* 1 = 0.00295827 loss)
I0317 09:31:26.968492  3513 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0317 09:31:34.287581  3513 solver.cpp:228] Iteration 13820, loss = 0.00278194
I0317 09:31:34.287650  3513 solver.cpp:244]     Train net output #0: loss = 0.00278194 (* 1 = 0.00278194 loss)
I0317 09:31:34.287664  3513 sgd_solver.cpp:106] Iteration 13820, lr = 0.01
I0317 09:31:41.619464  3513 solver.cpp:228] Iteration 13840, loss = 0.00370504
I0317 09:31:41.619624  3513 solver.cpp:244]     Train net output #0: loss = 0.00370504 (* 1 = 0.00370504 loss)
I0317 09:31:41.619638  3513 sgd_solver.cpp:106] Iteration 13840, lr = 0.01
I0317 09:31:48.944340  3513 solver.cpp:228] Iteration 13860, loss = 0.00308503
I0317 09:31:48.944423  3513 solver.cpp:244]     Train net output #0: loss = 0.00308503 (* 1 = 0.00308503 loss)
I0317 09:31:48.944437  3513 sgd_solver.cpp:106] Iteration 13860, lr = 0.01
I0317 09:31:56.269381  3513 solver.cpp:228] Iteration 13880, loss = 0.00417036
I0317 09:31:56.269445  3513 solver.cpp:244]     Train net output #0: loss = 0.00417036 (* 1 = 0.00417036 loss)
I0317 09:31:56.269459  3513 sgd_solver.cpp:106] Iteration 13880, lr = 0.01
I0317 09:32:03.592545  3513 solver.cpp:228] Iteration 13900, loss = 0.00682859
I0317 09:32:03.592610  3513 solver.cpp:244]     Train net output #0: loss = 0.00682859 (* 1 = 0.00682859 loss)
I0317 09:32:03.592623  3513 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0317 09:32:10.920766  3513 solver.cpp:228] Iteration 13920, loss = 0.0106287
I0317 09:32:10.920840  3513 solver.cpp:244]     Train net output #0: loss = 0.0106287 (* 1 = 0.0106287 loss)
I0317 09:32:10.920855  3513 sgd_solver.cpp:106] Iteration 13920, lr = 0.01
I0317 09:32:18.248934  3513 solver.cpp:228] Iteration 13940, loss = 0.00534356
I0317 09:32:18.249073  3513 solver.cpp:244]     Train net output #0: loss = 0.00534356 (* 1 = 0.00534356 loss)
I0317 09:32:18.249086  3513 sgd_solver.cpp:106] Iteration 13940, lr = 0.01
I0317 09:32:25.565878  3513 solver.cpp:228] Iteration 13960, loss = 0.00941027
I0317 09:32:25.565950  3513 solver.cpp:244]     Train net output #0: loss = 0.00941027 (* 1 = 0.00941027 loss)
I0317 09:32:25.565975  3513 sgd_solver.cpp:106] Iteration 13960, lr = 0.01
I0317 09:32:32.883564  3513 solver.cpp:228] Iteration 13980, loss = 0.00496489
I0317 09:32:32.883631  3513 solver.cpp:244]     Train net output #0: loss = 0.00496489 (* 1 = 0.00496489 loss)
I0317 09:32:32.883644  3513 sgd_solver.cpp:106] Iteration 13980, lr = 0.01
I0317 09:32:39.847501  3513 solver.cpp:337] Iteration 14000, Testing net (#0)
I0317 09:34:33.711128  3513 solver.cpp:404]     Test net output #0: loss = 0.0600013 (* 1 = 0.0600013 loss)
I0317 09:34:33.711261  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.672999 (* 1 = 0.672999 loss)
I0317 09:34:34.048287  3513 solver.cpp:228] Iteration 14000, loss = 0.00345172
I0317 09:34:34.048363  3513 solver.cpp:244]     Train net output #0: loss = 0.00345172 (* 1 = 0.00345172 loss)
I0317 09:34:34.048388  3513 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0317 09:34:41.306553  3513 solver.cpp:228] Iteration 14020, loss = 0.0039442
I0317 09:34:41.306623  3513 solver.cpp:244]     Train net output #0: loss = 0.0039442 (* 1 = 0.0039442 loss)
I0317 09:34:41.306637  3513 sgd_solver.cpp:106] Iteration 14020, lr = 0.01
I0317 09:34:48.595947  3513 solver.cpp:228] Iteration 14040, loss = 0.00344784
I0317 09:34:48.596016  3513 solver.cpp:244]     Train net output #0: loss = 0.00344783 (* 1 = 0.00344783 loss)
I0317 09:34:48.596030  3513 sgd_solver.cpp:106] Iteration 14040, lr = 0.01
I0317 09:34:55.914160  3513 solver.cpp:228] Iteration 14060, loss = 0.00761834
I0317 09:34:55.914228  3513 solver.cpp:244]     Train net output #0: loss = 0.00761834 (* 1 = 0.00761834 loss)
I0317 09:34:55.914243  3513 sgd_solver.cpp:106] Iteration 14060, lr = 0.01
I0317 09:35:03.236601  3513 solver.cpp:228] Iteration 14080, loss = 0.00500588
I0317 09:35:03.236671  3513 solver.cpp:244]     Train net output #0: loss = 0.00500588 (* 1 = 0.00500588 loss)
I0317 09:35:03.236685  3513 sgd_solver.cpp:106] Iteration 14080, lr = 0.01
I0317 09:35:10.558564  3513 solver.cpp:228] Iteration 14100, loss = 0.00881753
I0317 09:35:10.558753  3513 solver.cpp:244]     Train net output #0: loss = 0.00881753 (* 1 = 0.00881753 loss)
I0317 09:35:10.558766  3513 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0317 09:35:17.875994  3513 solver.cpp:228] Iteration 14120, loss = 0.00716593
I0317 09:35:17.876066  3513 solver.cpp:244]     Train net output #0: loss = 0.00716593 (* 1 = 0.00716593 loss)
I0317 09:35:17.876080  3513 sgd_solver.cpp:106] Iteration 14120, lr = 0.01
I0317 09:35:25.188442  3513 solver.cpp:228] Iteration 14140, loss = 0.00605611
I0317 09:35:25.188511  3513 solver.cpp:244]     Train net output #0: loss = 0.0060561 (* 1 = 0.0060561 loss)
I0317 09:35:25.188524  3513 sgd_solver.cpp:106] Iteration 14140, lr = 0.01
I0317 09:35:32.514513  3513 solver.cpp:228] Iteration 14160, loss = 0.00297677
I0317 09:35:32.514583  3513 solver.cpp:244]     Train net output #0: loss = 0.00297677 (* 1 = 0.00297677 loss)
I0317 09:35:32.514596  3513 sgd_solver.cpp:106] Iteration 14160, lr = 0.01
I0317 09:35:39.837837  3513 solver.cpp:228] Iteration 14180, loss = 0.00577203
I0317 09:35:39.837904  3513 solver.cpp:244]     Train net output #0: loss = 0.00577202 (* 1 = 0.00577202 loss)
I0317 09:35:39.837918  3513 sgd_solver.cpp:106] Iteration 14180, lr = 0.01
I0317 09:35:47.164100  3513 solver.cpp:228] Iteration 14200, loss = 0.00383689
I0317 09:35:47.164252  3513 solver.cpp:244]     Train net output #0: loss = 0.00383689 (* 1 = 0.00383689 loss)
I0317 09:35:47.164266  3513 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0317 09:35:54.503720  3513 solver.cpp:228] Iteration 14220, loss = 0.00551409
I0317 09:35:54.503792  3513 solver.cpp:244]     Train net output #0: loss = 0.00551409 (* 1 = 0.00551409 loss)
I0317 09:35:54.503805  3513 sgd_solver.cpp:106] Iteration 14220, lr = 0.01
I0317 09:36:01.833243  3513 solver.cpp:228] Iteration 14240, loss = 0.00644782
I0317 09:36:01.833310  3513 solver.cpp:244]     Train net output #0: loss = 0.00644782 (* 1 = 0.00644782 loss)
I0317 09:36:01.833324  3513 sgd_solver.cpp:106] Iteration 14240, lr = 0.01
I0317 09:36:05.129189  3513 solver.cpp:337] Iteration 14250, Testing net (#0)
I0317 09:37:59.022996  3513 solver.cpp:404]     Test net output #0: loss = 0.0645032 (* 1 = 0.0645032 loss)
I0317 09:37:59.023106  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 09:38:02.967582  3513 solver.cpp:228] Iteration 14260, loss = 0.00413112
I0317 09:38:02.967653  3513 solver.cpp:244]     Train net output #0: loss = 0.00413112 (* 1 = 0.00413112 loss)
I0317 09:38:02.967666  3513 sgd_solver.cpp:106] Iteration 14260, lr = 0.01
I0317 09:38:10.235075  3513 solver.cpp:228] Iteration 14280, loss = 0.00767726
I0317 09:38:10.235152  3513 solver.cpp:244]     Train net output #0: loss = 0.00767726 (* 1 = 0.00767726 loss)
I0317 09:38:10.235167  3513 sgd_solver.cpp:106] Iteration 14280, lr = 0.01
I0317 09:38:17.532817  3513 solver.cpp:228] Iteration 14300, loss = 0.00572144
I0317 09:38:17.532888  3513 solver.cpp:244]     Train net output #0: loss = 0.00572144 (* 1 = 0.00572144 loss)
I0317 09:38:17.532902  3513 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0317 09:38:24.853344  3513 solver.cpp:228] Iteration 14320, loss = 0.00688887
I0317 09:38:24.853418  3513 solver.cpp:244]     Train net output #0: loss = 0.00688886 (* 1 = 0.00688886 loss)
I0317 09:38:24.853432  3513 sgd_solver.cpp:106] Iteration 14320, lr = 0.01
I0317 09:38:32.178952  3513 solver.cpp:228] Iteration 14340, loss = 0.00629122
I0317 09:38:32.179154  3513 solver.cpp:244]     Train net output #0: loss = 0.00629122 (* 1 = 0.00629122 loss)
I0317 09:38:32.179169  3513 sgd_solver.cpp:106] Iteration 14340, lr = 0.01
I0317 09:38:39.505416  3513 solver.cpp:228] Iteration 14360, loss = 0.003661
I0317 09:38:39.505489  3513 solver.cpp:244]     Train net output #0: loss = 0.003661 (* 1 = 0.003661 loss)
I0317 09:38:39.505503  3513 sgd_solver.cpp:106] Iteration 14360, lr = 0.01
I0317 09:38:46.837036  3513 solver.cpp:228] Iteration 14380, loss = 0.00294814
I0317 09:38:46.837105  3513 solver.cpp:244]     Train net output #0: loss = 0.00294813 (* 1 = 0.00294813 loss)
I0317 09:38:46.837118  3513 sgd_solver.cpp:106] Iteration 14380, lr = 0.01
I0317 09:38:54.166738  3513 solver.cpp:228] Iteration 14400, loss = 0.00471914
I0317 09:38:54.166807  3513 solver.cpp:244]     Train net output #0: loss = 0.00471914 (* 1 = 0.00471914 loss)
I0317 09:38:54.166821  3513 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0317 09:39:01.491264  3513 solver.cpp:228] Iteration 14420, loss = 0.00788225
I0317 09:39:01.491333  3513 solver.cpp:244]     Train net output #0: loss = 0.00788225 (* 1 = 0.00788225 loss)
I0317 09:39:01.491346  3513 sgd_solver.cpp:106] Iteration 14420, lr = 0.01
I0317 09:39:08.799509  3513 solver.cpp:228] Iteration 14440, loss = 0.00482172
I0317 09:39:08.799688  3513 solver.cpp:244]     Train net output #0: loss = 0.00482172 (* 1 = 0.00482172 loss)
I0317 09:39:08.799705  3513 sgd_solver.cpp:106] Iteration 14440, lr = 0.01
I0317 09:39:16.122887  3513 solver.cpp:228] Iteration 14460, loss = 0.010267
I0317 09:39:16.122962  3513 solver.cpp:244]     Train net output #0: loss = 0.010267 (* 1 = 0.010267 loss)
I0317 09:39:16.122982  3513 sgd_solver.cpp:106] Iteration 14460, lr = 0.01
I0317 09:39:23.441377  3513 solver.cpp:228] Iteration 14480, loss = 0.00730588
I0317 09:39:23.441447  3513 solver.cpp:244]     Train net output #0: loss = 0.00730588 (* 1 = 0.00730588 loss)
I0317 09:39:23.441460  3513 sgd_solver.cpp:106] Iteration 14480, lr = 0.01
I0317 09:39:30.398061  3513 solver.cpp:337] Iteration 14500, Testing net (#0)
I0317 09:41:24.258808  3513 solver.cpp:404]     Test net output #0: loss = 0.0661753 (* 1 = 0.0661753 loss)
I0317 09:41:24.258965  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673039 (* 1 = 0.673039 loss)
I0317 09:41:24.596534  3513 solver.cpp:228] Iteration 14500, loss = 0.00567723
I0317 09:41:24.596604  3513 solver.cpp:244]     Train net output #0: loss = 0.00567723 (* 1 = 0.00567723 loss)
I0317 09:41:24.596619  3513 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0317 09:41:31.848244  3513 solver.cpp:228] Iteration 14520, loss = 0.00426427
I0317 09:41:31.848315  3513 solver.cpp:244]     Train net output #0: loss = 0.00426427 (* 1 = 0.00426427 loss)
I0317 09:41:31.848330  3513 sgd_solver.cpp:106] Iteration 14520, lr = 0.01
I0317 09:41:39.143396  3513 solver.cpp:228] Iteration 14540, loss = 0.00493891
I0317 09:41:39.143465  3513 solver.cpp:244]     Train net output #0: loss = 0.00493891 (* 1 = 0.00493891 loss)
I0317 09:41:39.143481  3513 sgd_solver.cpp:106] Iteration 14540, lr = 0.01
I0317 09:41:46.457343  3513 solver.cpp:228] Iteration 14560, loss = 0.00350772
I0317 09:41:46.457412  3513 solver.cpp:244]     Train net output #0: loss = 0.00350772 (* 1 = 0.00350772 loss)
I0317 09:41:46.457425  3513 sgd_solver.cpp:106] Iteration 14560, lr = 0.01
I0317 09:41:53.770946  3513 solver.cpp:228] Iteration 14580, loss = 0.00528356
I0317 09:41:53.771014  3513 solver.cpp:244]     Train net output #0: loss = 0.00528356 (* 1 = 0.00528356 loss)
I0317 09:41:53.771028  3513 sgd_solver.cpp:106] Iteration 14580, lr = 0.01
I0317 09:42:01.092943  3513 solver.cpp:228] Iteration 14600, loss = 0.0064422
I0317 09:42:01.093144  3513 solver.cpp:244]     Train net output #0: loss = 0.0064422 (* 1 = 0.0064422 loss)
I0317 09:42:01.093158  3513 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0317 09:42:08.419294  3513 solver.cpp:228] Iteration 14620, loss = 0.00699099
I0317 09:42:08.419368  3513 solver.cpp:244]     Train net output #0: loss = 0.00699099 (* 1 = 0.00699099 loss)
I0317 09:42:08.419381  3513 sgd_solver.cpp:106] Iteration 14620, lr = 0.01
I0317 09:42:15.750049  3513 solver.cpp:228] Iteration 14640, loss = 0.0100637
I0317 09:42:15.750118  3513 solver.cpp:244]     Train net output #0: loss = 0.0100637 (* 1 = 0.0100637 loss)
I0317 09:42:15.750131  3513 sgd_solver.cpp:106] Iteration 14640, lr = 0.01
I0317 09:42:23.084578  3513 solver.cpp:228] Iteration 14660, loss = 0.00570033
I0317 09:42:23.084647  3513 solver.cpp:244]     Train net output #0: loss = 0.00570033 (* 1 = 0.00570033 loss)
I0317 09:42:23.084661  3513 sgd_solver.cpp:106] Iteration 14660, lr = 0.01
I0317 09:42:30.414575  3513 solver.cpp:228] Iteration 14680, loss = 0.00583138
I0317 09:42:30.414646  3513 solver.cpp:244]     Train net output #0: loss = 0.00583138 (* 1 = 0.00583138 loss)
I0317 09:42:30.414659  3513 sgd_solver.cpp:106] Iteration 14680, lr = 0.01
I0317 09:42:37.744135  3513 solver.cpp:228] Iteration 14700, loss = 0.00430889
I0317 09:42:37.744297  3513 solver.cpp:244]     Train net output #0: loss = 0.00430889 (* 1 = 0.00430889 loss)
I0317 09:42:37.744312  3513 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0317 09:42:45.064503  3513 solver.cpp:228] Iteration 14720, loss = 0.00335103
I0317 09:42:45.064565  3513 solver.cpp:244]     Train net output #0: loss = 0.00335103 (* 1 = 0.00335103 loss)
I0317 09:42:45.064579  3513 sgd_solver.cpp:106] Iteration 14720, lr = 0.01
I0317 09:42:52.384244  3513 solver.cpp:228] Iteration 14740, loss = 0.00544157
I0317 09:42:52.384310  3513 solver.cpp:244]     Train net output #0: loss = 0.00544157 (* 1 = 0.00544157 loss)
I0317 09:42:52.384322  3513 sgd_solver.cpp:106] Iteration 14740, lr = 0.01
I0317 09:42:55.673451  3513 solver.cpp:337] Iteration 14750, Testing net (#0)
I0317 09:44:49.546296  3513 solver.cpp:404]     Test net output #0: loss = 0.0641217 (* 1 = 0.0641217 loss)
I0317 09:44:49.546414  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 09:44:53.490355  3513 solver.cpp:228] Iteration 14760, loss = 0.00352706
I0317 09:44:53.490422  3513 solver.cpp:244]     Train net output #0: loss = 0.00352706 (* 1 = 0.00352706 loss)
I0317 09:44:53.490437  3513 sgd_solver.cpp:106] Iteration 14760, lr = 0.01
I0317 09:45:00.760866  3513 solver.cpp:228] Iteration 14780, loss = 0.00431204
I0317 09:45:00.760943  3513 solver.cpp:244]     Train net output #0: loss = 0.00431204 (* 1 = 0.00431204 loss)
I0317 09:45:00.760957  3513 sgd_solver.cpp:106] Iteration 14780, lr = 0.01
I0317 09:45:08.070869  3513 solver.cpp:228] Iteration 14800, loss = 0.00341925
I0317 09:45:08.070940  3513 solver.cpp:244]     Train net output #0: loss = 0.00341925 (* 1 = 0.00341925 loss)
I0317 09:45:08.070955  3513 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0317 09:45:15.396420  3513 solver.cpp:228] Iteration 14820, loss = 0.00790647
I0317 09:45:15.396489  3513 solver.cpp:244]     Train net output #0: loss = 0.00790647 (* 1 = 0.00790647 loss)
I0317 09:45:15.396503  3513 sgd_solver.cpp:106] Iteration 14820, lr = 0.01
I0317 09:45:22.731612  3513 solver.cpp:228] Iteration 14840, loss = 0.00835085
I0317 09:45:22.731765  3513 solver.cpp:244]     Train net output #0: loss = 0.00835085 (* 1 = 0.00835085 loss)
I0317 09:45:22.731779  3513 sgd_solver.cpp:106] Iteration 14840, lr = 0.01
I0317 09:45:30.062825  3513 solver.cpp:228] Iteration 14860, loss = 0.00711295
I0317 09:45:30.062894  3513 solver.cpp:244]     Train net output #0: loss = 0.00711295 (* 1 = 0.00711295 loss)
I0317 09:45:30.062907  3513 sgd_solver.cpp:106] Iteration 14860, lr = 0.01
I0317 09:45:37.383440  3513 solver.cpp:228] Iteration 14880, loss = 0.00455457
I0317 09:45:37.383512  3513 solver.cpp:244]     Train net output #0: loss = 0.00455457 (* 1 = 0.00455457 loss)
I0317 09:45:37.383524  3513 sgd_solver.cpp:106] Iteration 14880, lr = 0.01
I0317 09:45:44.709723  3513 solver.cpp:228] Iteration 14900, loss = 0.00438577
I0317 09:45:44.709791  3513 solver.cpp:244]     Train net output #0: loss = 0.00438577 (* 1 = 0.00438577 loss)
I0317 09:45:44.709806  3513 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0317 09:45:52.036429  3513 solver.cpp:228] Iteration 14920, loss = 0.00390583
I0317 09:45:52.036509  3513 solver.cpp:244]     Train net output #0: loss = 0.00390583 (* 1 = 0.00390583 loss)
I0317 09:45:52.036525  3513 sgd_solver.cpp:106] Iteration 14920, lr = 0.01
I0317 09:45:59.372949  3513 solver.cpp:228] Iteration 14940, loss = 0.00643402
I0317 09:45:59.373155  3513 solver.cpp:244]     Train net output #0: loss = 0.00643402 (* 1 = 0.00643402 loss)
I0317 09:45:59.373170  3513 sgd_solver.cpp:106] Iteration 14940, lr = 0.01
I0317 09:46:06.705993  3513 solver.cpp:228] Iteration 14960, loss = 0.00673368
I0317 09:46:06.706079  3513 solver.cpp:244]     Train net output #0: loss = 0.00673368 (* 1 = 0.00673368 loss)
I0317 09:46:06.706092  3513 sgd_solver.cpp:106] Iteration 14960, lr = 0.01
I0317 09:46:14.029327  3513 solver.cpp:228] Iteration 14980, loss = 0.00454129
I0317 09:46:14.029394  3513 solver.cpp:244]     Train net output #0: loss = 0.00454129 (* 1 = 0.00454129 loss)
I0317 09:46:14.029408  3513 sgd_solver.cpp:106] Iteration 14980, lr = 0.01
I0317 09:46:20.991479  3513 solver.cpp:454] Snapshotting to binary proto file ./caffe_alexnet_train_iter_15000.caffemodel
I0317 09:46:22.675782  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./caffe_alexnet_train_iter_15000.solverstate
I0317 09:46:23.079367  3513 solver.cpp:337] Iteration 15000, Testing net (#0)
I0317 09:48:16.893996  3513 solver.cpp:404]     Test net output #0: loss = 0.0621475 (* 1 = 0.0621475 loss)
I0317 09:48:16.894143  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65384 (* 1 = 0.65384 loss)
I0317 09:48:17.231068  3513 solver.cpp:228] Iteration 15000, loss = 0.00934514
I0317 09:48:17.231137  3513 solver.cpp:244]     Train net output #0: loss = 0.00934514 (* 1 = 0.00934514 loss)
I0317 09:48:17.231150  3513 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0317 09:48:24.484958  3513 solver.cpp:228] Iteration 15020, loss = 0.00558635
I0317 09:48:24.485029  3513 solver.cpp:244]     Train net output #0: loss = 0.00558635 (* 1 = 0.00558635 loss)
I0317 09:48:24.485044  3513 sgd_solver.cpp:106] Iteration 15020, lr = 0.01
I0317 09:48:31.781296  3513 solver.cpp:228] Iteration 15040, loss = 0.00617174
I0317 09:48:31.781376  3513 solver.cpp:244]     Train net output #0: loss = 0.00617174 (* 1 = 0.00617174 loss)
I0317 09:48:31.781390  3513 sgd_solver.cpp:106] Iteration 15040, lr = 0.01
I0317 09:48:39.096570  3513 solver.cpp:228] Iteration 15060, loss = 0.00433214
I0317 09:48:39.096642  3513 solver.cpp:244]     Train net output #0: loss = 0.00433214 (* 1 = 0.00433214 loss)
I0317 09:48:39.096657  3513 sgd_solver.cpp:106] Iteration 15060, lr = 0.01
I0317 09:48:46.415844  3513 solver.cpp:228] Iteration 15080, loss = 0.00278086
I0317 09:48:46.415911  3513 solver.cpp:244]     Train net output #0: loss = 0.00278086 (* 1 = 0.00278086 loss)
I0317 09:48:46.415925  3513 sgd_solver.cpp:106] Iteration 15080, lr = 0.01
I0317 09:48:53.737452  3513 solver.cpp:228] Iteration 15100, loss = 0.00266151
I0317 09:48:53.737607  3513 solver.cpp:244]     Train net output #0: loss = 0.00266152 (* 1 = 0.00266152 loss)
I0317 09:48:53.737620  3513 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0317 09:49:01.063328  3513 solver.cpp:228] Iteration 15120, loss = 0.00403877
I0317 09:49:01.063397  3513 solver.cpp:244]     Train net output #0: loss = 0.00403877 (* 1 = 0.00403877 loss)
I0317 09:49:01.063410  3513 sgd_solver.cpp:106] Iteration 15120, lr = 0.01
I0317 09:49:08.389331  3513 solver.cpp:228] Iteration 15140, loss = 0.00706161
I0317 09:49:08.389397  3513 solver.cpp:244]     Train net output #0: loss = 0.00706161 (* 1 = 0.00706161 loss)
I0317 09:49:08.389411  3513 sgd_solver.cpp:106] Iteration 15140, lr = 0.01
I0317 09:49:15.722106  3513 solver.cpp:228] Iteration 15160, loss = 0.00536505
I0317 09:49:15.722175  3513 solver.cpp:244]     Train net output #0: loss = 0.00536505 (* 1 = 0.00536505 loss)
I0317 09:49:15.722189  3513 sgd_solver.cpp:106] Iteration 15160, lr = 0.01
I0317 09:49:23.059491  3513 solver.cpp:228] Iteration 15180, loss = 0.00964202
I0317 09:49:23.059561  3513 solver.cpp:244]     Train net output #0: loss = 0.00964202 (* 1 = 0.00964202 loss)
I0317 09:49:23.059574  3513 sgd_solver.cpp:106] Iteration 15180, lr = 0.01
I0317 09:49:30.392606  3513 solver.cpp:228] Iteration 15200, loss = 0.00580395
I0317 09:49:30.392799  3513 solver.cpp:244]     Train net output #0: loss = 0.00580395 (* 1 = 0.00580395 loss)
I0317 09:49:30.392814  3513 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0317 09:49:37.716194  3513 solver.cpp:228] Iteration 15220, loss = 0.00583514
I0317 09:49:37.716262  3513 solver.cpp:244]     Train net output #0: loss = 0.00583515 (* 1 = 0.00583515 loss)
I0317 09:49:37.716275  3513 sgd_solver.cpp:106] Iteration 15220, lr = 0.01
I0317 09:49:45.038794  3513 solver.cpp:228] Iteration 15240, loss = 0.0027949
I0317 09:49:45.038858  3513 solver.cpp:244]     Train net output #0: loss = 0.0027949 (* 1 = 0.0027949 loss)
I0317 09:49:45.038872  3513 sgd_solver.cpp:106] Iteration 15240, lr = 0.01
I0317 09:49:48.335211  3513 solver.cpp:337] Iteration 15250, Testing net (#0)
I0317 09:51:42.216753  3513 solver.cpp:404]     Test net output #0: loss = 0.0642754 (* 1 = 0.0642754 loss)
I0317 09:51:42.216892  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6634 (* 1 = 0.6634 loss)
I0317 09:51:46.157713  3513 solver.cpp:228] Iteration 15260, loss = 0.00268983
I0317 09:51:46.157783  3513 solver.cpp:244]     Train net output #0: loss = 0.00268983 (* 1 = 0.00268983 loss)
I0317 09:51:46.157796  3513 sgd_solver.cpp:106] Iteration 15260, lr = 0.01
I0317 09:51:53.426636  3513 solver.cpp:228] Iteration 15280, loss = 0.0042952
I0317 09:51:53.426704  3513 solver.cpp:244]     Train net output #0: loss = 0.0042952 (* 1 = 0.0042952 loss)
I0317 09:51:53.426718  3513 sgd_solver.cpp:106] Iteration 15280, lr = 0.01
I0317 09:52:00.734866  3513 solver.cpp:228] Iteration 15300, loss = 0.00433932
I0317 09:52:00.734935  3513 solver.cpp:244]     Train net output #0: loss = 0.00433932 (* 1 = 0.00433932 loss)
I0317 09:52:00.734948  3513 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0317 09:52:08.059715  3513 solver.cpp:228] Iteration 15320, loss = 0.00379704
I0317 09:52:08.059780  3513 solver.cpp:244]     Train net output #0: loss = 0.00379704 (* 1 = 0.00379704 loss)
I0317 09:52:08.059794  3513 sgd_solver.cpp:106] Iteration 15320, lr = 0.01
I0317 09:52:15.388541  3513 solver.cpp:228] Iteration 15340, loss = 0.00342594
I0317 09:52:15.388717  3513 solver.cpp:244]     Train net output #0: loss = 0.00342595 (* 1 = 0.00342595 loss)
I0317 09:52:15.388731  3513 sgd_solver.cpp:106] Iteration 15340, lr = 0.01
I0317 09:52:22.721518  3513 solver.cpp:228] Iteration 15360, loss = 0.0082397
I0317 09:52:22.721582  3513 solver.cpp:244]     Train net output #0: loss = 0.0082397 (* 1 = 0.0082397 loss)
I0317 09:52:22.721596  3513 sgd_solver.cpp:106] Iteration 15360, lr = 0.01
I0317 09:52:30.051532  3513 solver.cpp:228] Iteration 15380, loss = 0.00663581
I0317 09:52:30.051601  3513 solver.cpp:244]     Train net output #0: loss = 0.00663581 (* 1 = 0.00663581 loss)
I0317 09:52:30.051615  3513 sgd_solver.cpp:106] Iteration 15380, lr = 0.01
I0317 09:52:37.382388  3513 solver.cpp:228] Iteration 15400, loss = 0.00711614
I0317 09:52:37.382452  3513 solver.cpp:244]     Train net output #0: loss = 0.00711614 (* 1 = 0.00711614 loss)
I0317 09:52:37.382465  3513 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0317 09:52:44.719673  3513 solver.cpp:228] Iteration 15420, loss = 0.00574726
I0317 09:52:44.719753  3513 solver.cpp:244]     Train net output #0: loss = 0.00574726 (* 1 = 0.00574726 loss)
I0317 09:52:44.719779  3513 sgd_solver.cpp:106] Iteration 15420, lr = 0.01
I0317 09:52:52.055213  3513 solver.cpp:228] Iteration 15440, loss = 0.00301459
I0317 09:52:52.055421  3513 solver.cpp:244]     Train net output #0: loss = 0.00301459 (* 1 = 0.00301459 loss)
I0317 09:52:52.055436  3513 sgd_solver.cpp:106] Iteration 15440, lr = 0.01
I0317 09:52:59.386659  3513 solver.cpp:228] Iteration 15460, loss = 0.00436407
I0317 09:52:59.386723  3513 solver.cpp:244]     Train net output #0: loss = 0.00436407 (* 1 = 0.00436407 loss)
I0317 09:52:59.386736  3513 sgd_solver.cpp:106] Iteration 15460, lr = 0.01
I0317 09:53:06.725715  3513 solver.cpp:228] Iteration 15480, loss = 0.00725075
I0317 09:53:06.725785  3513 solver.cpp:244]     Train net output #0: loss = 0.00725075 (* 1 = 0.00725075 loss)
I0317 09:53:06.725798  3513 sgd_solver.cpp:106] Iteration 15480, lr = 0.01
I0317 09:53:13.694907  3513 solver.cpp:337] Iteration 15500, Testing net (#0)
I0317 09:55:07.569978  3513 solver.cpp:404]     Test net output #0: loss = 0.0631559 (* 1 = 0.0631559 loss)
I0317 09:55:07.570116  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673199 (* 1 = 0.673199 loss)
I0317 09:55:07.905766  3513 solver.cpp:228] Iteration 15500, loss = 0.00752168
I0317 09:55:07.905833  3513 solver.cpp:244]     Train net output #0: loss = 0.00752169 (* 1 = 0.00752169 loss)
I0317 09:55:07.905846  3513 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0317 09:55:15.144804  3513 solver.cpp:228] Iteration 15520, loss = 0.00514853
I0317 09:55:15.144870  3513 solver.cpp:244]     Train net output #0: loss = 0.00514854 (* 1 = 0.00514854 loss)
I0317 09:55:15.144884  3513 sgd_solver.cpp:106] Iteration 15520, lr = 0.01
I0317 09:55:22.439651  3513 solver.cpp:228] Iteration 15540, loss = 0.00839124
I0317 09:55:22.439719  3513 solver.cpp:244]     Train net output #0: loss = 0.00839124 (* 1 = 0.00839124 loss)
I0317 09:55:22.439733  3513 sgd_solver.cpp:106] Iteration 15540, lr = 0.01
I0317 09:55:29.753792  3513 solver.cpp:228] Iteration 15560, loss = 0.00639867
I0317 09:55:29.753859  3513 solver.cpp:244]     Train net output #0: loss = 0.00639868 (* 1 = 0.00639868 loss)
I0317 09:55:29.753873  3513 sgd_solver.cpp:106] Iteration 15560, lr = 0.01
I0317 09:55:37.081938  3513 solver.cpp:228] Iteration 15580, loss = 0.00691482
I0317 09:55:37.082007  3513 solver.cpp:244]     Train net output #0: loss = 0.00691482 (* 1 = 0.00691482 loss)
I0317 09:55:37.082020  3513 sgd_solver.cpp:106] Iteration 15580, lr = 0.01
I0317 09:55:44.416721  3513 solver.cpp:228] Iteration 15600, loss = 0.00254668
I0317 09:55:44.416867  3513 solver.cpp:244]     Train net output #0: loss = 0.00254668 (* 1 = 0.00254668 loss)
I0317 09:55:44.416882  3513 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0317 09:55:51.751794  3513 solver.cpp:228] Iteration 15620, loss = 0.00303854
I0317 09:55:51.751863  3513 solver.cpp:244]     Train net output #0: loss = 0.00303854 (* 1 = 0.00303854 loss)
I0317 09:55:51.751879  3513 sgd_solver.cpp:106] Iteration 15620, lr = 0.01
I0317 09:55:59.077527  3513 solver.cpp:228] Iteration 15640, loss = 0.00258547
I0317 09:55:59.077592  3513 solver.cpp:244]     Train net output #0: loss = 0.00258548 (* 1 = 0.00258548 loss)
I0317 09:55:59.077606  3513 sgd_solver.cpp:106] Iteration 15640, lr = 0.01
I0317 09:56:06.404623  3513 solver.cpp:228] Iteration 15660, loss = 0.00662167
I0317 09:56:06.404690  3513 solver.cpp:244]     Train net output #0: loss = 0.00662167 (* 1 = 0.00662167 loss)
I0317 09:56:06.404703  3513 sgd_solver.cpp:106] Iteration 15660, lr = 0.01
I0317 09:56:13.732246  3513 solver.cpp:228] Iteration 15680, loss = 0.00863262
I0317 09:56:13.732316  3513 solver.cpp:244]     Train net output #0: loss = 0.00863263 (* 1 = 0.00863263 loss)
I0317 09:56:13.732329  3513 sgd_solver.cpp:106] Iteration 15680, lr = 0.01
I0317 09:56:21.064385  3513 solver.cpp:228] Iteration 15700, loss = 0.00384561
I0317 09:56:21.064479  3513 solver.cpp:244]     Train net output #0: loss = 0.00384561 (* 1 = 0.00384561 loss)
I0317 09:56:21.064492  3513 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0317 09:56:28.394361  3513 solver.cpp:228] Iteration 15720, loss = 0.0072685
I0317 09:56:28.394430  3513 solver.cpp:244]     Train net output #0: loss = 0.0072685 (* 1 = 0.0072685 loss)
I0317 09:56:28.394444  3513 sgd_solver.cpp:106] Iteration 15720, lr = 0.01
I0317 09:56:35.722899  3513 solver.cpp:228] Iteration 15740, loss = 0.00781028
I0317 09:56:35.722975  3513 solver.cpp:244]     Train net output #0: loss = 0.00781028 (* 1 = 0.00781028 loss)
I0317 09:56:35.722988  3513 sgd_solver.cpp:106] Iteration 15740, lr = 0.01
I0317 09:56:39.024463  3513 solver.cpp:337] Iteration 15750, Testing net (#0)
I0317 09:58:32.903980  3513 solver.cpp:404]     Test net output #0: loss = 0.0625193 (* 1 = 0.0625193 loss)
I0317 09:58:32.904165  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66336 (* 1 = 0.66336 loss)
I0317 09:58:36.848052  3513 solver.cpp:228] Iteration 15760, loss = 0.00466578
I0317 09:58:36.848117  3513 solver.cpp:244]     Train net output #0: loss = 0.00466578 (* 1 = 0.00466578 loss)
I0317 09:58:36.848130  3513 sgd_solver.cpp:106] Iteration 15760, lr = 0.01
I0317 09:58:44.114096  3513 solver.cpp:228] Iteration 15780, loss = 0.00237233
I0317 09:58:44.114166  3513 solver.cpp:244]     Train net output #0: loss = 0.00237233 (* 1 = 0.00237233 loss)
I0317 09:58:44.114179  3513 sgd_solver.cpp:106] Iteration 15780, lr = 0.01
I0317 09:58:51.419883  3513 solver.cpp:228] Iteration 15800, loss = 0.00316314
I0317 09:58:51.419961  3513 solver.cpp:244]     Train net output #0: loss = 0.00316315 (* 1 = 0.00316315 loss)
I0317 09:58:51.419976  3513 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0317 09:58:58.743376  3513 solver.cpp:228] Iteration 15820, loss = 0.00433601
I0317 09:58:58.743443  3513 solver.cpp:244]     Train net output #0: loss = 0.00433602 (* 1 = 0.00433602 loss)
I0317 09:58:58.743456  3513 sgd_solver.cpp:106] Iteration 15820, lr = 0.01
I0317 09:59:06.068174  3513 solver.cpp:228] Iteration 15840, loss = 0.00335485
I0317 09:59:06.068326  3513 solver.cpp:244]     Train net output #0: loss = 0.00335486 (* 1 = 0.00335486 loss)
I0317 09:59:06.068341  3513 sgd_solver.cpp:106] Iteration 15840, lr = 0.01
I0317 09:59:13.401039  3513 solver.cpp:228] Iteration 15860, loss = 0.00710712
I0317 09:59:13.401111  3513 solver.cpp:244]     Train net output #0: loss = 0.00710712 (* 1 = 0.00710712 loss)
I0317 09:59:13.401124  3513 sgd_solver.cpp:106] Iteration 15860, lr = 0.01
I0317 09:59:20.730038  3513 solver.cpp:228] Iteration 15880, loss = 0.00448682
I0317 09:59:20.730111  3513 solver.cpp:244]     Train net output #0: loss = 0.00448682 (* 1 = 0.00448682 loss)
I0317 09:59:20.730125  3513 sgd_solver.cpp:106] Iteration 15880, lr = 0.01
I0317 09:59:28.057346  3513 solver.cpp:228] Iteration 15900, loss = 0.0066893
I0317 09:59:28.057413  3513 solver.cpp:244]     Train net output #0: loss = 0.0066893 (* 1 = 0.0066893 loss)
I0317 09:59:28.057428  3513 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0317 09:59:35.383185  3513 solver.cpp:228] Iteration 15920, loss = 0.0104229
I0317 09:59:35.383255  3513 solver.cpp:244]     Train net output #0: loss = 0.0104229 (* 1 = 0.0104229 loss)
I0317 09:59:35.383268  3513 sgd_solver.cpp:106] Iteration 15920, lr = 0.01
I0317 09:59:42.715682  3513 solver.cpp:228] Iteration 15940, loss = 0.00779616
I0317 09:59:42.715840  3513 solver.cpp:244]     Train net output #0: loss = 0.00779617 (* 1 = 0.00779617 loss)
I0317 09:59:42.715854  3513 sgd_solver.cpp:106] Iteration 15940, lr = 0.01
I0317 09:59:50.042034  3513 solver.cpp:228] Iteration 15960, loss = 0.00430964
I0317 09:59:50.042101  3513 solver.cpp:244]     Train net output #0: loss = 0.00430965 (* 1 = 0.00430965 loss)
I0317 09:59:50.042115  3513 sgd_solver.cpp:106] Iteration 15960, lr = 0.01
I0317 09:59:57.365382  3513 solver.cpp:228] Iteration 15980, loss = 0.00393294
I0317 09:59:57.365453  3513 solver.cpp:244]     Train net output #0: loss = 0.00393295 (* 1 = 0.00393295 loss)
I0317 09:59:57.365468  3513 sgd_solver.cpp:106] Iteration 15980, lr = 0.01
I0317 10:00:04.324235  3513 solver.cpp:337] Iteration 16000, Testing net (#0)
I0317 10:01:58.206611  3513 solver.cpp:404]     Test net output #0: loss = 0.0623735 (* 1 = 0.0623735 loss)
I0317 10:01:58.206807  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.69228 (* 1 = 0.69228 loss)
I0317 10:01:58.542696  3513 solver.cpp:228] Iteration 16000, loss = 0.00583607
I0317 10:01:58.542764  3513 solver.cpp:244]     Train net output #0: loss = 0.00583607 (* 1 = 0.00583607 loss)
I0317 10:01:58.542778  3513 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0317 10:02:05.774977  3513 solver.cpp:228] Iteration 16020, loss = 0.00498002
I0317 10:02:05.775056  3513 solver.cpp:244]     Train net output #0: loss = 0.00498003 (* 1 = 0.00498003 loss)
I0317 10:02:05.775069  3513 sgd_solver.cpp:106] Iteration 16020, lr = 0.01
I0317 10:02:13.053493  3513 solver.cpp:228] Iteration 16040, loss = 0.00654867
I0317 10:02:13.053562  3513 solver.cpp:244]     Train net output #0: loss = 0.00654868 (* 1 = 0.00654868 loss)
I0317 10:02:13.053576  3513 sgd_solver.cpp:106] Iteration 16040, lr = 0.01
I0317 10:02:20.370122  3513 solver.cpp:228] Iteration 16060, loss = 0.00618494
I0317 10:02:20.370194  3513 solver.cpp:244]     Train net output #0: loss = 0.00618495 (* 1 = 0.00618495 loss)
I0317 10:02:20.370209  3513 sgd_solver.cpp:106] Iteration 16060, lr = 0.01
I0317 10:02:27.696485  3513 solver.cpp:228] Iteration 16080, loss = 0.0123105
I0317 10:02:27.696550  3513 solver.cpp:244]     Train net output #0: loss = 0.0123105 (* 1 = 0.0123105 loss)
I0317 10:02:27.696563  3513 sgd_solver.cpp:106] Iteration 16080, lr = 0.01
I0317 10:02:35.026935  3513 solver.cpp:228] Iteration 16100, loss = 0.00581341
I0317 10:02:35.027109  3513 solver.cpp:244]     Train net output #0: loss = 0.00581342 (* 1 = 0.00581342 loss)
I0317 10:02:35.027124  3513 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0317 10:02:42.348206  3513 solver.cpp:228] Iteration 16120, loss = 0.00576207
I0317 10:02:42.348274  3513 solver.cpp:244]     Train net output #0: loss = 0.00576208 (* 1 = 0.00576208 loss)
I0317 10:02:42.348287  3513 sgd_solver.cpp:106] Iteration 16120, lr = 0.01
I0317 10:02:49.666283  3513 solver.cpp:228] Iteration 16140, loss = 0.00198667
I0317 10:02:49.666347  3513 solver.cpp:244]     Train net output #0: loss = 0.00198668 (* 1 = 0.00198668 loss)
I0317 10:02:49.666362  3513 sgd_solver.cpp:106] Iteration 16140, lr = 0.01
I0317 10:02:56.993630  3513 solver.cpp:228] Iteration 16160, loss = 0.00322984
I0317 10:02:56.993698  3513 solver.cpp:244]     Train net output #0: loss = 0.00322985 (* 1 = 0.00322985 loss)
I0317 10:02:56.993711  3513 sgd_solver.cpp:106] Iteration 16160, lr = 0.01
I0317 10:03:04.317505  3513 solver.cpp:228] Iteration 16180, loss = 0.00458911
I0317 10:03:04.317569  3513 solver.cpp:244]     Train net output #0: loss = 0.00458912 (* 1 = 0.00458912 loss)
I0317 10:03:04.317582  3513 sgd_solver.cpp:106] Iteration 16180, lr = 0.01
I0317 10:03:11.645001  3513 solver.cpp:228] Iteration 16200, loss = 0.00482952
I0317 10:03:11.645160  3513 solver.cpp:244]     Train net output #0: loss = 0.00482953 (* 1 = 0.00482953 loss)
I0317 10:03:11.645174  3513 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0317 10:03:18.969601  3513 solver.cpp:228] Iteration 16220, loss = 0.00955982
I0317 10:03:18.969665  3513 solver.cpp:244]     Train net output #0: loss = 0.00955983 (* 1 = 0.00955983 loss)
I0317 10:03:18.969676  3513 sgd_solver.cpp:106] Iteration 16220, lr = 0.01
I0317 10:03:26.294721  3513 solver.cpp:228] Iteration 16240, loss = 0.00375916
I0317 10:03:26.294790  3513 solver.cpp:244]     Train net output #0: loss = 0.00375917 (* 1 = 0.00375917 loss)
I0317 10:03:26.294805  3513 sgd_solver.cpp:106] Iteration 16240, lr = 0.01
I0317 10:03:29.588423  3513 solver.cpp:337] Iteration 16250, Testing net (#0)
I0317 10:05:23.443838  3513 solver.cpp:404]     Test net output #0: loss = 0.0638392 (* 1 = 0.0638392 loss)
I0317 10:05:23.443977  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.682799 (* 1 = 0.682799 loss)
I0317 10:05:27.401401  3513 solver.cpp:228] Iteration 16260, loss = 0.00776502
I0317 10:05:27.401469  3513 solver.cpp:244]     Train net output #0: loss = 0.00776503 (* 1 = 0.00776503 loss)
I0317 10:05:27.401484  3513 sgd_solver.cpp:106] Iteration 16260, lr = 0.01
I0317 10:05:34.681145  3513 solver.cpp:228] Iteration 16280, loss = 0.00618297
I0317 10:05:34.681218  3513 solver.cpp:244]     Train net output #0: loss = 0.00618298 (* 1 = 0.00618298 loss)
I0317 10:05:34.681231  3513 sgd_solver.cpp:106] Iteration 16280, lr = 0.01
I0317 10:05:41.980422  3513 solver.cpp:228] Iteration 16300, loss = 0.00537912
I0317 10:05:41.980494  3513 solver.cpp:244]     Train net output #0: loss = 0.00537913 (* 1 = 0.00537913 loss)
I0317 10:05:41.980509  3513 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0317 10:05:49.306833  3513 solver.cpp:228] Iteration 16320, loss = 0.00446082
I0317 10:05:49.306901  3513 solver.cpp:244]     Train net output #0: loss = 0.00446083 (* 1 = 0.00446083 loss)
I0317 10:05:49.306915  3513 sgd_solver.cpp:106] Iteration 16320, lr = 0.01
I0317 10:05:56.628146  3513 solver.cpp:228] Iteration 16340, loss = 0.00289511
I0317 10:05:56.628340  3513 solver.cpp:244]     Train net output #0: loss = 0.00289512 (* 1 = 0.00289512 loss)
I0317 10:05:56.628355  3513 sgd_solver.cpp:106] Iteration 16340, lr = 0.01
I0317 10:06:03.956446  3513 solver.cpp:228] Iteration 16360, loss = 0.00287413
I0317 10:06:03.956516  3513 solver.cpp:244]     Train net output #0: loss = 0.00287414 (* 1 = 0.00287414 loss)
I0317 10:06:03.956528  3513 sgd_solver.cpp:106] Iteration 16360, lr = 0.01
I0317 10:06:11.295295  3513 solver.cpp:228] Iteration 16380, loss = 0.00351545
I0317 10:06:11.295366  3513 solver.cpp:244]     Train net output #0: loss = 0.00351546 (* 1 = 0.00351546 loss)
I0317 10:06:11.295379  3513 sgd_solver.cpp:106] Iteration 16380, lr = 0.01
I0317 10:06:18.633882  3513 solver.cpp:228] Iteration 16400, loss = 0.00836555
I0317 10:06:18.633950  3513 solver.cpp:244]     Train net output #0: loss = 0.00836555 (* 1 = 0.00836555 loss)
I0317 10:06:18.633962  3513 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0317 10:06:25.965704  3513 solver.cpp:228] Iteration 16420, loss = 0.00637729
I0317 10:06:25.965772  3513 solver.cpp:244]     Train net output #0: loss = 0.00637729 (* 1 = 0.00637729 loss)
I0317 10:06:25.965785  3513 sgd_solver.cpp:106] Iteration 16420, lr = 0.01
I0317 10:06:33.295944  3513 solver.cpp:228] Iteration 16440, loss = 0.00546618
I0317 10:06:33.296098  3513 solver.cpp:244]     Train net output #0: loss = 0.00546619 (* 1 = 0.00546619 loss)
I0317 10:06:33.296113  3513 sgd_solver.cpp:106] Iteration 16440, lr = 0.01
I0317 10:06:40.614466  3513 solver.cpp:228] Iteration 16460, loss = 0.00700257
I0317 10:06:40.614529  3513 solver.cpp:244]     Train net output #0: loss = 0.00700257 (* 1 = 0.00700257 loss)
I0317 10:06:40.614542  3513 sgd_solver.cpp:106] Iteration 16460, lr = 0.01
I0317 10:06:47.936636  3513 solver.cpp:228] Iteration 16480, loss = 0.00724914
I0317 10:06:47.936712  3513 solver.cpp:244]     Train net output #0: loss = 0.00724915 (* 1 = 0.00724915 loss)
I0317 10:06:47.936723  3513 sgd_solver.cpp:106] Iteration 16480, lr = 0.01
I0317 10:06:54.899003  3513 solver.cpp:337] Iteration 16500, Testing net (#0)
I0317 10:08:48.748672  3513 solver.cpp:404]     Test net output #0: loss = 0.0596378 (* 1 = 0.0596378 loss)
I0317 10:08:48.748813  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66336 (* 1 = 0.66336 loss)
I0317 10:08:49.086802  3513 solver.cpp:228] Iteration 16500, loss = 0.00370749
I0317 10:08:49.086863  3513 solver.cpp:244]     Train net output #0: loss = 0.0037075 (* 1 = 0.0037075 loss)
I0317 10:08:49.086876  3513 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0317 10:08:56.331250  3513 solver.cpp:228] Iteration 16520, loss = 0.00237024
I0317 10:08:56.331317  3513 solver.cpp:244]     Train net output #0: loss = 0.00237024 (* 1 = 0.00237024 loss)
I0317 10:08:56.331331  3513 sgd_solver.cpp:106] Iteration 16520, lr = 0.01
I0317 10:09:03.624670  3513 solver.cpp:228] Iteration 16540, loss = 0.00241765
I0317 10:09:03.624752  3513 solver.cpp:244]     Train net output #0: loss = 0.00241765 (* 1 = 0.00241765 loss)
I0317 10:09:03.624765  3513 sgd_solver.cpp:106] Iteration 16540, lr = 0.01
I0317 10:09:10.927873  3513 solver.cpp:228] Iteration 16560, loss = 0.0034495
I0317 10:09:10.927942  3513 solver.cpp:244]     Train net output #0: loss = 0.00344951 (* 1 = 0.00344951 loss)
I0317 10:09:10.927955  3513 sgd_solver.cpp:106] Iteration 16560, lr = 0.01
I0317 10:09:18.250285  3513 solver.cpp:228] Iteration 16580, loss = 0.00861925
I0317 10:09:18.250355  3513 solver.cpp:244]     Train net output #0: loss = 0.00861926 (* 1 = 0.00861926 loss)
I0317 10:09:18.250377  3513 sgd_solver.cpp:106] Iteration 16580, lr = 0.01
I0317 10:09:25.579823  3513 solver.cpp:228] Iteration 16600, loss = 0.00347081
I0317 10:09:25.580027  3513 solver.cpp:244]     Train net output #0: loss = 0.00347082 (* 1 = 0.00347082 loss)
I0317 10:09:25.580050  3513 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0317 10:09:32.903578  3513 solver.cpp:228] Iteration 16620, loss = 0.00610684
I0317 10:09:32.903645  3513 solver.cpp:244]     Train net output #0: loss = 0.00610685 (* 1 = 0.00610685 loss)
I0317 10:09:32.903658  3513 sgd_solver.cpp:106] Iteration 16620, lr = 0.01
I0317 10:09:40.224521  3513 solver.cpp:228] Iteration 16640, loss = 0.00446811
I0317 10:09:40.224587  3513 solver.cpp:244]     Train net output #0: loss = 0.00446812 (* 1 = 0.00446812 loss)
I0317 10:09:40.224601  3513 sgd_solver.cpp:106] Iteration 16640, lr = 0.01
I0317 10:09:47.552173  3513 solver.cpp:228] Iteration 16660, loss = 0.00605191
I0317 10:09:47.552243  3513 solver.cpp:244]     Train net output #0: loss = 0.00605192 (* 1 = 0.00605192 loss)
I0317 10:09:47.552256  3513 sgd_solver.cpp:106] Iteration 16660, lr = 0.01
I0317 10:09:54.874377  3513 solver.cpp:228] Iteration 16680, loss = 0.00379043
I0317 10:09:54.874440  3513 solver.cpp:244]     Train net output #0: loss = 0.00379044 (* 1 = 0.00379044 loss)
I0317 10:09:54.874454  3513 sgd_solver.cpp:106] Iteration 16680, lr = 0.01
I0317 10:10:02.201810  3513 solver.cpp:228] Iteration 16700, loss = 0.00385389
I0317 10:10:02.201951  3513 solver.cpp:244]     Train net output #0: loss = 0.0038539 (* 1 = 0.0038539 loss)
I0317 10:10:02.201964  3513 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0317 10:10:09.527263  3513 solver.cpp:228] Iteration 16720, loss = 0.00415025
I0317 10:10:09.527339  3513 solver.cpp:244]     Train net output #0: loss = 0.00415025 (* 1 = 0.00415025 loss)
I0317 10:10:09.527354  3513 sgd_solver.cpp:106] Iteration 16720, lr = 0.01
I0317 10:10:16.838819  3513 solver.cpp:228] Iteration 16740, loss = 0.00384457
I0317 10:10:16.838886  3513 solver.cpp:244]     Train net output #0: loss = 0.00384458 (* 1 = 0.00384458 loss)
I0317 10:10:16.838899  3513 sgd_solver.cpp:106] Iteration 16740, lr = 0.01
I0317 10:10:20.136044  3513 solver.cpp:337] Iteration 16750, Testing net (#0)
I0317 10:12:14.002910  3513 solver.cpp:404]     Test net output #0: loss = 0.0630066 (* 1 = 0.0630066 loss)
I0317 10:12:14.003034  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 10:12:17.952769  3513 solver.cpp:228] Iteration 16760, loss = 0.0059588
I0317 10:12:17.952837  3513 solver.cpp:244]     Train net output #0: loss = 0.0059588 (* 1 = 0.0059588 loss)
I0317 10:12:17.952850  3513 sgd_solver.cpp:106] Iteration 16760, lr = 0.01
I0317 10:12:25.227895  3513 solver.cpp:228] Iteration 16780, loss = 0.00473365
I0317 10:12:25.227962  3513 solver.cpp:244]     Train net output #0: loss = 0.00473366 (* 1 = 0.00473366 loss)
I0317 10:12:25.227974  3513 sgd_solver.cpp:106] Iteration 16780, lr = 0.01
I0317 10:12:32.520304  3513 solver.cpp:228] Iteration 16800, loss = 0.00814982
I0317 10:12:32.520370  3513 solver.cpp:244]     Train net output #0: loss = 0.00814983 (* 1 = 0.00814983 loss)
I0317 10:12:32.520385  3513 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0317 10:12:39.833300  3513 solver.cpp:228] Iteration 16820, loss = 0.00554325
I0317 10:12:39.833369  3513 solver.cpp:244]     Train net output #0: loss = 0.00554326 (* 1 = 0.00554326 loss)
I0317 10:12:39.833382  3513 sgd_solver.cpp:106] Iteration 16820, lr = 0.01
I0317 10:12:47.165268  3513 solver.cpp:228] Iteration 16840, loss = 0.00678526
I0317 10:12:47.165390  3513 solver.cpp:244]     Train net output #0: loss = 0.00678527 (* 1 = 0.00678527 loss)
I0317 10:12:47.165405  3513 sgd_solver.cpp:106] Iteration 16840, lr = 0.01
I0317 10:12:54.500864  3513 solver.cpp:228] Iteration 16860, loss = 0.00540244
I0317 10:12:54.500931  3513 solver.cpp:244]     Train net output #0: loss = 0.00540244 (* 1 = 0.00540244 loss)
I0317 10:12:54.500946  3513 sgd_solver.cpp:106] Iteration 16860, lr = 0.01
I0317 10:13:01.834862  3513 solver.cpp:228] Iteration 16880, loss = 0.00481285
I0317 10:13:01.834931  3513 solver.cpp:244]     Train net output #0: loss = 0.00481286 (* 1 = 0.00481286 loss)
I0317 10:13:01.834944  3513 sgd_solver.cpp:106] Iteration 16880, lr = 0.01
I0317 10:13:09.168243  3513 solver.cpp:228] Iteration 16900, loss = 0.00337158
I0317 10:13:09.168306  3513 solver.cpp:244]     Train net output #0: loss = 0.00337158 (* 1 = 0.00337158 loss)
I0317 10:13:09.168319  3513 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0317 10:13:16.503784  3513 solver.cpp:228] Iteration 16920, loss = 0.00333864
I0317 10:13:16.503852  3513 solver.cpp:244]     Train net output #0: loss = 0.00333865 (* 1 = 0.00333865 loss)
I0317 10:13:16.503866  3513 sgd_solver.cpp:106] Iteration 16920, lr = 0.01
I0317 10:13:23.824308  3513 solver.cpp:228] Iteration 16940, loss = 0.00569031
I0317 10:13:23.824520  3513 solver.cpp:244]     Train net output #0: loss = 0.00569031 (* 1 = 0.00569031 loss)
I0317 10:13:23.824544  3513 sgd_solver.cpp:106] Iteration 16940, lr = 0.01
I0317 10:13:31.136126  3513 solver.cpp:228] Iteration 16960, loss = 0.00384817
I0317 10:13:31.136188  3513 solver.cpp:244]     Train net output #0: loss = 0.00384818 (* 1 = 0.00384818 loss)
I0317 10:13:31.136200  3513 sgd_solver.cpp:106] Iteration 16960, lr = 0.01
I0317 10:13:38.444118  3513 solver.cpp:228] Iteration 16980, loss = 0.00493472
I0317 10:13:38.444188  3513 solver.cpp:244]     Train net output #0: loss = 0.00493472 (* 1 = 0.00493472 loss)
I0317 10:13:38.444201  3513 sgd_solver.cpp:106] Iteration 16980, lr = 0.01
I0317 10:13:45.394208  3513 solver.cpp:337] Iteration 17000, Testing net (#0)
I0317 10:15:39.221258  3513 solver.cpp:404]     Test net output #0: loss = 0.0615619 (* 1 = 0.0615619 loss)
I0317 10:15:39.221393  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 10:15:39.556947  3513 solver.cpp:228] Iteration 17000, loss = 0.00606089
I0317 10:15:39.557013  3513 solver.cpp:244]     Train net output #0: loss = 0.0060609 (* 1 = 0.0060609 loss)
I0317 10:15:39.557026  3513 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0317 10:15:46.803882  3513 solver.cpp:228] Iteration 17020, loss = 0.00549374
I0317 10:15:46.803949  3513 solver.cpp:244]     Train net output #0: loss = 0.00549374 (* 1 = 0.00549374 loss)
I0317 10:15:46.803962  3513 sgd_solver.cpp:106] Iteration 17020, lr = 0.01
I0317 10:15:54.104189  3513 solver.cpp:228] Iteration 17040, loss = 0.00650253
I0317 10:15:54.104257  3513 solver.cpp:244]     Train net output #0: loss = 0.00650253 (* 1 = 0.00650253 loss)
I0317 10:15:54.104271  3513 sgd_solver.cpp:106] Iteration 17040, lr = 0.01
I0317 10:16:01.418709  3513 solver.cpp:228] Iteration 17060, loss = 0.00287738
I0317 10:16:01.418779  3513 solver.cpp:244]     Train net output #0: loss = 0.00287739 (* 1 = 0.00287739 loss)
I0317 10:16:01.418793  3513 sgd_solver.cpp:106] Iteration 17060, lr = 0.01
I0317 10:16:08.746875  3513 solver.cpp:228] Iteration 17080, loss = 0.00435159
I0317 10:16:08.746937  3513 solver.cpp:244]     Train net output #0: loss = 0.00435159 (* 1 = 0.00435159 loss)
I0317 10:16:08.746950  3513 sgd_solver.cpp:106] Iteration 17080, lr = 0.01
I0317 10:16:16.076319  3513 solver.cpp:228] Iteration 17100, loss = 0.00392702
I0317 10:16:16.076479  3513 solver.cpp:244]     Train net output #0: loss = 0.00392703 (* 1 = 0.00392703 loss)
I0317 10:16:16.076493  3513 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0317 10:16:23.406406  3513 solver.cpp:228] Iteration 17120, loss = 0.00848755
I0317 10:16:23.406473  3513 solver.cpp:244]     Train net output #0: loss = 0.00848755 (* 1 = 0.00848755 loss)
I0317 10:16:23.406486  3513 sgd_solver.cpp:106] Iteration 17120, lr = 0.01
I0317 10:16:30.737030  3513 solver.cpp:228] Iteration 17140, loss = 0.00350414
I0317 10:16:30.737097  3513 solver.cpp:244]     Train net output #0: loss = 0.00350415 (* 1 = 0.00350415 loss)
I0317 10:16:30.737110  3513 sgd_solver.cpp:106] Iteration 17140, lr = 0.01
I0317 10:16:38.064923  3513 solver.cpp:228] Iteration 17160, loss = 0.00603223
I0317 10:16:38.064986  3513 solver.cpp:244]     Train net output #0: loss = 0.00603224 (* 1 = 0.00603224 loss)
I0317 10:16:38.064999  3513 sgd_solver.cpp:106] Iteration 17160, lr = 0.01
I0317 10:16:45.392624  3513 solver.cpp:228] Iteration 17180, loss = 0.00399068
I0317 10:16:45.392691  3513 solver.cpp:244]     Train net output #0: loss = 0.00399069 (* 1 = 0.00399069 loss)
I0317 10:16:45.392704  3513 sgd_solver.cpp:106] Iteration 17180, lr = 0.01
I0317 10:16:52.714251  3513 solver.cpp:228] Iteration 17200, loss = 0.00809005
I0317 10:16:52.714458  3513 solver.cpp:244]     Train net output #0: loss = 0.00809005 (* 1 = 0.00809005 loss)
I0317 10:16:52.714480  3513 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0317 10:17:00.033756  3513 solver.cpp:228] Iteration 17220, loss = 0.00236902
I0317 10:17:00.033823  3513 solver.cpp:244]     Train net output #0: loss = 0.00236903 (* 1 = 0.00236903 loss)
I0317 10:17:00.033835  3513 sgd_solver.cpp:106] Iteration 17220, lr = 0.01
I0317 10:17:07.358265  3513 solver.cpp:228] Iteration 17240, loss = 0.00525436
I0317 10:17:07.358328  3513 solver.cpp:244]     Train net output #0: loss = 0.00525437 (* 1 = 0.00525437 loss)
I0317 10:17:07.358341  3513 sgd_solver.cpp:106] Iteration 17240, lr = 0.01
I0317 10:17:10.653355  3513 solver.cpp:337] Iteration 17250, Testing net (#0)
I0317 10:19:04.514050  3513 solver.cpp:404]     Test net output #0: loss = 0.0631221 (* 1 = 0.0631221 loss)
I0317 10:19:04.514191  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.682599 (* 1 = 0.682599 loss)
I0317 10:19:08.468155  3513 solver.cpp:228] Iteration 17260, loss = 0.0047485
I0317 10:19:08.468224  3513 solver.cpp:244]     Train net output #0: loss = 0.00474851 (* 1 = 0.00474851 loss)
I0317 10:19:08.468236  3513 sgd_solver.cpp:106] Iteration 17260, lr = 0.01
I0317 10:19:15.751109  3513 solver.cpp:228] Iteration 17280, loss = 0.00322087
I0317 10:19:15.751183  3513 solver.cpp:244]     Train net output #0: loss = 0.00322088 (* 1 = 0.00322088 loss)
I0317 10:19:15.751196  3513 sgd_solver.cpp:106] Iteration 17280, lr = 0.01
I0317 10:19:23.064196  3513 solver.cpp:228] Iteration 17300, loss = 0.00576081
I0317 10:19:23.064270  3513 solver.cpp:244]     Train net output #0: loss = 0.00576082 (* 1 = 0.00576082 loss)
I0317 10:19:23.064283  3513 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0317 10:19:30.388844  3513 solver.cpp:228] Iteration 17320, loss = 0.00538995
I0317 10:19:30.388911  3513 solver.cpp:244]     Train net output #0: loss = 0.00538996 (* 1 = 0.00538996 loss)
I0317 10:19:30.388924  3513 sgd_solver.cpp:106] Iteration 17320, lr = 0.01
I0317 10:19:37.711102  3513 solver.cpp:228] Iteration 17340, loss = 0.0070493
I0317 10:19:37.711243  3513 solver.cpp:244]     Train net output #0: loss = 0.00704931 (* 1 = 0.00704931 loss)
I0317 10:19:37.711257  3513 sgd_solver.cpp:106] Iteration 17340, lr = 0.01
I0317 10:19:45.036712  3513 solver.cpp:228] Iteration 17360, loss = 0.00779938
I0317 10:19:45.036774  3513 solver.cpp:244]     Train net output #0: loss = 0.00779939 (* 1 = 0.00779939 loss)
I0317 10:19:45.036787  3513 sgd_solver.cpp:106] Iteration 17360, lr = 0.01
I0317 10:19:52.365840  3513 solver.cpp:228] Iteration 17380, loss = 0.00669204
I0317 10:19:52.365921  3513 solver.cpp:244]     Train net output #0: loss = 0.00669205 (* 1 = 0.00669205 loss)
I0317 10:19:52.365934  3513 sgd_solver.cpp:106] Iteration 17380, lr = 0.01
I0317 10:19:59.699360  3513 solver.cpp:228] Iteration 17400, loss = 0.00320208
I0317 10:19:59.699427  3513 solver.cpp:244]     Train net output #0: loss = 0.00320209 (* 1 = 0.00320209 loss)
I0317 10:19:59.699440  3513 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0317 10:20:07.032207  3513 solver.cpp:228] Iteration 17420, loss = 0.00378644
I0317 10:20:07.032274  3513 solver.cpp:244]     Train net output #0: loss = 0.00378645 (* 1 = 0.00378645 loss)
I0317 10:20:07.032287  3513 sgd_solver.cpp:106] Iteration 17420, lr = 0.01
I0317 10:20:14.367197  3513 solver.cpp:228] Iteration 17440, loss = 0.00422304
I0317 10:20:14.367404  3513 solver.cpp:244]     Train net output #0: loss = 0.00422305 (* 1 = 0.00422305 loss)
I0317 10:20:14.367419  3513 sgd_solver.cpp:106] Iteration 17440, lr = 0.01
I0317 10:20:21.693779  3513 solver.cpp:228] Iteration 17460, loss = 0.00359536
I0317 10:20:21.693847  3513 solver.cpp:244]     Train net output #0: loss = 0.00359537 (* 1 = 0.00359537 loss)
I0317 10:20:21.693861  3513 sgd_solver.cpp:106] Iteration 17460, lr = 0.01
I0317 10:20:29.014364  3513 solver.cpp:228] Iteration 17480, loss = 0.00757044
I0317 10:20:29.014425  3513 solver.cpp:244]     Train net output #0: loss = 0.00757045 (* 1 = 0.00757045 loss)
I0317 10:20:29.014438  3513 sgd_solver.cpp:106] Iteration 17480, lr = 0.01
I0317 10:20:35.972812  3513 solver.cpp:337] Iteration 17500, Testing net (#0)
I0317 10:22:29.832732  3513 solver.cpp:404]     Test net output #0: loss = 0.0681929 (* 1 = 0.0681929 loss)
I0317 10:22:29.832854  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.682719 (* 1 = 0.682719 loss)
I0317 10:22:30.170367  3513 solver.cpp:228] Iteration 17500, loss = 0.00428776
I0317 10:22:30.170433  3513 solver.cpp:244]     Train net output #0: loss = 0.00428777 (* 1 = 0.00428777 loss)
I0317 10:22:30.170446  3513 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0317 10:22:37.423843  3513 solver.cpp:228] Iteration 17520, loss = 0.00619682
I0317 10:22:37.423912  3513 solver.cpp:244]     Train net output #0: loss = 0.00619683 (* 1 = 0.00619683 loss)
I0317 10:22:37.423923  3513 sgd_solver.cpp:106] Iteration 17520, lr = 0.01
I0317 10:22:44.719096  3513 solver.cpp:228] Iteration 17540, loss = 0.00532987
I0317 10:22:44.719166  3513 solver.cpp:244]     Train net output #0: loss = 0.00532988 (* 1 = 0.00532988 loss)
I0317 10:22:44.719187  3513 sgd_solver.cpp:106] Iteration 17540, lr = 0.01
I0317 10:22:52.032990  3513 solver.cpp:228] Iteration 17560, loss = 0.00631102
I0317 10:22:52.033051  3513 solver.cpp:244]     Train net output #0: loss = 0.00631103 (* 1 = 0.00631103 loss)
I0317 10:22:52.033064  3513 sgd_solver.cpp:106] Iteration 17560, lr = 0.01
I0317 10:22:59.355794  3513 solver.cpp:228] Iteration 17580, loss = 0.00353306
I0317 10:22:59.355862  3513 solver.cpp:244]     Train net output #0: loss = 0.00353307 (* 1 = 0.00353307 loss)
I0317 10:22:59.355875  3513 sgd_solver.cpp:106] Iteration 17580, lr = 0.01
I0317 10:23:06.680524  3513 solver.cpp:228] Iteration 17600, loss = 0.00172623
I0317 10:23:06.680660  3513 solver.cpp:244]     Train net output #0: loss = 0.00172624 (* 1 = 0.00172624 loss)
I0317 10:23:06.680673  3513 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0317 10:23:14.005805  3513 solver.cpp:228] Iteration 17620, loss = 0.00304652
I0317 10:23:14.005872  3513 solver.cpp:244]     Train net output #0: loss = 0.00304653 (* 1 = 0.00304653 loss)
I0317 10:23:14.005885  3513 sgd_solver.cpp:106] Iteration 17620, lr = 0.01
I0317 10:23:21.343987  3513 solver.cpp:228] Iteration 17640, loss = 0.0044417
I0317 10:23:21.344068  3513 solver.cpp:244]     Train net output #0: loss = 0.00444171 (* 1 = 0.00444171 loss)
I0317 10:23:21.344080  3513 sgd_solver.cpp:106] Iteration 17640, lr = 0.01
I0317 10:23:28.672425  3513 solver.cpp:228] Iteration 17660, loss = 0.00628509
I0317 10:23:28.672487  3513 solver.cpp:244]     Train net output #0: loss = 0.00628509 (* 1 = 0.00628509 loss)
I0317 10:23:28.672499  3513 sgd_solver.cpp:106] Iteration 17660, lr = 0.01
I0317 10:23:36.001014  3513 solver.cpp:228] Iteration 17680, loss = 0.00356749
I0317 10:23:36.001080  3513 solver.cpp:244]     Train net output #0: loss = 0.0035675 (* 1 = 0.0035675 loss)
I0317 10:23:36.001094  3513 sgd_solver.cpp:106] Iteration 17680, lr = 0.01
I0317 10:23:43.322763  3513 solver.cpp:228] Iteration 17700, loss = 0.0067799
I0317 10:23:43.322962  3513 solver.cpp:244]     Train net output #0: loss = 0.00677991 (* 1 = 0.00677991 loss)
I0317 10:23:43.322975  3513 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0317 10:23:50.634166  3513 solver.cpp:228] Iteration 17720, loss = 0.00669016
I0317 10:23:50.634243  3513 solver.cpp:244]     Train net output #0: loss = 0.00669017 (* 1 = 0.00669017 loss)
I0317 10:23:50.634258  3513 sgd_solver.cpp:106] Iteration 17720, lr = 0.01
I0317 10:23:57.963706  3513 solver.cpp:228] Iteration 17740, loss = 0.00779523
I0317 10:23:57.963773  3513 solver.cpp:244]     Train net output #0: loss = 0.00779524 (* 1 = 0.00779524 loss)
I0317 10:23:57.963786  3513 sgd_solver.cpp:106] Iteration 17740, lr = 0.01
I0317 10:24:01.259937  3513 solver.cpp:337] Iteration 17750, Testing net (#0)
I0317 10:25:55.129401  3513 solver.cpp:404]     Test net output #0: loss = 0.0660827 (* 1 = 0.0660827 loss)
I0317 10:25:55.129537  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673039 (* 1 = 0.673039 loss)
I0317 10:25:59.077455  3513 solver.cpp:228] Iteration 17760, loss = 0.00257992
I0317 10:25:59.077517  3513 solver.cpp:244]     Train net output #0: loss = 0.00257993 (* 1 = 0.00257993 loss)
I0317 10:25:59.077538  3513 sgd_solver.cpp:106] Iteration 17760, lr = 0.01
I0317 10:26:06.346685  3513 solver.cpp:228] Iteration 17780, loss = 0.00416581
I0317 10:26:06.346753  3513 solver.cpp:244]     Train net output #0: loss = 0.00416582 (* 1 = 0.00416582 loss)
I0317 10:26:06.346766  3513 sgd_solver.cpp:106] Iteration 17780, lr = 0.01
I0317 10:26:13.654937  3513 solver.cpp:228] Iteration 17800, loss = 0.00751452
I0317 10:26:13.655004  3513 solver.cpp:244]     Train net output #0: loss = 0.00751453 (* 1 = 0.00751453 loss)
I0317 10:26:13.655017  3513 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0317 10:26:20.982730  3513 solver.cpp:228] Iteration 17820, loss = 0.00572553
I0317 10:26:20.982800  3513 solver.cpp:244]     Train net output #0: loss = 0.00572554 (* 1 = 0.00572554 loss)
I0317 10:26:20.982812  3513 sgd_solver.cpp:106] Iteration 17820, lr = 0.01
I0317 10:26:28.306879  3513 solver.cpp:228] Iteration 17840, loss = 0.00867786
I0317 10:26:28.307066  3513 solver.cpp:244]     Train net output #0: loss = 0.00867787 (* 1 = 0.00867787 loss)
I0317 10:26:28.307080  3513 sgd_solver.cpp:106] Iteration 17840, lr = 0.01
I0317 10:26:35.637747  3513 solver.cpp:228] Iteration 17860, loss = 0.00440791
I0317 10:26:35.637814  3513 solver.cpp:244]     Train net output #0: loss = 0.00440792 (* 1 = 0.00440792 loss)
I0317 10:26:35.637826  3513 sgd_solver.cpp:106] Iteration 17860, lr = 0.01
I0317 10:26:42.976140  3513 solver.cpp:228] Iteration 17880, loss = 0.00723199
I0317 10:26:42.976207  3513 solver.cpp:244]     Train net output #0: loss = 0.007232 (* 1 = 0.007232 loss)
I0317 10:26:42.976220  3513 sgd_solver.cpp:106] Iteration 17880, lr = 0.01
I0317 10:26:50.301771  3513 solver.cpp:228] Iteration 17900, loss = 0.00692533
I0317 10:26:50.301833  3513 solver.cpp:244]     Train net output #0: loss = 0.00692534 (* 1 = 0.00692534 loss)
I0317 10:26:50.301846  3513 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0317 10:26:57.624912  3513 solver.cpp:228] Iteration 17920, loss = 0.00384244
I0317 10:26:57.624979  3513 solver.cpp:244]     Train net output #0: loss = 0.00384245 (* 1 = 0.00384245 loss)
I0317 10:26:57.624992  3513 sgd_solver.cpp:106] Iteration 17920, lr = 0.01
I0317 10:27:04.953982  3513 solver.cpp:228] Iteration 17940, loss = 0.00432786
I0317 10:27:04.954131  3513 solver.cpp:244]     Train net output #0: loss = 0.00432787 (* 1 = 0.00432787 loss)
I0317 10:27:04.954145  3513 sgd_solver.cpp:106] Iteration 17940, lr = 0.01
I0317 10:27:12.274946  3513 solver.cpp:228] Iteration 17960, loss = 0.00330506
I0317 10:27:12.275009  3513 solver.cpp:244]     Train net output #0: loss = 0.00330508 (* 1 = 0.00330508 loss)
I0317 10:27:12.275022  3513 sgd_solver.cpp:106] Iteration 17960, lr = 0.01
I0317 10:27:19.591784  3513 solver.cpp:228] Iteration 17980, loss = 0.0050842
I0317 10:27:19.591851  3513 solver.cpp:244]     Train net output #0: loss = 0.00508421 (* 1 = 0.00508421 loss)
I0317 10:27:19.591866  3513 sgd_solver.cpp:106] Iteration 17980, lr = 0.01
I0317 10:27:26.558619  3513 solver.cpp:337] Iteration 18000, Testing net (#0)
I0317 10:29:20.422631  3513 solver.cpp:404]     Test net output #0: loss = 0.0598481 (* 1 = 0.0598481 loss)
I0317 10:29:20.422787  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 10:29:20.758700  3513 solver.cpp:228] Iteration 18000, loss = 0.00381727
I0317 10:29:20.758769  3513 solver.cpp:244]     Train net output #0: loss = 0.00381728 (* 1 = 0.00381728 loss)
I0317 10:29:20.758780  3513 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0317 10:29:28.014227  3513 solver.cpp:228] Iteration 18020, loss = 0.00516623
I0317 10:29:28.014297  3513 solver.cpp:244]     Train net output #0: loss = 0.00516625 (* 1 = 0.00516625 loss)
I0317 10:29:28.014308  3513 sgd_solver.cpp:106] Iteration 18020, lr = 0.01
I0317 10:29:35.313454  3513 solver.cpp:228] Iteration 18040, loss = 0.00528259
I0317 10:29:35.313524  3513 solver.cpp:244]     Train net output #0: loss = 0.0052826 (* 1 = 0.0052826 loss)
I0317 10:29:35.313539  3513 sgd_solver.cpp:106] Iteration 18040, lr = 0.01
I0317 10:29:42.631374  3513 solver.cpp:228] Iteration 18060, loss = 0.00665929
I0317 10:29:42.631443  3513 solver.cpp:244]     Train net output #0: loss = 0.0066593 (* 1 = 0.0066593 loss)
I0317 10:29:42.631455  3513 sgd_solver.cpp:106] Iteration 18060, lr = 0.01
I0317 10:29:49.954640  3513 solver.cpp:228] Iteration 18080, loss = 0.00506438
I0317 10:29:49.954710  3513 solver.cpp:244]     Train net output #0: loss = 0.00506439 (* 1 = 0.00506439 loss)
I0317 10:29:49.954722  3513 sgd_solver.cpp:106] Iteration 18080, lr = 0.01
I0317 10:29:57.273988  3513 solver.cpp:228] Iteration 18100, loss = 0.00688315
I0317 10:29:57.274139  3513 solver.cpp:244]     Train net output #0: loss = 0.00688316 (* 1 = 0.00688316 loss)
I0317 10:29:57.274152  3513 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0317 10:30:04.602856  3513 solver.cpp:228] Iteration 18120, loss = 0.00347589
I0317 10:30:04.602924  3513 solver.cpp:244]     Train net output #0: loss = 0.0034759 (* 1 = 0.0034759 loss)
I0317 10:30:04.602936  3513 sgd_solver.cpp:106] Iteration 18120, lr = 0.01
I0317 10:30:11.924136  3513 solver.cpp:228] Iteration 18140, loss = 0.00172429
I0317 10:30:11.924206  3513 solver.cpp:244]     Train net output #0: loss = 0.0017243 (* 1 = 0.0017243 loss)
I0317 10:30:11.924218  3513 sgd_solver.cpp:106] Iteration 18140, lr = 0.01
I0317 10:30:19.261592  3513 solver.cpp:228] Iteration 18160, loss = 0.00304425
I0317 10:30:19.261662  3513 solver.cpp:244]     Train net output #0: loss = 0.00304426 (* 1 = 0.00304426 loss)
I0317 10:30:19.261675  3513 sgd_solver.cpp:106] Iteration 18160, lr = 0.01
I0317 10:30:26.593938  3513 solver.cpp:228] Iteration 18180, loss = 0.00337223
I0317 10:30:26.594005  3513 solver.cpp:244]     Train net output #0: loss = 0.00337224 (* 1 = 0.00337224 loss)
I0317 10:30:26.594018  3513 sgd_solver.cpp:106] Iteration 18180, lr = 0.01
I0317 10:30:33.929529  3513 solver.cpp:228] Iteration 18200, loss = 0.00606403
I0317 10:30:33.929674  3513 solver.cpp:244]     Train net output #0: loss = 0.00606404 (* 1 = 0.00606404 loss)
I0317 10:30:33.929688  3513 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0317 10:30:41.263710  3513 solver.cpp:228] Iteration 18220, loss = 0.00572022
I0317 10:30:41.263783  3513 solver.cpp:244]     Train net output #0: loss = 0.00572023 (* 1 = 0.00572023 loss)
I0317 10:30:41.263797  3513 sgd_solver.cpp:106] Iteration 18220, lr = 0.01
I0317 10:30:48.585414  3513 solver.cpp:228] Iteration 18240, loss = 0.00503918
I0317 10:30:48.585480  3513 solver.cpp:244]     Train net output #0: loss = 0.00503919 (* 1 = 0.00503919 loss)
I0317 10:30:48.585494  3513 sgd_solver.cpp:106] Iteration 18240, lr = 0.01
I0317 10:30:51.880755  3513 solver.cpp:337] Iteration 18250, Testing net (#0)
I0317 10:32:45.762215  3513 solver.cpp:404]     Test net output #0: loss = 0.0606802 (* 1 = 0.0606802 loss)
I0317 10:32:45.762334  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 10:32:49.710044  3513 solver.cpp:228] Iteration 18260, loss = 0.00555914
I0317 10:32:49.710108  3513 solver.cpp:244]     Train net output #0: loss = 0.00555915 (* 1 = 0.00555915 loss)
I0317 10:32:49.710120  3513 sgd_solver.cpp:106] Iteration 18260, lr = 0.01
I0317 10:32:56.982894  3513 solver.cpp:228] Iteration 18280, loss = 0.00865695
I0317 10:32:56.982960  3513 solver.cpp:244]     Train net output #0: loss = 0.00865696 (* 1 = 0.00865696 loss)
I0317 10:32:56.982973  3513 sgd_solver.cpp:106] Iteration 18280, lr = 0.01
I0317 10:33:04.288529  3513 solver.cpp:228] Iteration 18300, loss = 0.00362292
I0317 10:33:04.288599  3513 solver.cpp:244]     Train net output #0: loss = 0.00362293 (* 1 = 0.00362293 loss)
I0317 10:33:04.288611  3513 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0317 10:33:11.608014  3513 solver.cpp:228] Iteration 18320, loss = 0.00430617
I0317 10:33:11.608084  3513 solver.cpp:244]     Train net output #0: loss = 0.00430618 (* 1 = 0.00430618 loss)
I0317 10:33:11.608098  3513 sgd_solver.cpp:106] Iteration 18320, lr = 0.01
I0317 10:33:18.935382  3513 solver.cpp:228] Iteration 18340, loss = 0.00355071
I0317 10:33:18.935560  3513 solver.cpp:244]     Train net output #0: loss = 0.00355072 (* 1 = 0.00355072 loss)
I0317 10:33:18.935575  3513 sgd_solver.cpp:106] Iteration 18340, lr = 0.01
I0317 10:33:26.263654  3513 solver.cpp:228] Iteration 18360, loss = 0.00323875
I0317 10:33:26.263718  3513 solver.cpp:244]     Train net output #0: loss = 0.00323876 (* 1 = 0.00323876 loss)
I0317 10:33:26.263731  3513 sgd_solver.cpp:106] Iteration 18360, lr = 0.01
I0317 10:33:33.595784  3513 solver.cpp:228] Iteration 18380, loss = 0.00540845
I0317 10:33:33.595851  3513 solver.cpp:244]     Train net output #0: loss = 0.00540846 (* 1 = 0.00540846 loss)
I0317 10:33:33.595865  3513 sgd_solver.cpp:106] Iteration 18380, lr = 0.01
I0317 10:33:40.924240  3513 solver.cpp:228] Iteration 18400, loss = 0.00369625
I0317 10:33:40.924306  3513 solver.cpp:244]     Train net output #0: loss = 0.00369626 (* 1 = 0.00369626 loss)
I0317 10:33:40.924320  3513 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0317 10:33:48.238704  3513 solver.cpp:228] Iteration 18420, loss = 0.00934375
I0317 10:33:48.238772  3513 solver.cpp:244]     Train net output #0: loss = 0.00934376 (* 1 = 0.00934376 loss)
I0317 10:33:48.238785  3513 sgd_solver.cpp:106] Iteration 18420, lr = 0.01
I0317 10:33:55.562877  3513 solver.cpp:228] Iteration 18440, loss = 0.00717927
I0317 10:33:55.563016  3513 solver.cpp:244]     Train net output #0: loss = 0.00717928 (* 1 = 0.00717928 loss)
I0317 10:33:55.563030  3513 sgd_solver.cpp:106] Iteration 18440, lr = 0.01
I0317 10:34:02.878221  3513 solver.cpp:228] Iteration 18460, loss = 0.00668253
I0317 10:34:02.878288  3513 solver.cpp:244]     Train net output #0: loss = 0.00668254 (* 1 = 0.00668254 loss)
I0317 10:34:02.878300  3513 sgd_solver.cpp:106] Iteration 18460, lr = 0.01
I0317 10:34:10.193934  3513 solver.cpp:228] Iteration 18480, loss = 0.00681268
I0317 10:34:10.194003  3513 solver.cpp:244]     Train net output #0: loss = 0.00681269 (* 1 = 0.00681269 loss)
I0317 10:34:10.194016  3513 sgd_solver.cpp:106] Iteration 18480, lr = 0.01
I0317 10:34:17.134977  3513 solver.cpp:337] Iteration 18500, Testing net (#0)
I0317 10:36:11.020535  3513 solver.cpp:404]     Test net output #0: loss = 0.0586015 (* 1 = 0.0586015 loss)
I0317 10:36:11.020664  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 10:36:11.357012  3513 solver.cpp:228] Iteration 18500, loss = 0.00172953
I0317 10:36:11.357077  3513 solver.cpp:244]     Train net output #0: loss = 0.00172954 (* 1 = 0.00172954 loss)
I0317 10:36:11.357090  3513 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0317 10:36:18.591433  3513 solver.cpp:228] Iteration 18520, loss = 0.00231472
I0317 10:36:18.591498  3513 solver.cpp:244]     Train net output #0: loss = 0.00231472 (* 1 = 0.00231472 loss)
I0317 10:36:18.591511  3513 sgd_solver.cpp:106] Iteration 18520, lr = 0.01
I0317 10:36:25.871693  3513 solver.cpp:228] Iteration 18540, loss = 0.00447312
I0317 10:36:25.871762  3513 solver.cpp:244]     Train net output #0: loss = 0.00447313 (* 1 = 0.00447313 loss)
I0317 10:36:25.871774  3513 sgd_solver.cpp:106] Iteration 18540, lr = 0.01
I0317 10:36:33.164759  3513 solver.cpp:228] Iteration 18560, loss = 0.00555292
I0317 10:36:33.164827  3513 solver.cpp:244]     Train net output #0: loss = 0.00555293 (* 1 = 0.00555293 loss)
I0317 10:36:33.164839  3513 sgd_solver.cpp:106] Iteration 18560, lr = 0.01
I0317 10:36:40.474530  3513 solver.cpp:228] Iteration 18580, loss = 0.00719406
I0317 10:36:40.474598  3513 solver.cpp:244]     Train net output #0: loss = 0.00719406 (* 1 = 0.00719406 loss)
I0317 10:36:40.474611  3513 sgd_solver.cpp:106] Iteration 18580, lr = 0.01
I0317 10:36:47.798645  3513 solver.cpp:228] Iteration 18600, loss = 0.0053482
I0317 10:36:47.798844  3513 solver.cpp:244]     Train net output #0: loss = 0.00534821 (* 1 = 0.00534821 loss)
I0317 10:36:47.798858  3513 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0317 10:36:55.123814  3513 solver.cpp:228] Iteration 18620, loss = 0.00830287
I0317 10:36:55.123881  3513 solver.cpp:244]     Train net output #0: loss = 0.00830288 (* 1 = 0.00830288 loss)
I0317 10:36:55.123894  3513 sgd_solver.cpp:106] Iteration 18620, lr = 0.01
I0317 10:37:02.453192  3513 solver.cpp:228] Iteration 18640, loss = 0.00815502
I0317 10:37:02.453263  3513 solver.cpp:244]     Train net output #0: loss = 0.00815503 (* 1 = 0.00815503 loss)
I0317 10:37:02.453277  3513 sgd_solver.cpp:106] Iteration 18640, lr = 0.01
I0317 10:37:09.778645  3513 solver.cpp:228] Iteration 18660, loss = 0.00312897
I0317 10:37:09.778712  3513 solver.cpp:244]     Train net output #0: loss = 0.00312898 (* 1 = 0.00312898 loss)
I0317 10:37:09.778724  3513 sgd_solver.cpp:106] Iteration 18660, lr = 0.01
I0317 10:37:17.110479  3513 solver.cpp:228] Iteration 18680, loss = 0.00281949
I0317 10:37:17.110553  3513 solver.cpp:244]     Train net output #0: loss = 0.00281949 (* 1 = 0.00281949 loss)
I0317 10:37:17.110566  3513 sgd_solver.cpp:106] Iteration 18680, lr = 0.01
I0317 10:37:24.439615  3513 solver.cpp:228] Iteration 18700, loss = 0.00445485
I0317 10:37:24.439774  3513 solver.cpp:244]     Train net output #0: loss = 0.00445486 (* 1 = 0.00445486 loss)
I0317 10:37:24.439788  3513 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0317 10:37:31.758724  3513 solver.cpp:228] Iteration 18720, loss = 0.00422367
I0317 10:37:31.758791  3513 solver.cpp:244]     Train net output #0: loss = 0.00422368 (* 1 = 0.00422368 loss)
I0317 10:37:31.758805  3513 sgd_solver.cpp:106] Iteration 18720, lr = 0.01
I0317 10:37:39.085885  3513 solver.cpp:228] Iteration 18740, loss = 0.00548979
I0317 10:37:39.085947  3513 solver.cpp:244]     Train net output #0: loss = 0.0054898 (* 1 = 0.0054898 loss)
I0317 10:37:39.085960  3513 sgd_solver.cpp:106] Iteration 18740, lr = 0.01
I0317 10:37:42.387337  3513 solver.cpp:337] Iteration 18750, Testing net (#0)
I0317 10:39:36.258319  3513 solver.cpp:404]     Test net output #0: loss = 0.0624514 (* 1 = 0.0624514 loss)
I0317 10:39:36.258452  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673199 (* 1 = 0.673199 loss)
I0317 10:39:40.200546  3513 solver.cpp:228] Iteration 18760, loss = 0.00702184
I0317 10:39:40.200608  3513 solver.cpp:244]     Train net output #0: loss = 0.00702185 (* 1 = 0.00702185 loss)
I0317 10:39:40.200621  3513 sgd_solver.cpp:106] Iteration 18760, lr = 0.01
I0317 10:39:47.451037  3513 solver.cpp:228] Iteration 18780, loss = 0.0091186
I0317 10:39:47.451110  3513 solver.cpp:244]     Train net output #0: loss = 0.00911862 (* 1 = 0.00911862 loss)
I0317 10:39:47.451124  3513 sgd_solver.cpp:106] Iteration 18780, lr = 0.01
I0317 10:39:54.744408  3513 solver.cpp:228] Iteration 18800, loss = 0.00632494
I0317 10:39:54.744477  3513 solver.cpp:244]     Train net output #0: loss = 0.00632495 (* 1 = 0.00632495 loss)
I0317 10:39:54.744490  3513 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0317 10:40:02.060755  3513 solver.cpp:228] Iteration 18820, loss = 0.00706273
I0317 10:40:02.060838  3513 solver.cpp:244]     Train net output #0: loss = 0.00706274 (* 1 = 0.00706274 loss)
I0317 10:40:02.060853  3513 sgd_solver.cpp:106] Iteration 18820, lr = 0.01
I0317 10:40:09.385779  3513 solver.cpp:228] Iteration 18840, loss = 0.00321791
I0317 10:40:09.385956  3513 solver.cpp:244]     Train net output #0: loss = 0.00321792 (* 1 = 0.00321792 loss)
I0317 10:40:09.385969  3513 sgd_solver.cpp:106] Iteration 18840, lr = 0.01
I0317 10:40:16.708706  3513 solver.cpp:228] Iteration 18860, loss = 0.00247726
I0317 10:40:16.708775  3513 solver.cpp:244]     Train net output #0: loss = 0.00247728 (* 1 = 0.00247728 loss)
I0317 10:40:16.708787  3513 sgd_solver.cpp:106] Iteration 18860, lr = 0.01
I0317 10:40:24.031703  3513 solver.cpp:228] Iteration 18880, loss = 0.00375028
I0317 10:40:24.031770  3513 solver.cpp:244]     Train net output #0: loss = 0.00375029 (* 1 = 0.00375029 loss)
I0317 10:40:24.031783  3513 sgd_solver.cpp:106] Iteration 18880, lr = 0.01
I0317 10:40:31.361335  3513 solver.cpp:228] Iteration 18900, loss = 0.00469493
I0317 10:40:31.361402  3513 solver.cpp:244]     Train net output #0: loss = 0.00469494 (* 1 = 0.00469494 loss)
I0317 10:40:31.361414  3513 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0317 10:40:38.692338  3513 solver.cpp:228] Iteration 18920, loss = 0.00457491
I0317 10:40:38.692405  3513 solver.cpp:244]     Train net output #0: loss = 0.00457492 (* 1 = 0.00457492 loss)
I0317 10:40:38.692418  3513 sgd_solver.cpp:106] Iteration 18920, lr = 0.01
I0317 10:40:46.017843  3513 solver.cpp:228] Iteration 18940, loss = 0.00443435
I0317 10:40:46.017987  3513 solver.cpp:244]     Train net output #0: loss = 0.00443436 (* 1 = 0.00443436 loss)
I0317 10:40:46.018000  3513 sgd_solver.cpp:106] Iteration 18940, lr = 0.01
I0317 10:40:53.346765  3513 solver.cpp:228] Iteration 18960, loss = 0.00598691
I0317 10:40:53.346827  3513 solver.cpp:244]     Train net output #0: loss = 0.00598692 (* 1 = 0.00598692 loss)
I0317 10:40:53.346839  3513 sgd_solver.cpp:106] Iteration 18960, lr = 0.01
I0317 10:41:00.673486  3513 solver.cpp:228] Iteration 18980, loss = 0.00516046
I0317 10:41:00.673552  3513 solver.cpp:244]     Train net output #0: loss = 0.00516048 (* 1 = 0.00516048 loss)
I0317 10:41:00.673563  3513 sgd_solver.cpp:106] Iteration 18980, lr = 0.01
I0317 10:41:07.642918  3513 solver.cpp:337] Iteration 19000, Testing net (#0)
I0317 10:43:01.490236  3513 solver.cpp:404]     Test net output #0: loss = 0.0603378 (* 1 = 0.0603378 loss)
I0317 10:43:01.490362  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 10:43:01.827934  3513 solver.cpp:228] Iteration 19000, loss = 0.00529114
I0317 10:43:01.828013  3513 solver.cpp:244]     Train net output #0: loss = 0.00529115 (* 1 = 0.00529115 loss)
I0317 10:43:01.828033  3513 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0317 10:43:09.080343  3513 solver.cpp:228] Iteration 19020, loss = 0.00393063
I0317 10:43:09.080415  3513 solver.cpp:244]     Train net output #0: loss = 0.00393065 (* 1 = 0.00393065 loss)
I0317 10:43:09.080430  3513 sgd_solver.cpp:106] Iteration 19020, lr = 0.01
I0317 10:43:16.379830  3513 solver.cpp:228] Iteration 19040, loss = 0.00322638
I0317 10:43:16.379899  3513 solver.cpp:244]     Train net output #0: loss = 0.00322639 (* 1 = 0.00322639 loss)
I0317 10:43:16.379911  3513 sgd_solver.cpp:106] Iteration 19040, lr = 0.01
I0317 10:43:23.696036  3513 solver.cpp:228] Iteration 19060, loss = 0.00603225
I0317 10:43:23.696104  3513 solver.cpp:244]     Train net output #0: loss = 0.00603227 (* 1 = 0.00603227 loss)
I0317 10:43:23.696116  3513 sgd_solver.cpp:106] Iteration 19060, lr = 0.01
I0317 10:43:31.026438  3513 solver.cpp:228] Iteration 19080, loss = 0.00288346
I0317 10:43:31.026505  3513 solver.cpp:244]     Train net output #0: loss = 0.00288347 (* 1 = 0.00288347 loss)
I0317 10:43:31.026518  3513 sgd_solver.cpp:106] Iteration 19080, lr = 0.01
I0317 10:43:38.355149  3513 solver.cpp:228] Iteration 19100, loss = 0.00526283
I0317 10:43:38.355303  3513 solver.cpp:244]     Train net output #0: loss = 0.00526285 (* 1 = 0.00526285 loss)
I0317 10:43:38.355317  3513 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0317 10:43:45.681838  3513 solver.cpp:228] Iteration 19120, loss = 0.00457682
I0317 10:43:45.681902  3513 solver.cpp:244]     Train net output #0: loss = 0.00457684 (* 1 = 0.00457684 loss)
I0317 10:43:45.681915  3513 sgd_solver.cpp:106] Iteration 19120, lr = 0.01
I0317 10:43:53.008481  3513 solver.cpp:228] Iteration 19140, loss = 0.00573015
I0317 10:43:53.008549  3513 solver.cpp:244]     Train net output #0: loss = 0.00573016 (* 1 = 0.00573016 loss)
I0317 10:43:53.008563  3513 sgd_solver.cpp:106] Iteration 19140, lr = 0.01
I0317 10:44:00.330137  3513 solver.cpp:228] Iteration 19160, loss = 0.00753592
I0317 10:44:00.330201  3513 solver.cpp:244]     Train net output #0: loss = 0.00753593 (* 1 = 0.00753593 loss)
I0317 10:44:00.330215  3513 sgd_solver.cpp:106] Iteration 19160, lr = 0.01
I0317 10:44:07.657205  3513 solver.cpp:228] Iteration 19180, loss = 0.00433714
I0317 10:44:07.657272  3513 solver.cpp:244]     Train net output #0: loss = 0.00433715 (* 1 = 0.00433715 loss)
I0317 10:44:07.657285  3513 sgd_solver.cpp:106] Iteration 19180, lr = 0.01
I0317 10:44:14.981779  3513 solver.cpp:228] Iteration 19200, loss = 0.00395139
I0317 10:44:14.982002  3513 solver.cpp:244]     Train net output #0: loss = 0.00395141 (* 1 = 0.00395141 loss)
I0317 10:44:14.982017  3513 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0317 10:44:22.301686  3513 solver.cpp:228] Iteration 19220, loss = 0.00199144
I0317 10:44:22.301755  3513 solver.cpp:244]     Train net output #0: loss = 0.00199146 (* 1 = 0.00199146 loss)
I0317 10:44:22.301771  3513 sgd_solver.cpp:106] Iteration 19220, lr = 0.01
I0317 10:44:29.624732  3513 solver.cpp:228] Iteration 19240, loss = 0.00299788
I0317 10:44:29.624799  3513 solver.cpp:244]     Train net output #0: loss = 0.0029979 (* 1 = 0.0029979 loss)
I0317 10:44:29.624812  3513 sgd_solver.cpp:106] Iteration 19240, lr = 0.01
I0317 10:44:32.916625  3513 solver.cpp:337] Iteration 19250, Testing net (#0)
I0317 10:46:26.811928  3513 solver.cpp:404]     Test net output #0: loss = 0.0587003 (* 1 = 0.0587003 loss)
I0317 10:46:26.812063  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64424 (* 1 = 0.64424 loss)
I0317 10:46:30.752094  3513 solver.cpp:228] Iteration 19260, loss = 0.00480741
I0317 10:46:30.752159  3513 solver.cpp:244]     Train net output #0: loss = 0.00480743 (* 1 = 0.00480743 loss)
I0317 10:46:30.752172  3513 sgd_solver.cpp:106] Iteration 19260, lr = 0.01
I0317 10:46:38.015645  3513 solver.cpp:228] Iteration 19280, loss = 0.00636623
I0317 10:46:38.015715  3513 solver.cpp:244]     Train net output #0: loss = 0.00636624 (* 1 = 0.00636624 loss)
I0317 10:46:38.015728  3513 sgd_solver.cpp:106] Iteration 19280, lr = 0.01
I0317 10:46:45.313760  3513 solver.cpp:228] Iteration 19300, loss = 0.00356949
I0317 10:46:45.313827  3513 solver.cpp:244]     Train net output #0: loss = 0.0035695 (* 1 = 0.0035695 loss)
I0317 10:46:45.313840  3513 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0317 10:46:52.624022  3513 solver.cpp:228] Iteration 19320, loss = 0.010101
I0317 10:46:52.624089  3513 solver.cpp:244]     Train net output #0: loss = 0.010101 (* 1 = 0.010101 loss)
I0317 10:46:52.624101  3513 sgd_solver.cpp:106] Iteration 19320, lr = 0.01
I0317 10:46:59.951463  3513 solver.cpp:228] Iteration 19340, loss = 0.00643264
I0317 10:46:59.951635  3513 solver.cpp:244]     Train net output #0: loss = 0.00643266 (* 1 = 0.00643266 loss)
I0317 10:46:59.951650  3513 sgd_solver.cpp:106] Iteration 19340, lr = 0.01
I0317 10:47:07.283996  3513 solver.cpp:228] Iteration 19360, loss = 0.00624719
I0317 10:47:07.284065  3513 solver.cpp:244]     Train net output #0: loss = 0.0062472 (* 1 = 0.0062472 loss)
I0317 10:47:07.284076  3513 sgd_solver.cpp:106] Iteration 19360, lr = 0.01
I0317 10:47:14.610301  3513 solver.cpp:228] Iteration 19380, loss = 0.00451446
I0317 10:47:14.610374  3513 solver.cpp:244]     Train net output #0: loss = 0.00451448 (* 1 = 0.00451448 loss)
I0317 10:47:14.610388  3513 sgd_solver.cpp:106] Iteration 19380, lr = 0.01
I0317 10:47:21.934356  3513 solver.cpp:228] Iteration 19400, loss = 0.0036227
I0317 10:47:21.934424  3513 solver.cpp:244]     Train net output #0: loss = 0.00362272 (* 1 = 0.00362272 loss)
I0317 10:47:21.934437  3513 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0317 10:47:29.264282  3513 solver.cpp:228] Iteration 19420, loss = 0.00593198
I0317 10:47:29.264346  3513 solver.cpp:244]     Train net output #0: loss = 0.005932 (* 1 = 0.005932 loss)
I0317 10:47:29.264358  3513 sgd_solver.cpp:106] Iteration 19420, lr = 0.01
I0317 10:47:36.598795  3513 solver.cpp:228] Iteration 19440, loss = 0.00427857
I0317 10:47:36.599023  3513 solver.cpp:244]     Train net output #0: loss = 0.00427859 (* 1 = 0.00427859 loss)
I0317 10:47:36.599040  3513 sgd_solver.cpp:106] Iteration 19440, lr = 0.01
I0317 10:47:43.927876  3513 solver.cpp:228] Iteration 19460, loss = 0.00517983
I0317 10:47:43.927939  3513 solver.cpp:244]     Train net output #0: loss = 0.00517984 (* 1 = 0.00517984 loss)
I0317 10:47:43.927952  3513 sgd_solver.cpp:106] Iteration 19460, lr = 0.01
I0317 10:47:51.260530  3513 solver.cpp:228] Iteration 19480, loss = 0.00529967
I0317 10:47:51.260597  3513 solver.cpp:244]     Train net output #0: loss = 0.00529969 (* 1 = 0.00529969 loss)
I0317 10:47:51.260610  3513 sgd_solver.cpp:106] Iteration 19480, lr = 0.01
I0317 10:47:58.217676  3513 solver.cpp:337] Iteration 19500, Testing net (#0)
I0317 10:49:52.065254  3513 solver.cpp:404]     Test net output #0: loss = 0.0611507 (* 1 = 0.0611507 loss)
I0317 10:49:52.065378  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66356 (* 1 = 0.66356 loss)
I0317 10:49:52.402300  3513 solver.cpp:228] Iteration 19500, loss = 0.00926256
I0317 10:49:52.402369  3513 solver.cpp:244]     Train net output #0: loss = 0.00926258 (* 1 = 0.00926258 loss)
I0317 10:49:52.402382  3513 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0317 10:49:59.659334  3513 solver.cpp:228] Iteration 19520, loss = 0.00843603
I0317 10:49:59.659406  3513 solver.cpp:244]     Train net output #0: loss = 0.00843605 (* 1 = 0.00843605 loss)
I0317 10:49:59.659420  3513 sgd_solver.cpp:106] Iteration 19520, lr = 0.01
I0317 10:50:06.963762  3513 solver.cpp:228] Iteration 19540, loss = 0.0070663
I0317 10:50:06.963830  3513 solver.cpp:244]     Train net output #0: loss = 0.00706632 (* 1 = 0.00706632 loss)
I0317 10:50:06.963843  3513 sgd_solver.cpp:106] Iteration 19540, lr = 0.01
I0317 10:50:14.282510  3513 solver.cpp:228] Iteration 19560, loss = 0.00410619
I0317 10:50:14.282579  3513 solver.cpp:244]     Train net output #0: loss = 0.00410621 (* 1 = 0.00410621 loss)
I0317 10:50:14.282593  3513 sgd_solver.cpp:106] Iteration 19560, lr = 0.01
I0317 10:50:21.609617  3513 solver.cpp:228] Iteration 19580, loss = 0.00298157
I0317 10:50:21.609684  3513 solver.cpp:244]     Train net output #0: loss = 0.00298158 (* 1 = 0.00298158 loss)
I0317 10:50:21.609697  3513 sgd_solver.cpp:106] Iteration 19580, lr = 0.01
I0317 10:50:28.938732  3513 solver.cpp:228] Iteration 19600, loss = 0.00581548
I0317 10:50:28.938885  3513 solver.cpp:244]     Train net output #0: loss = 0.00581549 (* 1 = 0.00581549 loss)
I0317 10:50:28.938899  3513 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0317 10:50:36.266260  3513 solver.cpp:228] Iteration 19620, loss = 0.00268885
I0317 10:50:36.266332  3513 solver.cpp:244]     Train net output #0: loss = 0.00268887 (* 1 = 0.00268887 loss)
I0317 10:50:36.266345  3513 sgd_solver.cpp:106] Iteration 19620, lr = 0.01
I0317 10:50:43.595245  3513 solver.cpp:228] Iteration 19640, loss = 0.00397094
I0317 10:50:43.595309  3513 solver.cpp:244]     Train net output #0: loss = 0.00397096 (* 1 = 0.00397096 loss)
I0317 10:50:43.595320  3513 sgd_solver.cpp:106] Iteration 19640, lr = 0.01
I0317 10:50:50.926456  3513 solver.cpp:228] Iteration 19660, loss = 0.00493948
I0317 10:50:50.926517  3513 solver.cpp:244]     Train net output #0: loss = 0.00493949 (* 1 = 0.00493949 loss)
I0317 10:50:50.926530  3513 sgd_solver.cpp:106] Iteration 19660, lr = 0.01
I0317 10:50:58.252936  3513 solver.cpp:228] Iteration 19680, loss = 0.00687773
I0317 10:50:58.253003  3513 solver.cpp:244]     Train net output #0: loss = 0.00687775 (* 1 = 0.00687775 loss)
I0317 10:50:58.253016  3513 sgd_solver.cpp:106] Iteration 19680, lr = 0.01
I0317 10:51:05.577422  3513 solver.cpp:228] Iteration 19700, loss = 0.00667375
I0317 10:51:05.577626  3513 solver.cpp:244]     Train net output #0: loss = 0.00667377 (* 1 = 0.00667377 loss)
I0317 10:51:05.577648  3513 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0317 10:51:12.902842  3513 solver.cpp:228] Iteration 19720, loss = 0.00602469
I0317 10:51:12.902910  3513 solver.cpp:244]     Train net output #0: loss = 0.0060247 (* 1 = 0.0060247 loss)
I0317 10:51:12.902925  3513 sgd_solver.cpp:106] Iteration 19720, lr = 0.01
I0317 10:51:20.228003  3513 solver.cpp:228] Iteration 19740, loss = 0.00310506
I0317 10:51:20.228070  3513 solver.cpp:244]     Train net output #0: loss = 0.00310507 (* 1 = 0.00310507 loss)
I0317 10:51:20.228082  3513 sgd_solver.cpp:106] Iteration 19740, lr = 0.01
I0317 10:51:23.523748  3513 solver.cpp:337] Iteration 19750, Testing net (#0)
I0317 10:53:17.371009  3513 solver.cpp:404]     Test net output #0: loss = 0.0618761 (* 1 = 0.0618761 loss)
I0317 10:53:17.371145  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.672959 (* 1 = 0.672959 loss)
I0317 10:53:21.319741  3513 solver.cpp:228] Iteration 19760, loss = 0.00235399
I0317 10:53:21.319809  3513 solver.cpp:244]     Train net output #0: loss = 0.00235401 (* 1 = 0.00235401 loss)
I0317 10:53:21.319823  3513 sgd_solver.cpp:106] Iteration 19760, lr = 0.01
I0317 10:53:28.603135  3513 solver.cpp:228] Iteration 19780, loss = 0.00364158
I0317 10:53:28.603209  3513 solver.cpp:244]     Train net output #0: loss = 0.0036416 (* 1 = 0.0036416 loss)
I0317 10:53:28.603222  3513 sgd_solver.cpp:106] Iteration 19780, lr = 0.01
I0317 10:53:35.904609  3513 solver.cpp:228] Iteration 19800, loss = 0.0045649
I0317 10:53:35.904678  3513 solver.cpp:244]     Train net output #0: loss = 0.00456491 (* 1 = 0.00456491 loss)
I0317 10:53:35.904692  3513 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0317 10:53:43.219758  3513 solver.cpp:228] Iteration 19820, loss = 0.00675738
I0317 10:53:43.219825  3513 solver.cpp:244]     Train net output #0: loss = 0.0067574 (* 1 = 0.0067574 loss)
I0317 10:53:43.219838  3513 sgd_solver.cpp:106] Iteration 19820, lr = 0.01
I0317 10:53:50.550184  3513 solver.cpp:228] Iteration 19840, loss = 0.00604234
I0317 10:53:50.550312  3513 solver.cpp:244]     Train net output #0: loss = 0.00604235 (* 1 = 0.00604235 loss)
I0317 10:53:50.550325  3513 sgd_solver.cpp:106] Iteration 19840, lr = 0.01
I0317 10:53:57.891162  3513 solver.cpp:228] Iteration 19860, loss = 0.00839495
I0317 10:53:57.891229  3513 solver.cpp:244]     Train net output #0: loss = 0.00839497 (* 1 = 0.00839497 loss)
I0317 10:53:57.891242  3513 sgd_solver.cpp:106] Iteration 19860, lr = 0.01
I0317 10:54:05.225064  3513 solver.cpp:228] Iteration 19880, loss = 0.00669794
I0317 10:54:05.225128  3513 solver.cpp:244]     Train net output #0: loss = 0.00669796 (* 1 = 0.00669796 loss)
I0317 10:54:05.225141  3513 sgd_solver.cpp:106] Iteration 19880, lr = 0.01
I0317 10:54:12.560482  3513 solver.cpp:228] Iteration 19900, loss = 0.00386136
I0317 10:54:12.560549  3513 solver.cpp:244]     Train net output #0: loss = 0.00386138 (* 1 = 0.00386138 loss)
I0317 10:54:12.560562  3513 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0317 10:54:19.898020  3513 solver.cpp:228] Iteration 19920, loss = 0.00212112
I0317 10:54:19.898088  3513 solver.cpp:244]     Train net output #0: loss = 0.00212114 (* 1 = 0.00212114 loss)
I0317 10:54:19.898102  3513 sgd_solver.cpp:106] Iteration 19920, lr = 0.01
I0317 10:54:27.227921  3513 solver.cpp:228] Iteration 19940, loss = 0.00290183
I0317 10:54:27.228075  3513 solver.cpp:244]     Train net output #0: loss = 0.00290184 (* 1 = 0.00290184 loss)
I0317 10:54:27.228091  3513 sgd_solver.cpp:106] Iteration 19940, lr = 0.01
I0317 10:54:34.563798  3513 solver.cpp:228] Iteration 19960, loss = 0.00486681
I0317 10:54:34.563866  3513 solver.cpp:244]     Train net output #0: loss = 0.00486682 (* 1 = 0.00486682 loss)
I0317 10:54:34.563879  3513 sgd_solver.cpp:106] Iteration 19960, lr = 0.01
I0317 10:54:41.894713  3513 solver.cpp:228] Iteration 19980, loss = 0.00401286
I0317 10:54:41.894783  3513 solver.cpp:244]     Train net output #0: loss = 0.00401287 (* 1 = 0.00401287 loss)
I0317 10:54:41.894795  3513 sgd_solver.cpp:106] Iteration 19980, lr = 0.01
I0317 10:54:48.859333  3513 solver.cpp:454] Snapshotting to binary proto file ./caffe_alexnet_train_iter_20000.caffemodel
I0317 10:54:50.539790  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./caffe_alexnet_train_iter_20000.solverstate
I0317 10:54:50.949952  3513 solver.cpp:337] Iteration 20000, Testing net (#0)
I0317 10:56:44.770493  3513 solver.cpp:404]     Test net output #0: loss = 0.0637698 (* 1 = 0.0637698 loss)
I0317 10:56:44.770684  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 10:56:45.106371  3513 solver.cpp:228] Iteration 20000, loss = 0.00531715
I0317 10:56:45.106438  3513 solver.cpp:244]     Train net output #0: loss = 0.00531717 (* 1 = 0.00531717 loss)
I0317 10:56:45.106451  3513 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0317 10:56:52.351672  3513 solver.cpp:228] Iteration 20020, loss = 0.00534552
I0317 10:56:52.351740  3513 solver.cpp:244]     Train net output #0: loss = 0.00534554 (* 1 = 0.00534554 loss)
I0317 10:56:52.351753  3513 sgd_solver.cpp:106] Iteration 20020, lr = 0.01
I0317 10:56:59.644670  3513 solver.cpp:228] Iteration 20040, loss = 0.0074155
I0317 10:56:59.644729  3513 solver.cpp:244]     Train net output #0: loss = 0.00741552 (* 1 = 0.00741552 loss)
I0317 10:56:59.644742  3513 sgd_solver.cpp:106] Iteration 20040, lr = 0.01
I0317 10:57:06.954607  3513 solver.cpp:228] Iteration 20060, loss = 0.00418932
I0317 10:57:06.954670  3513 solver.cpp:244]     Train net output #0: loss = 0.00418933 (* 1 = 0.00418933 loss)
I0317 10:57:06.954684  3513 sgd_solver.cpp:106] Iteration 20060, lr = 0.01
I0317 10:57:14.274816  3513 solver.cpp:228] Iteration 20080, loss = 0.0043231
I0317 10:57:14.274891  3513 solver.cpp:244]     Train net output #0: loss = 0.00432311 (* 1 = 0.00432311 loss)
I0317 10:57:14.274905  3513 sgd_solver.cpp:106] Iteration 20080, lr = 0.01
I0317 10:57:21.606894  3513 solver.cpp:228] Iteration 20100, loss = 0.00497918
I0317 10:57:21.607060  3513 solver.cpp:244]     Train net output #0: loss = 0.00497919 (* 1 = 0.00497919 loss)
I0317 10:57:21.607074  3513 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0317 10:57:28.940474  3513 solver.cpp:228] Iteration 20120, loss = 0.00215277
I0317 10:57:28.940541  3513 solver.cpp:244]     Train net output #0: loss = 0.00215278 (* 1 = 0.00215278 loss)
I0317 10:57:28.940556  3513 sgd_solver.cpp:106] Iteration 20120, lr = 0.01
I0317 10:57:36.267909  3513 solver.cpp:228] Iteration 20140, loss = 0.00274707
I0317 10:57:36.267976  3513 solver.cpp:244]     Train net output #0: loss = 0.00274708 (* 1 = 0.00274708 loss)
I0317 10:57:36.267988  3513 sgd_solver.cpp:106] Iteration 20140, lr = 0.01
I0317 10:57:43.598812  3513 solver.cpp:228] Iteration 20160, loss = 0.00485995
I0317 10:57:43.598881  3513 solver.cpp:244]     Train net output #0: loss = 0.00485996 (* 1 = 0.00485996 loss)
I0317 10:57:43.598894  3513 sgd_solver.cpp:106] Iteration 20160, lr = 0.01
I0317 10:57:50.926895  3513 solver.cpp:228] Iteration 20180, loss = 0.00481612
I0317 10:57:50.926964  3513 solver.cpp:244]     Train net output #0: loss = 0.00481613 (* 1 = 0.00481613 loss)
I0317 10:57:50.926978  3513 sgd_solver.cpp:106] Iteration 20180, lr = 0.01
I0317 10:57:58.256852  3513 solver.cpp:228] Iteration 20200, loss = 0.00265395
I0317 10:57:58.257014  3513 solver.cpp:244]     Train net output #0: loss = 0.00265396 (* 1 = 0.00265396 loss)
I0317 10:57:58.257027  3513 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0317 10:58:05.582484  3513 solver.cpp:228] Iteration 20220, loss = 0.00696659
I0317 10:58:05.582553  3513 solver.cpp:244]     Train net output #0: loss = 0.0069666 (* 1 = 0.0069666 loss)
I0317 10:58:05.582566  3513 sgd_solver.cpp:106] Iteration 20220, lr = 0.01
I0317 10:58:12.901444  3513 solver.cpp:228] Iteration 20240, loss = 0.00657275
I0317 10:58:12.901512  3513 solver.cpp:244]     Train net output #0: loss = 0.00657276 (* 1 = 0.00657276 loss)
I0317 10:58:12.901528  3513 sgd_solver.cpp:106] Iteration 20240, lr = 0.01
I0317 10:58:16.194560  3513 solver.cpp:337] Iteration 20250, Testing net (#0)
I0317 11:00:10.073453  3513 solver.cpp:404]     Test net output #0: loss = 0.0590986 (* 1 = 0.0590986 loss)
I0317 11:00:10.073679  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673079 (* 1 = 0.673079 loss)
I0317 11:00:14.028244  3513 solver.cpp:228] Iteration 20260, loss = 0.004735
I0317 11:00:14.028317  3513 solver.cpp:244]     Train net output #0: loss = 0.00473501 (* 1 = 0.00473501 loss)
I0317 11:00:14.028331  3513 sgd_solver.cpp:106] Iteration 20260, lr = 0.01
I0317 11:00:21.302037  3513 solver.cpp:228] Iteration 20280, loss = 0.0015123
I0317 11:00:21.302099  3513 solver.cpp:244]     Train net output #0: loss = 0.00151231 (* 1 = 0.00151231 loss)
I0317 11:00:21.302112  3513 sgd_solver.cpp:106] Iteration 20280, lr = 0.01
I0317 11:00:28.617202  3513 solver.cpp:228] Iteration 20300, loss = 0.00249653
I0317 11:00:28.617272  3513 solver.cpp:244]     Train net output #0: loss = 0.00249654 (* 1 = 0.00249654 loss)
I0317 11:00:28.617286  3513 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0317 11:00:35.944308  3513 solver.cpp:228] Iteration 20320, loss = 0.00326396
I0317 11:00:35.944377  3513 solver.cpp:244]     Train net output #0: loss = 0.00326398 (* 1 = 0.00326398 loss)
I0317 11:00:35.944391  3513 sgd_solver.cpp:106] Iteration 20320, lr = 0.01
I0317 11:00:43.273520  3513 solver.cpp:228] Iteration 20340, loss = 0.00259661
I0317 11:00:43.273677  3513 solver.cpp:244]     Train net output #0: loss = 0.00259662 (* 1 = 0.00259662 loss)
I0317 11:00:43.273691  3513 sgd_solver.cpp:106] Iteration 20340, lr = 0.01
I0317 11:00:50.605375  3513 solver.cpp:228] Iteration 20360, loss = 0.00539109
I0317 11:00:50.605458  3513 solver.cpp:244]     Train net output #0: loss = 0.00539111 (* 1 = 0.00539111 loss)
I0317 11:00:50.605476  3513 sgd_solver.cpp:106] Iteration 20360, lr = 0.01
I0317 11:00:57.942896  3513 solver.cpp:228] Iteration 20380, loss = 0.00412381
I0317 11:00:57.942963  3513 solver.cpp:244]     Train net output #0: loss = 0.00412383 (* 1 = 0.00412383 loss)
I0317 11:00:57.942976  3513 sgd_solver.cpp:106] Iteration 20380, lr = 0.01
I0317 11:01:05.280081  3513 solver.cpp:228] Iteration 20400, loss = 0.00703495
I0317 11:01:05.280149  3513 solver.cpp:244]     Train net output #0: loss = 0.00703497 (* 1 = 0.00703497 loss)
I0317 11:01:05.280164  3513 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0317 11:01:12.608670  3513 solver.cpp:228] Iteration 20420, loss = 0.00454581
I0317 11:01:12.608741  3513 solver.cpp:244]     Train net output #0: loss = 0.00454583 (* 1 = 0.00454583 loss)
I0317 11:01:12.608755  3513 sgd_solver.cpp:106] Iteration 20420, lr = 0.01
I0317 11:01:19.946275  3513 solver.cpp:228] Iteration 20440, loss = 0.00847497
I0317 11:01:19.946435  3513 solver.cpp:244]     Train net output #0: loss = 0.00847499 (* 1 = 0.00847499 loss)
I0317 11:01:19.946450  3513 sgd_solver.cpp:106] Iteration 20440, lr = 0.01
I0317 11:01:27.279839  3513 solver.cpp:228] Iteration 20460, loss = 0.00314428
I0317 11:01:27.279906  3513 solver.cpp:244]     Train net output #0: loss = 0.0031443 (* 1 = 0.0031443 loss)
I0317 11:01:27.279919  3513 sgd_solver.cpp:106] Iteration 20460, lr = 0.01
I0317 11:01:34.612876  3513 solver.cpp:228] Iteration 20480, loss = 0.00222842
I0317 11:01:34.612951  3513 solver.cpp:244]     Train net output #0: loss = 0.00222844 (* 1 = 0.00222844 loss)
I0317 11:01:34.612965  3513 sgd_solver.cpp:106] Iteration 20480, lr = 0.01
I0317 11:01:41.580986  3513 solver.cpp:337] Iteration 20500, Testing net (#0)
I0317 11:03:35.418467  3513 solver.cpp:404]     Test net output #0: loss = 0.057733 (* 1 = 0.057733 loss)
I0317 11:03:35.418581  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.663401 (* 1 = 0.663401 loss)
I0317 11:03:35.754638  3513 solver.cpp:228] Iteration 20500, loss = 0.00356867
I0317 11:03:35.754719  3513 solver.cpp:244]     Train net output #0: loss = 0.00356868 (* 1 = 0.00356868 loss)
I0317 11:03:35.754734  3513 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0317 11:03:42.994161  3513 solver.cpp:228] Iteration 20520, loss = 0.00258022
I0317 11:03:42.994230  3513 solver.cpp:244]     Train net output #0: loss = 0.00258024 (* 1 = 0.00258024 loss)
I0317 11:03:42.994242  3513 sgd_solver.cpp:106] Iteration 20520, lr = 0.01
I0317 11:03:50.288907  3513 solver.cpp:228] Iteration 20540, loss = 0.00922284
I0317 11:03:50.288975  3513 solver.cpp:244]     Train net output #0: loss = 0.00922286 (* 1 = 0.00922286 loss)
I0317 11:03:50.288987  3513 sgd_solver.cpp:106] Iteration 20540, lr = 0.01
I0317 11:03:57.593582  3513 solver.cpp:228] Iteration 20560, loss = 0.00568925
I0317 11:03:57.593649  3513 solver.cpp:244]     Train net output #0: loss = 0.00568927 (* 1 = 0.00568927 loss)
I0317 11:03:57.593663  3513 sgd_solver.cpp:106] Iteration 20560, lr = 0.01
I0317 11:04:04.916731  3513 solver.cpp:228] Iteration 20580, loss = 0.00465629
I0317 11:04:04.916796  3513 solver.cpp:244]     Train net output #0: loss = 0.00465631 (* 1 = 0.00465631 loss)
I0317 11:04:04.916810  3513 sgd_solver.cpp:106] Iteration 20580, lr = 0.01
I0317 11:04:12.253355  3513 solver.cpp:228] Iteration 20600, loss = 0.00661845
I0317 11:04:12.253571  3513 solver.cpp:244]     Train net output #0: loss = 0.00661847 (* 1 = 0.00661847 loss)
I0317 11:04:12.253585  3513 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0317 11:04:19.588481  3513 solver.cpp:228] Iteration 20620, loss = 0.00550946
I0317 11:04:19.588554  3513 solver.cpp:244]     Train net output #0: loss = 0.00550947 (* 1 = 0.00550947 loss)
I0317 11:04:19.588567  3513 sgd_solver.cpp:106] Iteration 20620, lr = 0.01
I0317 11:04:26.931499  3513 solver.cpp:228] Iteration 20640, loss = 0.00273431
I0317 11:04:26.931571  3513 solver.cpp:244]     Train net output #0: loss = 0.00273433 (* 1 = 0.00273433 loss)
I0317 11:04:26.931584  3513 sgd_solver.cpp:106] Iteration 20640, lr = 0.01
I0317 11:04:34.274103  3513 solver.cpp:228] Iteration 20660, loss = 0.00201585
I0317 11:04:34.274173  3513 solver.cpp:244]     Train net output #0: loss = 0.00201587 (* 1 = 0.00201587 loss)
I0317 11:04:34.274186  3513 sgd_solver.cpp:106] Iteration 20660, lr = 0.01
I0317 11:04:41.608006  3513 solver.cpp:228] Iteration 20680, loss = 0.00143284
I0317 11:04:41.608077  3513 solver.cpp:244]     Train net output #0: loss = 0.00143286 (* 1 = 0.00143286 loss)
I0317 11:04:41.608090  3513 sgd_solver.cpp:106] Iteration 20680, lr = 0.01
I0317 11:04:48.931752  3513 solver.cpp:228] Iteration 20700, loss = 0.0037666
I0317 11:04:48.931898  3513 solver.cpp:244]     Train net output #0: loss = 0.00376662 (* 1 = 0.00376662 loss)
I0317 11:04:48.931912  3513 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0317 11:04:56.258246  3513 solver.cpp:228] Iteration 20720, loss = 0.00747803
I0317 11:04:56.258316  3513 solver.cpp:244]     Train net output #0: loss = 0.00747804 (* 1 = 0.00747804 loss)
I0317 11:04:56.258329  3513 sgd_solver.cpp:106] Iteration 20720, lr = 0.01
I0317 11:05:03.597201  3513 solver.cpp:228] Iteration 20740, loss = 0.00649353
I0317 11:05:03.597275  3513 solver.cpp:244]     Train net output #0: loss = 0.00649355 (* 1 = 0.00649355 loss)
I0317 11:05:03.597297  3513 sgd_solver.cpp:106] Iteration 20740, lr = 0.01
I0317 11:05:06.897929  3513 solver.cpp:337] Iteration 20750, Testing net (#0)
I0317 11:07:00.786207  3513 solver.cpp:404]     Test net output #0: loss = 0.0670592 (* 1 = 0.0670592 loss)
I0317 11:07:00.786334  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.682719 (* 1 = 0.682719 loss)
I0317 11:07:04.738559  3513 solver.cpp:228] Iteration 20760, loss = 0.00940872
I0317 11:07:04.738622  3513 solver.cpp:244]     Train net output #0: loss = 0.00940874 (* 1 = 0.00940874 loss)
I0317 11:07:04.738636  3513 sgd_solver.cpp:106] Iteration 20760, lr = 0.01
I0317 11:07:12.004777  3513 solver.cpp:228] Iteration 20780, loss = 0.00569502
I0317 11:07:12.004847  3513 solver.cpp:244]     Train net output #0: loss = 0.00569504 (* 1 = 0.00569504 loss)
I0317 11:07:12.004860  3513 sgd_solver.cpp:106] Iteration 20780, lr = 0.01
I0317 11:07:19.317814  3513 solver.cpp:228] Iteration 20800, loss = 0.00653568
I0317 11:07:19.317883  3513 solver.cpp:244]     Train net output #0: loss = 0.0065357 (* 1 = 0.0065357 loss)
I0317 11:07:19.317898  3513 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0317 11:07:26.646437  3513 solver.cpp:228] Iteration 20820, loss = 0.00194938
I0317 11:07:26.646503  3513 solver.cpp:244]     Train net output #0: loss = 0.0019494 (* 1 = 0.0019494 loss)
I0317 11:07:26.646515  3513 sgd_solver.cpp:106] Iteration 20820, lr = 0.01
I0317 11:07:33.979986  3513 solver.cpp:228] Iteration 20840, loss = 0.0026027
I0317 11:07:33.980191  3513 solver.cpp:244]     Train net output #0: loss = 0.00260272 (* 1 = 0.00260272 loss)
I0317 11:07:33.980206  3513 sgd_solver.cpp:106] Iteration 20840, lr = 0.01
I0317 11:07:41.311031  3513 solver.cpp:228] Iteration 20860, loss = 0.00322512
I0317 11:07:41.311095  3513 solver.cpp:244]     Train net output #0: loss = 0.00322514 (* 1 = 0.00322514 loss)
I0317 11:07:41.311107  3513 sgd_solver.cpp:106] Iteration 20860, lr = 0.01
I0317 11:07:48.642771  3513 solver.cpp:228] Iteration 20880, loss = 0.00541192
I0317 11:07:48.642839  3513 solver.cpp:244]     Train net output #0: loss = 0.00541194 (* 1 = 0.00541194 loss)
I0317 11:07:48.642853  3513 sgd_solver.cpp:106] Iteration 20880, lr = 0.01
I0317 11:07:55.975400  3513 solver.cpp:228] Iteration 20900, loss = 0.0048874
I0317 11:07:55.975469  3513 solver.cpp:244]     Train net output #0: loss = 0.00488742 (* 1 = 0.00488742 loss)
I0317 11:07:55.975484  3513 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0317 11:08:03.304653  3513 solver.cpp:228] Iteration 20920, loss = 0.00374535
I0317 11:08:03.304724  3513 solver.cpp:244]     Train net output #0: loss = 0.00374537 (* 1 = 0.00374537 loss)
I0317 11:08:03.304738  3513 sgd_solver.cpp:106] Iteration 20920, lr = 0.01
I0317 11:08:10.637037  3513 solver.cpp:228] Iteration 20940, loss = 0.00730166
I0317 11:08:10.637184  3513 solver.cpp:244]     Train net output #0: loss = 0.00730168 (* 1 = 0.00730168 loss)
I0317 11:08:10.637198  3513 sgd_solver.cpp:106] Iteration 20940, lr = 0.01
I0317 11:08:17.971045  3513 solver.cpp:228] Iteration 20960, loss = 0.00645418
I0317 11:08:17.971108  3513 solver.cpp:244]     Train net output #0: loss = 0.0064542 (* 1 = 0.0064542 loss)
I0317 11:08:17.971123  3513 sgd_solver.cpp:106] Iteration 20960, lr = 0.01
I0317 11:08:25.302023  3513 solver.cpp:228] Iteration 20980, loss = 0.00654471
I0317 11:08:25.302094  3513 solver.cpp:244]     Train net output #0: loss = 0.00654473 (* 1 = 0.00654473 loss)
I0317 11:08:25.302108  3513 sgd_solver.cpp:106] Iteration 20980, lr = 0.01
I0317 11:08:32.273458  3513 solver.cpp:337] Iteration 21000, Testing net (#0)
I0317 11:10:26.160686  3513 solver.cpp:404]     Test net output #0: loss = 0.0637432 (* 1 = 0.0637432 loss)
I0317 11:10:26.160817  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6634 (* 1 = 0.6634 loss)
I0317 11:10:26.497114  3513 solver.cpp:228] Iteration 21000, loss = 0.00325619
I0317 11:10:26.497192  3513 solver.cpp:244]     Train net output #0: loss = 0.00325621 (* 1 = 0.00325621 loss)
I0317 11:10:26.497206  3513 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0317 11:10:33.740860  3513 solver.cpp:228] Iteration 21020, loss = 0.00260128
I0317 11:10:33.740932  3513 solver.cpp:244]     Train net output #0: loss = 0.0026013 (* 1 = 0.0026013 loss)
I0317 11:10:33.740945  3513 sgd_solver.cpp:106] Iteration 21020, lr = 0.01
I0317 11:10:41.040525  3513 solver.cpp:228] Iteration 21040, loss = 0.00371136
I0317 11:10:41.040593  3513 solver.cpp:244]     Train net output #0: loss = 0.00371138 (* 1 = 0.00371138 loss)
I0317 11:10:41.040606  3513 sgd_solver.cpp:106] Iteration 21040, lr = 0.01
I0317 11:10:48.357030  3513 solver.cpp:228] Iteration 21060, loss = 0.00513402
I0317 11:10:48.357098  3513 solver.cpp:244]     Train net output #0: loss = 0.00513404 (* 1 = 0.00513404 loss)
I0317 11:10:48.357110  3513 sgd_solver.cpp:106] Iteration 21060, lr = 0.01
I0317 11:10:55.682693  3513 solver.cpp:228] Iteration 21080, loss = 0.00734564
I0317 11:10:55.682760  3513 solver.cpp:244]     Train net output #0: loss = 0.00734566 (* 1 = 0.00734566 loss)
I0317 11:10:55.682773  3513 sgd_solver.cpp:106] Iteration 21080, lr = 0.01
I0317 11:11:03.004775  3513 solver.cpp:228] Iteration 21100, loss = 0.00426419
I0317 11:11:03.004976  3513 solver.cpp:244]     Train net output #0: loss = 0.00426421 (* 1 = 0.00426421 loss)
I0317 11:11:03.004989  3513 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0317 11:11:10.326797  3513 solver.cpp:228] Iteration 21120, loss = 0.0128556
I0317 11:11:10.326861  3513 solver.cpp:244]     Train net output #0: loss = 0.0128556 (* 1 = 0.0128556 loss)
I0317 11:11:10.326874  3513 sgd_solver.cpp:106] Iteration 21120, lr = 0.01
I0317 11:11:17.639179  3513 solver.cpp:228] Iteration 21140, loss = 0.00519086
I0317 11:11:17.639250  3513 solver.cpp:244]     Train net output #0: loss = 0.00519088 (* 1 = 0.00519088 loss)
I0317 11:11:17.639262  3513 sgd_solver.cpp:106] Iteration 21140, lr = 0.01
I0317 11:11:24.962864  3513 solver.cpp:228] Iteration 21160, loss = 0.00617504
I0317 11:11:24.962927  3513 solver.cpp:244]     Train net output #0: loss = 0.00617506 (* 1 = 0.00617506 loss)
I0317 11:11:24.962939  3513 sgd_solver.cpp:106] Iteration 21160, lr = 0.01
I0317 11:11:32.280614  3513 solver.cpp:228] Iteration 21180, loss = 0.00240633
I0317 11:11:32.280685  3513 solver.cpp:244]     Train net output #0: loss = 0.00240635 (* 1 = 0.00240635 loss)
I0317 11:11:32.280699  3513 sgd_solver.cpp:106] Iteration 21180, lr = 0.01
I0317 11:11:39.605418  3513 solver.cpp:228] Iteration 21200, loss = 0.00324762
I0317 11:11:39.605578  3513 solver.cpp:244]     Train net output #0: loss = 0.00324764 (* 1 = 0.00324764 loss)
I0317 11:11:39.605593  3513 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0317 11:11:46.931143  3513 solver.cpp:228] Iteration 21220, loss = 0.0040489
I0317 11:11:46.931212  3513 solver.cpp:244]     Train net output #0: loss = 0.00404893 (* 1 = 0.00404893 loss)
I0317 11:11:46.931226  3513 sgd_solver.cpp:106] Iteration 21220, lr = 0.01
I0317 11:11:54.263393  3513 solver.cpp:228] Iteration 21240, loss = 0.00484345
I0317 11:11:54.263463  3513 solver.cpp:244]     Train net output #0: loss = 0.00484347 (* 1 = 0.00484347 loss)
I0317 11:11:54.263476  3513 sgd_solver.cpp:106] Iteration 21240, lr = 0.01
I0317 11:11:57.559607  3513 solver.cpp:337] Iteration 21250, Testing net (#0)
I0317 11:13:51.448127  3513 solver.cpp:404]     Test net output #0: loss = 0.0612808 (* 1 = 0.0612808 loss)
I0317 11:13:51.448249  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 11:13:55.393828  3513 solver.cpp:228] Iteration 21260, loss = 0.00472416
I0317 11:13:55.393885  3513 solver.cpp:244]     Train net output #0: loss = 0.00472418 (* 1 = 0.00472418 loss)
I0317 11:13:55.393898  3513 sgd_solver.cpp:106] Iteration 21260, lr = 0.01
I0317 11:14:02.659260  3513 solver.cpp:228] Iteration 21280, loss = 0.00321714
I0317 11:14:02.659328  3513 solver.cpp:244]     Train net output #0: loss = 0.00321716 (* 1 = 0.00321716 loss)
I0317 11:14:02.659342  3513 sgd_solver.cpp:106] Iteration 21280, lr = 0.01
I0317 11:14:09.967407  3513 solver.cpp:228] Iteration 21300, loss = 0.00650977
I0317 11:14:09.967481  3513 solver.cpp:244]     Train net output #0: loss = 0.00650979 (* 1 = 0.00650979 loss)
I0317 11:14:09.967494  3513 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0317 11:14:17.291205  3513 solver.cpp:228] Iteration 21320, loss = 0.0106028
I0317 11:14:17.291276  3513 solver.cpp:244]     Train net output #0: loss = 0.0106028 (* 1 = 0.0106028 loss)
I0317 11:14:17.291290  3513 sgd_solver.cpp:106] Iteration 21320, lr = 0.01
I0317 11:14:24.618427  3513 solver.cpp:228] Iteration 21340, loss = 0.00703678
I0317 11:14:24.618568  3513 solver.cpp:244]     Train net output #0: loss = 0.00703681 (* 1 = 0.00703681 loss)
I0317 11:14:24.618582  3513 sgd_solver.cpp:106] Iteration 21340, lr = 0.01
I0317 11:14:31.947871  3513 solver.cpp:228] Iteration 21360, loss = 0.00218635
I0317 11:14:31.947952  3513 solver.cpp:244]     Train net output #0: loss = 0.00218637 (* 1 = 0.00218637 loss)
I0317 11:14:31.947968  3513 sgd_solver.cpp:106] Iteration 21360, lr = 0.01
I0317 11:14:39.279579  3513 solver.cpp:228] Iteration 21380, loss = 0.0026954
I0317 11:14:39.279642  3513 solver.cpp:244]     Train net output #0: loss = 0.00269543 (* 1 = 0.00269543 loss)
I0317 11:14:39.279655  3513 sgd_solver.cpp:106] Iteration 21380, lr = 0.01
I0317 11:14:46.600878  3513 solver.cpp:228] Iteration 21400, loss = 0.00240342
I0317 11:14:46.600946  3513 solver.cpp:244]     Train net output #0: loss = 0.00240344 (* 1 = 0.00240344 loss)
I0317 11:14:46.600961  3513 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0317 11:14:53.916895  3513 solver.cpp:228] Iteration 21420, loss = 0.00391973
I0317 11:14:53.916965  3513 solver.cpp:244]     Train net output #0: loss = 0.00391975 (* 1 = 0.00391975 loss)
I0317 11:14:53.916978  3513 sgd_solver.cpp:106] Iteration 21420, lr = 0.01
I0317 11:15:01.243137  3513 solver.cpp:228] Iteration 21440, loss = 0.00224493
I0317 11:15:01.243345  3513 solver.cpp:244]     Train net output #0: loss = 0.00224495 (* 1 = 0.00224495 loss)
I0317 11:15:01.243358  3513 sgd_solver.cpp:106] Iteration 21440, lr = 0.01
I0317 11:15:08.571154  3513 solver.cpp:228] Iteration 21460, loss = 0.00309591
I0317 11:15:08.571233  3513 solver.cpp:244]     Train net output #0: loss = 0.00309593 (* 1 = 0.00309593 loss)
I0317 11:15:08.571251  3513 sgd_solver.cpp:106] Iteration 21460, lr = 0.01
I0317 11:15:15.899183  3513 solver.cpp:228] Iteration 21480, loss = 0.00792683
I0317 11:15:15.899255  3513 solver.cpp:244]     Train net output #0: loss = 0.00792685 (* 1 = 0.00792685 loss)
I0317 11:15:15.899268  3513 sgd_solver.cpp:106] Iteration 21480, lr = 0.01
I0317 11:15:22.860724  3513 solver.cpp:337] Iteration 21500, Testing net (#0)
I0317 11:17:16.729884  3513 solver.cpp:404]     Test net output #0: loss = 0.0629185 (* 1 = 0.0629185 loss)
I0317 11:17:16.730026  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 11:17:17.066368  3513 solver.cpp:228] Iteration 21500, loss = 0.0056344
I0317 11:17:17.066435  3513 solver.cpp:244]     Train net output #0: loss = 0.00563442 (* 1 = 0.00563442 loss)
I0317 11:17:17.066448  3513 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0317 11:17:24.307839  3513 solver.cpp:228] Iteration 21520, loss = 0.00644465
I0317 11:17:24.307909  3513 solver.cpp:244]     Train net output #0: loss = 0.00644468 (* 1 = 0.00644468 loss)
I0317 11:17:24.307921  3513 sgd_solver.cpp:106] Iteration 21520, lr = 0.01
I0317 11:17:31.606899  3513 solver.cpp:228] Iteration 21540, loss = 0.0039798
I0317 11:17:31.606966  3513 solver.cpp:244]     Train net output #0: loss = 0.00397983 (* 1 = 0.00397983 loss)
I0317 11:17:31.606979  3513 sgd_solver.cpp:106] Iteration 21540, lr = 0.01
I0317 11:17:38.928169  3513 solver.cpp:228] Iteration 21560, loss = 0.00184875
I0317 11:17:38.928233  3513 solver.cpp:244]     Train net output #0: loss = 0.00184877 (* 1 = 0.00184877 loss)
I0317 11:17:38.928246  3513 sgd_solver.cpp:106] Iteration 21560, lr = 0.01
I0317 11:17:46.267648  3513 solver.cpp:228] Iteration 21580, loss = 0.00281833
I0317 11:17:46.267714  3513 solver.cpp:244]     Train net output #0: loss = 0.00281835 (* 1 = 0.00281835 loss)
I0317 11:17:46.267727  3513 sgd_solver.cpp:106] Iteration 21580, lr = 0.01
I0317 11:17:53.607578  3513 solver.cpp:228] Iteration 21600, loss = 0.00266802
I0317 11:17:53.607727  3513 solver.cpp:244]     Train net output #0: loss = 0.00266805 (* 1 = 0.00266805 loss)
I0317 11:17:53.607741  3513 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0317 11:18:00.936749  3513 solver.cpp:228] Iteration 21620, loss = 0.00341974
I0317 11:18:00.936816  3513 solver.cpp:244]     Train net output #0: loss = 0.00341977 (* 1 = 0.00341977 loss)
I0317 11:18:00.936830  3513 sgd_solver.cpp:106] Iteration 21620, lr = 0.01
I0317 11:18:08.263903  3513 solver.cpp:228] Iteration 21640, loss = 0.00272964
I0317 11:18:08.263977  3513 solver.cpp:244]     Train net output #0: loss = 0.00272966 (* 1 = 0.00272966 loss)
I0317 11:18:08.263990  3513 sgd_solver.cpp:106] Iteration 21640, lr = 0.01
I0317 11:18:15.596253  3513 solver.cpp:228] Iteration 21660, loss = 0.00596411
I0317 11:18:15.596320  3513 solver.cpp:244]     Train net output #0: loss = 0.00596413 (* 1 = 0.00596413 loss)
I0317 11:18:15.596334  3513 sgd_solver.cpp:106] Iteration 21660, lr = 0.01
I0317 11:18:22.926537  3513 solver.cpp:228] Iteration 21680, loss = 0.00622355
I0317 11:18:22.926604  3513 solver.cpp:244]     Train net output #0: loss = 0.00622357 (* 1 = 0.00622357 loss)
I0317 11:18:22.926616  3513 sgd_solver.cpp:106] Iteration 21680, lr = 0.01
I0317 11:18:30.248225  3513 solver.cpp:228] Iteration 21700, loss = 0.00608261
I0317 11:18:30.248431  3513 solver.cpp:244]     Train net output #0: loss = 0.00608263 (* 1 = 0.00608263 loss)
I0317 11:18:30.248446  3513 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0317 11:18:37.562116  3513 solver.cpp:228] Iteration 21720, loss = 0.00471488
I0317 11:18:37.562186  3513 solver.cpp:244]     Train net output #0: loss = 0.0047149 (* 1 = 0.0047149 loss)
I0317 11:18:37.562201  3513 sgd_solver.cpp:106] Iteration 21720, lr = 0.01
I0317 11:18:44.876835  3513 solver.cpp:228] Iteration 21740, loss = 0.00262968
I0317 11:18:44.876909  3513 solver.cpp:244]     Train net output #0: loss = 0.0026297 (* 1 = 0.0026297 loss)
I0317 11:18:44.876921  3513 sgd_solver.cpp:106] Iteration 21740, lr = 0.01
I0317 11:18:48.165740  3513 solver.cpp:337] Iteration 21750, Testing net (#0)
I0317 11:20:42.059208  3513 solver.cpp:404]     Test net output #0: loss = 0.0610212 (* 1 = 0.0610212 loss)
I0317 11:20:42.059353  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6538 (* 1 = 0.6538 loss)
I0317 11:20:46.008466  3513 solver.cpp:228] Iteration 21760, loss = 0.00369216
I0317 11:20:46.008533  3513 solver.cpp:244]     Train net output #0: loss = 0.00369218 (* 1 = 0.00369218 loss)
I0317 11:20:46.008546  3513 sgd_solver.cpp:106] Iteration 21760, lr = 0.01
I0317 11:20:53.291077  3513 solver.cpp:228] Iteration 21780, loss = 0.00297936
I0317 11:20:53.291147  3513 solver.cpp:244]     Train net output #0: loss = 0.00297939 (* 1 = 0.00297939 loss)
I0317 11:20:53.291160  3513 sgd_solver.cpp:106] Iteration 21780, lr = 0.01
I0317 11:21:00.591758  3513 solver.cpp:228] Iteration 21800, loss = 0.0059519
I0317 11:21:00.591832  3513 solver.cpp:244]     Train net output #0: loss = 0.00595192 (* 1 = 0.00595192 loss)
I0317 11:21:00.591845  3513 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0317 11:21:07.897969  3513 solver.cpp:228] Iteration 21820, loss = 0.0035345
I0317 11:21:07.898036  3513 solver.cpp:244]     Train net output #0: loss = 0.00353452 (* 1 = 0.00353452 loss)
I0317 11:21:07.898049  3513 sgd_solver.cpp:106] Iteration 21820, lr = 0.01
I0317 11:21:15.219095  3513 solver.cpp:228] Iteration 21840, loss = 0.00503408
I0317 11:21:15.219238  3513 solver.cpp:244]     Train net output #0: loss = 0.0050341 (* 1 = 0.0050341 loss)
I0317 11:21:15.219251  3513 sgd_solver.cpp:106] Iteration 21840, lr = 0.01
I0317 11:21:22.524399  3513 solver.cpp:228] Iteration 21860, loss = 0.00645581
I0317 11:21:22.524468  3513 solver.cpp:244]     Train net output #0: loss = 0.00645584 (* 1 = 0.00645584 loss)
I0317 11:21:22.524482  3513 sgd_solver.cpp:106] Iteration 21860, lr = 0.01
I0317 11:21:29.836773  3513 solver.cpp:228] Iteration 21880, loss = 0.00483089
I0317 11:21:29.836839  3513 solver.cpp:244]     Train net output #0: loss = 0.00483092 (* 1 = 0.00483092 loss)
I0317 11:21:29.836853  3513 sgd_solver.cpp:106] Iteration 21880, lr = 0.01
I0317 11:21:37.151684  3513 solver.cpp:228] Iteration 21900, loss = 0.00272285
I0317 11:21:37.151752  3513 solver.cpp:244]     Train net output #0: loss = 0.00272287 (* 1 = 0.00272287 loss)
I0317 11:21:37.151765  3513 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0317 11:21:44.466367  3513 solver.cpp:228] Iteration 21920, loss = 0.00327903
I0317 11:21:44.466434  3513 solver.cpp:244]     Train net output #0: loss = 0.00327906 (* 1 = 0.00327906 loss)
I0317 11:21:44.466447  3513 sgd_solver.cpp:106] Iteration 21920, lr = 0.01
I0317 11:21:51.789885  3513 solver.cpp:228] Iteration 21940, loss = 0.00272665
I0317 11:21:51.790088  3513 solver.cpp:244]     Train net output #0: loss = 0.00272667 (* 1 = 0.00272667 loss)
I0317 11:21:51.790109  3513 sgd_solver.cpp:106] Iteration 21940, lr = 0.01
I0317 11:21:59.113651  3513 solver.cpp:228] Iteration 21960, loss = 0.00232855
I0317 11:21:59.113713  3513 solver.cpp:244]     Train net output #0: loss = 0.00232858 (* 1 = 0.00232858 loss)
I0317 11:21:59.113726  3513 sgd_solver.cpp:106] Iteration 21960, lr = 0.01
I0317 11:22:06.441998  3513 solver.cpp:228] Iteration 21980, loss = 0.00352194
I0317 11:22:06.442060  3513 solver.cpp:244]     Train net output #0: loss = 0.00352196 (* 1 = 0.00352196 loss)
I0317 11:22:06.442073  3513 sgd_solver.cpp:106] Iteration 21980, lr = 0.01
I0317 11:22:13.395900  3513 solver.cpp:337] Iteration 22000, Testing net (#0)
I0317 11:24:07.250150  3513 solver.cpp:404]     Test net output #0: loss = 0.0608247 (* 1 = 0.0608247 loss)
I0317 11:24:07.250268  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6636 (* 1 = 0.6636 loss)
I0317 11:24:07.585980  3513 solver.cpp:228] Iteration 22000, loss = 0.00321008
I0317 11:24:07.586045  3513 solver.cpp:244]     Train net output #0: loss = 0.00321011 (* 1 = 0.00321011 loss)
I0317 11:24:07.586057  3513 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0317 11:24:14.827229  3513 solver.cpp:228] Iteration 22020, loss = 0.0103861
I0317 11:24:14.827297  3513 solver.cpp:244]     Train net output #0: loss = 0.0103861 (* 1 = 0.0103861 loss)
I0317 11:24:14.827311  3513 sgd_solver.cpp:106] Iteration 22020, lr = 0.01
I0317 11:24:22.120626  3513 solver.cpp:228] Iteration 22040, loss = 0.0049394
I0317 11:24:22.120700  3513 solver.cpp:244]     Train net output #0: loss = 0.00493942 (* 1 = 0.00493942 loss)
I0317 11:24:22.120714  3513 sgd_solver.cpp:106] Iteration 22040, lr = 0.01
I0317 11:24:29.435139  3513 solver.cpp:228] Iteration 22060, loss = 0.00523769
I0317 11:24:29.435205  3513 solver.cpp:244]     Train net output #0: loss = 0.00523771 (* 1 = 0.00523771 loss)
I0317 11:24:29.435219  3513 sgd_solver.cpp:106] Iteration 22060, lr = 0.01
I0317 11:24:36.761369  3513 solver.cpp:228] Iteration 22080, loss = 0.00394573
I0317 11:24:36.761437  3513 solver.cpp:244]     Train net output #0: loss = 0.00394575 (* 1 = 0.00394575 loss)
I0317 11:24:36.761451  3513 sgd_solver.cpp:106] Iteration 22080, lr = 0.01
I0317 11:24:44.094573  3513 solver.cpp:228] Iteration 22100, loss = 0.00393909
I0317 11:24:44.094723  3513 solver.cpp:244]     Train net output #0: loss = 0.00393911 (* 1 = 0.00393911 loss)
I0317 11:24:44.094736  3513 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0317 11:24:51.428812  3513 solver.cpp:228] Iteration 22120, loss = 0.00333266
I0317 11:24:51.428879  3513 solver.cpp:244]     Train net output #0: loss = 0.00333268 (* 1 = 0.00333268 loss)
I0317 11:24:51.428891  3513 sgd_solver.cpp:106] Iteration 22120, lr = 0.01
I0317 11:24:58.748467  3513 solver.cpp:228] Iteration 22140, loss = 0.00333838
I0317 11:24:58.748530  3513 solver.cpp:244]     Train net output #0: loss = 0.0033384 (* 1 = 0.0033384 loss)
I0317 11:24:58.748543  3513 sgd_solver.cpp:106] Iteration 22140, lr = 0.01
I0317 11:25:06.069174  3513 solver.cpp:228] Iteration 22160, loss = 0.00401479
I0317 11:25:06.069247  3513 solver.cpp:244]     Train net output #0: loss = 0.00401481 (* 1 = 0.00401481 loss)
I0317 11:25:06.069260  3513 sgd_solver.cpp:106] Iteration 22160, lr = 0.01
I0317 11:25:13.388654  3513 solver.cpp:228] Iteration 22180, loss = 0.00404524
I0317 11:25:13.388721  3513 solver.cpp:244]     Train net output #0: loss = 0.00404527 (* 1 = 0.00404527 loss)
I0317 11:25:13.388734  3513 sgd_solver.cpp:106] Iteration 22180, lr = 0.01
I0317 11:25:20.708412  3513 solver.cpp:228] Iteration 22200, loss = 0.00440868
I0317 11:25:20.708514  3513 solver.cpp:244]     Train net output #0: loss = 0.0044087 (* 1 = 0.0044087 loss)
I0317 11:25:20.708528  3513 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0317 11:25:28.044865  3513 solver.cpp:228] Iteration 22220, loss = 0.00523811
I0317 11:25:28.044930  3513 solver.cpp:244]     Train net output #0: loss = 0.00523813 (* 1 = 0.00523813 loss)
I0317 11:25:28.044944  3513 sgd_solver.cpp:106] Iteration 22220, lr = 0.01
I0317 11:25:35.371606  3513 solver.cpp:228] Iteration 22240, loss = 0.00508298
I0317 11:25:35.371681  3513 solver.cpp:244]     Train net output #0: loss = 0.00508301 (* 1 = 0.00508301 loss)
I0317 11:25:35.371695  3513 sgd_solver.cpp:106] Iteration 22240, lr = 0.01
I0317 11:25:38.663359  3513 solver.cpp:337] Iteration 22250, Testing net (#0)
I0317 11:27:32.510469  3513 solver.cpp:404]     Test net output #0: loss = 0.0602347 (* 1 = 0.0602347 loss)
I0317 11:27:32.510642  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 11:27:36.457620  3513 solver.cpp:228] Iteration 22260, loss = 0.00336043
I0317 11:27:36.457689  3513 solver.cpp:244]     Train net output #0: loss = 0.00336045 (* 1 = 0.00336045 loss)
I0317 11:27:36.457701  3513 sgd_solver.cpp:106] Iteration 22260, lr = 0.01
I0317 11:27:43.736340  3513 solver.cpp:228] Iteration 22280, loss = 0.00288265
I0317 11:27:43.736402  3513 solver.cpp:244]     Train net output #0: loss = 0.00288267 (* 1 = 0.00288267 loss)
I0317 11:27:43.736414  3513 sgd_solver.cpp:106] Iteration 22280, lr = 0.01
I0317 11:27:51.045027  3513 solver.cpp:228] Iteration 22300, loss = 0.00266663
I0317 11:27:51.045092  3513 solver.cpp:244]     Train net output #0: loss = 0.00266665 (* 1 = 0.00266665 loss)
I0317 11:27:51.045106  3513 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0317 11:27:58.368161  3513 solver.cpp:228] Iteration 22320, loss = 0.00548946
I0317 11:27:58.368247  3513 solver.cpp:244]     Train net output #0: loss = 0.00548948 (* 1 = 0.00548948 loss)
I0317 11:27:58.368259  3513 sgd_solver.cpp:106] Iteration 22320, lr = 0.01
I0317 11:28:05.707651  3513 solver.cpp:228] Iteration 22340, loss = 0.00428351
I0317 11:28:05.707792  3513 solver.cpp:244]     Train net output #0: loss = 0.00428353 (* 1 = 0.00428353 loss)
I0317 11:28:05.707805  3513 sgd_solver.cpp:106] Iteration 22340, lr = 0.01
I0317 11:28:13.039425  3513 solver.cpp:228] Iteration 22360, loss = 0.00345971
I0317 11:28:13.039491  3513 solver.cpp:244]     Train net output #0: loss = 0.00345973 (* 1 = 0.00345973 loss)
I0317 11:28:13.039505  3513 sgd_solver.cpp:106] Iteration 22360, lr = 0.01
I0317 11:28:20.357424  3513 solver.cpp:228] Iteration 22380, loss = 0.00681761
I0317 11:28:20.357492  3513 solver.cpp:244]     Train net output #0: loss = 0.00681763 (* 1 = 0.00681763 loss)
I0317 11:28:20.357506  3513 sgd_solver.cpp:106] Iteration 22380, lr = 0.01
I0317 11:28:27.681049  3513 solver.cpp:228] Iteration 22400, loss = 0.00508489
I0317 11:28:27.681113  3513 solver.cpp:244]     Train net output #0: loss = 0.00508491 (* 1 = 0.00508491 loss)
I0317 11:28:27.681124  3513 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0317 11:28:35.012055  3513 solver.cpp:228] Iteration 22420, loss = 0.00464154
I0317 11:28:35.012122  3513 solver.cpp:244]     Train net output #0: loss = 0.00464156 (* 1 = 0.00464156 loss)
I0317 11:28:35.012135  3513 sgd_solver.cpp:106] Iteration 22420, lr = 0.01
I0317 11:28:42.344714  3513 solver.cpp:228] Iteration 22440, loss = 0.00405645
I0317 11:28:42.344864  3513 solver.cpp:244]     Train net output #0: loss = 0.00405647 (* 1 = 0.00405647 loss)
I0317 11:28:42.344878  3513 sgd_solver.cpp:106] Iteration 22440, lr = 0.01
I0317 11:28:49.678763  3513 solver.cpp:228] Iteration 22460, loss = 0.00398866
I0317 11:28:49.678829  3513 solver.cpp:244]     Train net output #0: loss = 0.00398869 (* 1 = 0.00398869 loss)
I0317 11:28:49.678841  3513 sgd_solver.cpp:106] Iteration 22460, lr = 0.01
I0317 11:28:57.013942  3513 solver.cpp:228] Iteration 22480, loss = 0.00448433
I0317 11:28:57.014003  3513 solver.cpp:244]     Train net output #0: loss = 0.00448435 (* 1 = 0.00448435 loss)
I0317 11:28:57.014016  3513 sgd_solver.cpp:106] Iteration 22480, lr = 0.01
I0317 11:29:03.978819  3513 solver.cpp:337] Iteration 22500, Testing net (#0)
I0317 11:30:57.845396  3513 solver.cpp:404]     Test net output #0: loss = 0.0640498 (* 1 = 0.0640498 loss)
I0317 11:30:57.845489  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673079 (* 1 = 0.673079 loss)
I0317 11:30:58.181993  3513 solver.cpp:228] Iteration 22500, loss = 0.00460893
I0317 11:30:58.182085  3513 solver.cpp:244]     Train net output #0: loss = 0.00460895 (* 1 = 0.00460895 loss)
I0317 11:30:58.182099  3513 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0317 11:31:05.422781  3513 solver.cpp:228] Iteration 22520, loss = 0.00458898
I0317 11:31:05.422849  3513 solver.cpp:244]     Train net output #0: loss = 0.004589 (* 1 = 0.004589 loss)
I0317 11:31:05.422863  3513 sgd_solver.cpp:106] Iteration 22520, lr = 0.01
I0317 11:31:12.712594  3513 solver.cpp:228] Iteration 22540, loss = 0.0047602
I0317 11:31:12.712662  3513 solver.cpp:244]     Train net output #0: loss = 0.00476023 (* 1 = 0.00476023 loss)
I0317 11:31:12.712676  3513 sgd_solver.cpp:106] Iteration 22540, lr = 0.01
I0317 11:31:20.022490  3513 solver.cpp:228] Iteration 22560, loss = 0.00567735
I0317 11:31:20.022567  3513 solver.cpp:244]     Train net output #0: loss = 0.00567737 (* 1 = 0.00567737 loss)
I0317 11:31:20.022583  3513 sgd_solver.cpp:106] Iteration 22560, lr = 0.01
I0317 11:31:27.331950  3513 solver.cpp:228] Iteration 22580, loss = 0.0068385
I0317 11:31:27.332017  3513 solver.cpp:244]     Train net output #0: loss = 0.00683852 (* 1 = 0.00683852 loss)
I0317 11:31:27.332029  3513 sgd_solver.cpp:106] Iteration 22580, lr = 0.01
I0317 11:31:34.656106  3513 solver.cpp:228] Iteration 22600, loss = 0.00645941
I0317 11:31:34.656317  3513 solver.cpp:244]     Train net output #0: loss = 0.00645943 (* 1 = 0.00645943 loss)
I0317 11:31:34.656332  3513 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0317 11:31:41.983801  3513 solver.cpp:228] Iteration 22620, loss = 0.00397879
I0317 11:31:41.983877  3513 solver.cpp:244]     Train net output #0: loss = 0.00397881 (* 1 = 0.00397881 loss)
I0317 11:31:41.983891  3513 sgd_solver.cpp:106] Iteration 22620, lr = 0.01
I0317 11:31:49.312645  3513 solver.cpp:228] Iteration 22640, loss = 0.00277422
I0317 11:31:49.312712  3513 solver.cpp:244]     Train net output #0: loss = 0.00277425 (* 1 = 0.00277425 loss)
I0317 11:31:49.312726  3513 sgd_solver.cpp:106] Iteration 22640, lr = 0.01
I0317 11:31:56.641803  3513 solver.cpp:228] Iteration 22660, loss = 0.00355014
I0317 11:31:56.641865  3513 solver.cpp:244]     Train net output #0: loss = 0.00355016 (* 1 = 0.00355016 loss)
I0317 11:31:56.641877  3513 sgd_solver.cpp:106] Iteration 22660, lr = 0.01
I0317 11:32:03.971690  3513 solver.cpp:228] Iteration 22680, loss = 0.00328401
I0317 11:32:03.971757  3513 solver.cpp:244]     Train net output #0: loss = 0.00328403 (* 1 = 0.00328403 loss)
I0317 11:32:03.971771  3513 sgd_solver.cpp:106] Iteration 22680, lr = 0.01
I0317 11:32:11.299005  3513 solver.cpp:228] Iteration 22700, loss = 0.0042115
I0317 11:32:11.299170  3513 solver.cpp:244]     Train net output #0: loss = 0.00421152 (* 1 = 0.00421152 loss)
I0317 11:32:11.299183  3513 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0317 11:32:18.620653  3513 solver.cpp:228] Iteration 22720, loss = 0.00317363
I0317 11:32:18.620715  3513 solver.cpp:244]     Train net output #0: loss = 0.00317365 (* 1 = 0.00317365 loss)
I0317 11:32:18.620728  3513 sgd_solver.cpp:106] Iteration 22720, lr = 0.01
I0317 11:32:25.941710  3513 solver.cpp:228] Iteration 22740, loss = 0.00442426
I0317 11:32:25.941776  3513 solver.cpp:244]     Train net output #0: loss = 0.00442428 (* 1 = 0.00442428 loss)
I0317 11:32:25.941789  3513 sgd_solver.cpp:106] Iteration 22740, lr = 0.01
I0317 11:32:29.238353  3513 solver.cpp:337] Iteration 22750, Testing net (#0)
I0317 11:34:23.097712  3513 solver.cpp:404]     Test net output #0: loss = 0.0606601 (* 1 = 0.0606601 loss)
I0317 11:34:23.097829  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66356 (* 1 = 0.66356 loss)
I0317 11:34:27.049846  3513 solver.cpp:228] Iteration 22760, loss = 0.00494217
I0317 11:34:27.049913  3513 solver.cpp:244]     Train net output #0: loss = 0.00494219 (* 1 = 0.00494219 loss)
I0317 11:34:27.049926  3513 sgd_solver.cpp:106] Iteration 22760, lr = 0.01
I0317 11:34:34.332412  3513 solver.cpp:228] Iteration 22780, loss = 0.00599686
I0317 11:34:34.332486  3513 solver.cpp:244]     Train net output #0: loss = 0.00599689 (* 1 = 0.00599689 loss)
I0317 11:34:34.332500  3513 sgd_solver.cpp:106] Iteration 22780, lr = 0.01
I0317 11:34:41.640957  3513 solver.cpp:228] Iteration 22800, loss = 0.00332236
I0317 11:34:41.641024  3513 solver.cpp:244]     Train net output #0: loss = 0.00332238 (* 1 = 0.00332238 loss)
I0317 11:34:41.641039  3513 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0317 11:34:48.953735  3513 solver.cpp:228] Iteration 22820, loss = 0.00225125
I0317 11:34:48.953804  3513 solver.cpp:244]     Train net output #0: loss = 0.00225127 (* 1 = 0.00225127 loss)
I0317 11:34:48.953816  3513 sgd_solver.cpp:106] Iteration 22820, lr = 0.01
I0317 11:34:56.275032  3513 solver.cpp:228] Iteration 22840, loss = 0.00534974
I0317 11:34:56.275205  3513 solver.cpp:244]     Train net output #0: loss = 0.00534977 (* 1 = 0.00534977 loss)
I0317 11:34:56.275219  3513 sgd_solver.cpp:106] Iteration 22840, lr = 0.01
I0317 11:35:03.601306  3513 solver.cpp:228] Iteration 22860, loss = 0.00556594
I0317 11:35:03.601371  3513 solver.cpp:244]     Train net output #0: loss = 0.00556597 (* 1 = 0.00556597 loss)
I0317 11:35:03.601383  3513 sgd_solver.cpp:106] Iteration 22860, lr = 0.01
I0317 11:35:10.920625  3513 solver.cpp:228] Iteration 22880, loss = 0.00692607
I0317 11:35:10.920694  3513 solver.cpp:244]     Train net output #0: loss = 0.0069261 (* 1 = 0.0069261 loss)
I0317 11:35:10.920707  3513 sgd_solver.cpp:106] Iteration 22880, lr = 0.01
I0317 11:35:18.240027  3513 solver.cpp:228] Iteration 22900, loss = 0.0031204
I0317 11:35:18.240097  3513 solver.cpp:244]     Train net output #0: loss = 0.00312042 (* 1 = 0.00312042 loss)
I0317 11:35:18.240111  3513 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0317 11:35:25.566210  3513 solver.cpp:228] Iteration 22920, loss = 0.00662107
I0317 11:35:25.566272  3513 solver.cpp:244]     Train net output #0: loss = 0.00662109 (* 1 = 0.00662109 loss)
I0317 11:35:25.566284  3513 sgd_solver.cpp:106] Iteration 22920, lr = 0.01
I0317 11:35:32.887816  3513 solver.cpp:228] Iteration 22940, loss = 0.0052719
I0317 11:35:32.887964  3513 solver.cpp:244]     Train net output #0: loss = 0.00527192 (* 1 = 0.00527192 loss)
I0317 11:35:32.887979  3513 sgd_solver.cpp:106] Iteration 22940, lr = 0.01
I0317 11:35:40.220091  3513 solver.cpp:228] Iteration 22960, loss = 0.00426147
I0317 11:35:40.220156  3513 solver.cpp:244]     Train net output #0: loss = 0.00426149 (* 1 = 0.00426149 loss)
I0317 11:35:40.220170  3513 sgd_solver.cpp:106] Iteration 22960, lr = 0.01
I0317 11:35:47.548622  3513 solver.cpp:228] Iteration 22980, loss = 0.00337989
I0317 11:35:47.548692  3513 solver.cpp:244]     Train net output #0: loss = 0.00337992 (* 1 = 0.00337992 loss)
I0317 11:35:47.548705  3513 sgd_solver.cpp:106] Iteration 22980, lr = 0.01
I0317 11:35:54.507186  3513 solver.cpp:337] Iteration 23000, Testing net (#0)
I0317 11:37:48.390281  3513 solver.cpp:404]     Test net output #0: loss = 0.0604711 (* 1 = 0.0604711 loss)
I0317 11:37:48.390398  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66336 (* 1 = 0.66336 loss)
I0317 11:37:48.727990  3513 solver.cpp:228] Iteration 23000, loss = 0.00391187
I0317 11:37:48.728052  3513 solver.cpp:244]     Train net output #0: loss = 0.00391189 (* 1 = 0.00391189 loss)
I0317 11:37:48.728065  3513 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0317 11:37:55.976697  3513 solver.cpp:228] Iteration 23020, loss = 0.00265971
I0317 11:37:55.976765  3513 solver.cpp:244]     Train net output #0: loss = 0.00265974 (* 1 = 0.00265974 loss)
I0317 11:37:55.976778  3513 sgd_solver.cpp:106] Iteration 23020, lr = 0.01
I0317 11:38:03.268278  3513 solver.cpp:228] Iteration 23040, loss = 0.00287189
I0317 11:38:03.268347  3513 solver.cpp:244]     Train net output #0: loss = 0.00287192 (* 1 = 0.00287192 loss)
I0317 11:38:03.268359  3513 sgd_solver.cpp:106] Iteration 23040, lr = 0.01
I0317 11:38:10.587532  3513 solver.cpp:228] Iteration 23060, loss = 0.00557555
I0317 11:38:10.587601  3513 solver.cpp:244]     Train net output #0: loss = 0.00557558 (* 1 = 0.00557558 loss)
I0317 11:38:10.587616  3513 sgd_solver.cpp:106] Iteration 23060, lr = 0.01
I0317 11:38:17.918251  3513 solver.cpp:228] Iteration 23080, loss = 0.0026876
I0317 11:38:17.918318  3513 solver.cpp:244]     Train net output #0: loss = 0.00268762 (* 1 = 0.00268762 loss)
I0317 11:38:17.918332  3513 sgd_solver.cpp:106] Iteration 23080, lr = 0.01
I0317 11:38:25.243798  3513 solver.cpp:228] Iteration 23100, loss = 0.00605147
I0317 11:38:25.243974  3513 solver.cpp:244]     Train net output #0: loss = 0.0060515 (* 1 = 0.0060515 loss)
I0317 11:38:25.243995  3513 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0317 11:38:32.563612  3513 solver.cpp:228] Iteration 23120, loss = 0.00584672
I0317 11:38:32.563678  3513 solver.cpp:244]     Train net output #0: loss = 0.00584675 (* 1 = 0.00584675 loss)
I0317 11:38:32.563693  3513 sgd_solver.cpp:106] Iteration 23120, lr = 0.01
I0317 11:38:39.891234  3513 solver.cpp:228] Iteration 23140, loss = 0.00568366
I0317 11:38:39.891297  3513 solver.cpp:244]     Train net output #0: loss = 0.00568369 (* 1 = 0.00568369 loss)
I0317 11:38:39.891310  3513 sgd_solver.cpp:106] Iteration 23140, lr = 0.01
I0317 11:38:47.210036  3513 solver.cpp:228] Iteration 23160, loss = 0.00203591
I0317 11:38:47.210103  3513 solver.cpp:244]     Train net output #0: loss = 0.00203593 (* 1 = 0.00203593 loss)
I0317 11:38:47.210116  3513 sgd_solver.cpp:106] Iteration 23160, lr = 0.01
I0317 11:38:54.529444  3513 solver.cpp:228] Iteration 23180, loss = 0.00329211
I0317 11:38:54.529512  3513 solver.cpp:244]     Train net output #0: loss = 0.00329213 (* 1 = 0.00329213 loss)
I0317 11:38:54.529525  3513 sgd_solver.cpp:106] Iteration 23180, lr = 0.01
I0317 11:39:01.855132  3513 solver.cpp:228] Iteration 23200, loss = 0.00362037
I0317 11:39:01.855300  3513 solver.cpp:244]     Train net output #0: loss = 0.00362039 (* 1 = 0.00362039 loss)
I0317 11:39:01.855316  3513 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0317 11:39:09.175309  3513 solver.cpp:228] Iteration 23220, loss = 0.00326794
I0317 11:39:09.175374  3513 solver.cpp:244]     Train net output #0: loss = 0.00326796 (* 1 = 0.00326796 loss)
I0317 11:39:09.175387  3513 sgd_solver.cpp:106] Iteration 23220, lr = 0.01
I0317 11:39:16.495187  3513 solver.cpp:228] Iteration 23240, loss = 0.00456644
I0317 11:39:16.495254  3513 solver.cpp:244]     Train net output #0: loss = 0.00456647 (* 1 = 0.00456647 loss)
I0317 11:39:16.495267  3513 sgd_solver.cpp:106] Iteration 23240, lr = 0.01
I0317 11:39:19.795002  3513 solver.cpp:337] Iteration 23250, Testing net (#0)
I0317 11:41:13.648676  3513 solver.cpp:404]     Test net output #0: loss = 0.0589699 (* 1 = 0.0589699 loss)
I0317 11:41:13.648797  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65384 (* 1 = 0.65384 loss)
I0317 11:41:17.603050  3513 solver.cpp:228] Iteration 23260, loss = 0.00456103
I0317 11:41:17.603117  3513 solver.cpp:244]     Train net output #0: loss = 0.00456106 (* 1 = 0.00456106 loss)
I0317 11:41:17.603132  3513 sgd_solver.cpp:106] Iteration 23260, lr = 0.01
I0317 11:41:24.884642  3513 solver.cpp:228] Iteration 23280, loss = 0.00819359
I0317 11:41:24.884706  3513 solver.cpp:244]     Train net output #0: loss = 0.00819362 (* 1 = 0.00819362 loss)
I0317 11:41:24.884718  3513 sgd_solver.cpp:106] Iteration 23280, lr = 0.01
I0317 11:41:32.195036  3513 solver.cpp:228] Iteration 23300, loss = 0.0078188
I0317 11:41:32.195104  3513 solver.cpp:244]     Train net output #0: loss = 0.00781882 (* 1 = 0.00781882 loss)
I0317 11:41:32.195118  3513 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0317 11:41:39.522691  3513 solver.cpp:228] Iteration 23320, loss = 0.00762034
I0317 11:41:39.522758  3513 solver.cpp:244]     Train net output #0: loss = 0.00762037 (* 1 = 0.00762037 loss)
I0317 11:41:39.522771  3513 sgd_solver.cpp:106] Iteration 23320, lr = 0.01
I0317 11:41:46.845679  3513 solver.cpp:228] Iteration 23340, loss = 0.00251186
I0317 11:41:46.845825  3513 solver.cpp:244]     Train net output #0: loss = 0.00251188 (* 1 = 0.00251188 loss)
I0317 11:41:46.845839  3513 sgd_solver.cpp:106] Iteration 23340, lr = 0.01
I0317 11:41:54.171492  3513 solver.cpp:228] Iteration 23360, loss = 0.00263031
I0317 11:41:54.171561  3513 solver.cpp:244]     Train net output #0: loss = 0.00263033 (* 1 = 0.00263033 loss)
I0317 11:41:54.171573  3513 sgd_solver.cpp:106] Iteration 23360, lr = 0.01
I0317 11:42:01.497854  3513 solver.cpp:228] Iteration 23380, loss = 0.00405014
I0317 11:42:01.497925  3513 solver.cpp:244]     Train net output #0: loss = 0.00405017 (* 1 = 0.00405017 loss)
I0317 11:42:01.497939  3513 sgd_solver.cpp:106] Iteration 23380, lr = 0.01
I0317 11:42:08.818148  3513 solver.cpp:228] Iteration 23400, loss = 0.00359667
I0317 11:42:08.818217  3513 solver.cpp:244]     Train net output #0: loss = 0.00359669 (* 1 = 0.00359669 loss)
I0317 11:42:08.818229  3513 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0317 11:42:16.144882  3513 solver.cpp:228] Iteration 23420, loss = 0.00670601
I0317 11:42:16.144953  3513 solver.cpp:244]     Train net output #0: loss = 0.00670604 (* 1 = 0.00670604 loss)
I0317 11:42:16.144965  3513 sgd_solver.cpp:106] Iteration 23420, lr = 0.01
I0317 11:42:23.463712  3513 solver.cpp:228] Iteration 23440, loss = 0.0046361
I0317 11:42:23.463903  3513 solver.cpp:244]     Train net output #0: loss = 0.00463612 (* 1 = 0.00463612 loss)
I0317 11:42:23.463918  3513 sgd_solver.cpp:106] Iteration 23440, lr = 0.01
I0317 11:42:30.781458  3513 solver.cpp:228] Iteration 23460, loss = 0.00648608
I0317 11:42:30.781529  3513 solver.cpp:244]     Train net output #0: loss = 0.0064861 (* 1 = 0.0064861 loss)
I0317 11:42:30.781543  3513 sgd_solver.cpp:106] Iteration 23460, lr = 0.01
I0317 11:42:38.097347  3513 solver.cpp:228] Iteration 23480, loss = 0.0068227
I0317 11:42:38.097412  3513 solver.cpp:244]     Train net output #0: loss = 0.00682272 (* 1 = 0.00682272 loss)
I0317 11:42:38.097426  3513 sgd_solver.cpp:106] Iteration 23480, lr = 0.01
I0317 11:42:45.060927  3513 solver.cpp:337] Iteration 23500, Testing net (#0)
I0317 11:44:38.928324  3513 solver.cpp:404]     Test net output #0: loss = 0.0582649 (* 1 = 0.0582649 loss)
I0317 11:44:38.928469  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65392 (* 1 = 0.65392 loss)
I0317 11:44:39.264394  3513 solver.cpp:228] Iteration 23500, loss = 0.00587472
I0317 11:44:39.264453  3513 solver.cpp:244]     Train net output #0: loss = 0.00587474 (* 1 = 0.00587474 loss)
I0317 11:44:39.264467  3513 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0317 11:44:46.503052  3513 solver.cpp:228] Iteration 23520, loss = 0.00405468
I0317 11:44:46.503129  3513 solver.cpp:244]     Train net output #0: loss = 0.0040547 (* 1 = 0.0040547 loss)
I0317 11:44:46.503141  3513 sgd_solver.cpp:106] Iteration 23520, lr = 0.01
I0317 11:44:53.790555  3513 solver.cpp:228] Iteration 23540, loss = 0.00195451
I0317 11:44:53.790628  3513 solver.cpp:244]     Train net output #0: loss = 0.00195453 (* 1 = 0.00195453 loss)
I0317 11:44:53.790642  3513 sgd_solver.cpp:106] Iteration 23540, lr = 0.01
I0317 11:45:01.100515  3513 solver.cpp:228] Iteration 23560, loss = 0.00302057
I0317 11:45:01.100585  3513 solver.cpp:244]     Train net output #0: loss = 0.0030206 (* 1 = 0.0030206 loss)
I0317 11:45:01.100599  3513 sgd_solver.cpp:106] Iteration 23560, lr = 0.01
I0317 11:45:08.426661  3513 solver.cpp:228] Iteration 23580, loss = 0.00171447
I0317 11:45:08.426748  3513 solver.cpp:244]     Train net output #0: loss = 0.00171449 (* 1 = 0.00171449 loss)
I0317 11:45:08.426762  3513 sgd_solver.cpp:106] Iteration 23580, lr = 0.01
I0317 11:45:15.751513  3513 solver.cpp:228] Iteration 23600, loss = 0.00798036
I0317 11:45:15.751669  3513 solver.cpp:244]     Train net output #0: loss = 0.00798038 (* 1 = 0.00798038 loss)
I0317 11:45:15.751683  3513 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0317 11:45:23.074445  3513 solver.cpp:228] Iteration 23620, loss = 0.0034594
I0317 11:45:23.074507  3513 solver.cpp:244]     Train net output #0: loss = 0.00345942 (* 1 = 0.00345942 loss)
I0317 11:45:23.074519  3513 sgd_solver.cpp:106] Iteration 23620, lr = 0.01
I0317 11:45:30.403694  3513 solver.cpp:228] Iteration 23640, loss = 0.00522744
I0317 11:45:30.403762  3513 solver.cpp:244]     Train net output #0: loss = 0.00522747 (* 1 = 0.00522747 loss)
I0317 11:45:30.403776  3513 sgd_solver.cpp:106] Iteration 23640, lr = 0.01
I0317 11:45:37.732280  3513 solver.cpp:228] Iteration 23660, loss = 0.00543503
I0317 11:45:37.732344  3513 solver.cpp:244]     Train net output #0: loss = 0.00543505 (* 1 = 0.00543505 loss)
I0317 11:45:37.732357  3513 sgd_solver.cpp:106] Iteration 23660, lr = 0.01
I0317 11:45:45.062304  3513 solver.cpp:228] Iteration 23680, loss = 0.00653049
I0317 11:45:45.062372  3513 solver.cpp:244]     Train net output #0: loss = 0.00653052 (* 1 = 0.00653052 loss)
I0317 11:45:45.062384  3513 sgd_solver.cpp:106] Iteration 23680, lr = 0.01
I0317 11:45:52.387889  3513 solver.cpp:228] Iteration 23700, loss = 0.00396301
I0317 11:45:52.388070  3513 solver.cpp:244]     Train net output #0: loss = 0.00396303 (* 1 = 0.00396303 loss)
I0317 11:45:52.388087  3513 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0317 11:45:59.711098  3513 solver.cpp:228] Iteration 23720, loss = 0.00244003
I0317 11:45:59.711169  3513 solver.cpp:244]     Train net output #0: loss = 0.00244005 (* 1 = 0.00244005 loss)
I0317 11:45:59.711184  3513 sgd_solver.cpp:106] Iteration 23720, lr = 0.01
I0317 11:46:07.031081  3513 solver.cpp:228] Iteration 23740, loss = 0.00203577
I0317 11:46:07.031150  3513 solver.cpp:244]     Train net output #0: loss = 0.00203579 (* 1 = 0.00203579 loss)
I0317 11:46:07.031164  3513 sgd_solver.cpp:106] Iteration 23740, lr = 0.01
I0317 11:46:10.324882  3513 solver.cpp:337] Iteration 23750, Testing net (#0)
I0317 11:48:04.251317  3513 solver.cpp:404]     Test net output #0: loss = 0.0591802 (* 1 = 0.0591802 loss)
I0317 11:48:04.251468  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64412 (* 1 = 0.64412 loss)
I0317 11:48:08.199661  3513 solver.cpp:228] Iteration 23760, loss = 0.00291847
I0317 11:48:08.199734  3513 solver.cpp:244]     Train net output #0: loss = 0.0029185 (* 1 = 0.0029185 loss)
I0317 11:48:08.199748  3513 sgd_solver.cpp:106] Iteration 23760, lr = 0.01
I0317 11:48:15.482475  3513 solver.cpp:228] Iteration 23780, loss = 0.00374782
I0317 11:48:15.482540  3513 solver.cpp:244]     Train net output #0: loss = 0.00374784 (* 1 = 0.00374784 loss)
I0317 11:48:15.482553  3513 sgd_solver.cpp:106] Iteration 23780, lr = 0.01
I0317 11:48:22.788161  3513 solver.cpp:228] Iteration 23800, loss = 0.00408894
I0317 11:48:22.788231  3513 solver.cpp:244]     Train net output #0: loss = 0.00408896 (* 1 = 0.00408896 loss)
I0317 11:48:22.788244  3513 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0317 11:48:30.104392  3513 solver.cpp:228] Iteration 23820, loss = 0.00474249
I0317 11:48:30.104473  3513 solver.cpp:244]     Train net output #0: loss = 0.00474251 (* 1 = 0.00474251 loss)
I0317 11:48:30.104486  3513 sgd_solver.cpp:106] Iteration 23820, lr = 0.01
I0317 11:48:37.434340  3513 solver.cpp:228] Iteration 23840, loss = 0.00622126
I0317 11:48:37.434484  3513 solver.cpp:244]     Train net output #0: loss = 0.00622129 (* 1 = 0.00622129 loss)
I0317 11:48:37.434497  3513 sgd_solver.cpp:106] Iteration 23840, lr = 0.01
I0317 11:48:44.769538  3513 solver.cpp:228] Iteration 23860, loss = 0.00609698
I0317 11:48:44.769606  3513 solver.cpp:244]     Train net output #0: loss = 0.006097 (* 1 = 0.006097 loss)
I0317 11:48:44.769619  3513 sgd_solver.cpp:106] Iteration 23860, lr = 0.01
I0317 11:48:52.105798  3513 solver.cpp:228] Iteration 23880, loss = 0.0051824
I0317 11:48:52.105870  3513 solver.cpp:244]     Train net output #0: loss = 0.00518242 (* 1 = 0.00518242 loss)
I0317 11:48:52.105890  3513 sgd_solver.cpp:106] Iteration 23880, lr = 0.01
I0317 11:48:59.432385  3513 solver.cpp:228] Iteration 23900, loss = 0.00249347
I0317 11:48:59.432451  3513 solver.cpp:244]     Train net output #0: loss = 0.0024935 (* 1 = 0.0024935 loss)
I0317 11:48:59.432464  3513 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0317 11:49:06.749003  3513 solver.cpp:228] Iteration 23920, loss = 0.00198289
I0317 11:49:06.749070  3513 solver.cpp:244]     Train net output #0: loss = 0.00198291 (* 1 = 0.00198291 loss)
I0317 11:49:06.749084  3513 sgd_solver.cpp:106] Iteration 23920, lr = 0.01
I0317 11:49:14.075603  3513 solver.cpp:228] Iteration 23940, loss = 0.00380992
I0317 11:49:14.075814  3513 solver.cpp:244]     Train net output #0: loss = 0.00380995 (* 1 = 0.00380995 loss)
I0317 11:49:14.075829  3513 sgd_solver.cpp:106] Iteration 23940, lr = 0.01
I0317 11:49:21.405071  3513 solver.cpp:228] Iteration 23960, loss = 0.00462582
I0317 11:49:21.405133  3513 solver.cpp:244]     Train net output #0: loss = 0.00462585 (* 1 = 0.00462585 loss)
I0317 11:49:21.405145  3513 sgd_solver.cpp:106] Iteration 23960, lr = 0.01
I0317 11:49:28.733348  3513 solver.cpp:228] Iteration 23980, loss = 0.00466146
I0317 11:49:28.733417  3513 solver.cpp:244]     Train net output #0: loss = 0.00466148 (* 1 = 0.00466148 loss)
I0317 11:49:28.733429  3513 sgd_solver.cpp:106] Iteration 23980, lr = 0.01
I0317 11:49:35.692592  3513 solver.cpp:337] Iteration 24000, Testing net (#0)
I0317 11:51:29.574379  3513 solver.cpp:404]     Test net output #0: loss = 0.0594256 (* 1 = 0.0594256 loss)
I0317 11:51:29.574506  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64428 (* 1 = 0.64428 loss)
I0317 11:51:29.910331  3513 solver.cpp:228] Iteration 24000, loss = 0.00353352
I0317 11:51:29.910392  3513 solver.cpp:244]     Train net output #0: loss = 0.00353354 (* 1 = 0.00353354 loss)
I0317 11:51:29.910404  3513 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0317 11:51:37.153533  3513 solver.cpp:228] Iteration 24020, loss = 0.00379365
I0317 11:51:37.153599  3513 solver.cpp:244]     Train net output #0: loss = 0.00379367 (* 1 = 0.00379367 loss)
I0317 11:51:37.153612  3513 sgd_solver.cpp:106] Iteration 24020, lr = 0.01
I0317 11:51:44.467056  3513 solver.cpp:228] Iteration 24040, loss = 0.00722338
I0317 11:51:44.467123  3513 solver.cpp:244]     Train net output #0: loss = 0.00722341 (* 1 = 0.00722341 loss)
I0317 11:51:44.467135  3513 sgd_solver.cpp:106] Iteration 24040, lr = 0.01
I0317 11:51:51.793714  3513 solver.cpp:228] Iteration 24060, loss = 0.0022814
I0317 11:51:51.793793  3513 solver.cpp:244]     Train net output #0: loss = 0.00228143 (* 1 = 0.00228143 loss)
I0317 11:51:51.793807  3513 sgd_solver.cpp:106] Iteration 24060, lr = 0.01
I0317 11:51:59.118348  3513 solver.cpp:228] Iteration 24080, loss = 0.00166322
I0317 11:51:59.118410  3513 solver.cpp:244]     Train net output #0: loss = 0.00166324 (* 1 = 0.00166324 loss)
I0317 11:51:59.118424  3513 sgd_solver.cpp:106] Iteration 24080, lr = 0.01
I0317 11:52:06.450239  3513 solver.cpp:228] Iteration 24100, loss = 0.00218515
I0317 11:52:06.450381  3513 solver.cpp:244]     Train net output #0: loss = 0.00218518 (* 1 = 0.00218518 loss)
I0317 11:52:06.450395  3513 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0317 11:52:13.772135  3513 solver.cpp:228] Iteration 24120, loss = 0.00251208
I0317 11:52:13.772210  3513 solver.cpp:244]     Train net output #0: loss = 0.0025121 (* 1 = 0.0025121 loss)
I0317 11:52:13.772223  3513 sgd_solver.cpp:106] Iteration 24120, lr = 0.01
I0317 11:52:21.098079  3513 solver.cpp:228] Iteration 24140, loss = 0.00602451
I0317 11:52:21.098145  3513 solver.cpp:244]     Train net output #0: loss = 0.00602454 (* 1 = 0.00602454 loss)
I0317 11:52:21.098157  3513 sgd_solver.cpp:106] Iteration 24140, lr = 0.01
I0317 11:52:28.424221  3513 solver.cpp:228] Iteration 24160, loss = 0.00567155
I0317 11:52:28.424285  3513 solver.cpp:244]     Train net output #0: loss = 0.00567158 (* 1 = 0.00567158 loss)
I0317 11:52:28.424299  3513 sgd_solver.cpp:106] Iteration 24160, lr = 0.01
I0317 11:52:35.749639  3513 solver.cpp:228] Iteration 24180, loss = 0.00551579
I0317 11:52:35.749706  3513 solver.cpp:244]     Train net output #0: loss = 0.00551581 (* 1 = 0.00551581 loss)
I0317 11:52:35.749717  3513 sgd_solver.cpp:106] Iteration 24180, lr = 0.01
I0317 11:52:43.085309  3513 solver.cpp:228] Iteration 24200, loss = 0.00509055
I0317 11:52:43.085469  3513 solver.cpp:244]     Train net output #0: loss = 0.00509057 (* 1 = 0.00509057 loss)
I0317 11:52:43.085484  3513 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0317 11:52:50.412086  3513 solver.cpp:228] Iteration 24220, loss = 0.00483095
I0317 11:52:50.412149  3513 solver.cpp:244]     Train net output #0: loss = 0.00483097 (* 1 = 0.00483097 loss)
I0317 11:52:50.412163  3513 sgd_solver.cpp:106] Iteration 24220, lr = 0.01
I0317 11:52:57.739778  3513 solver.cpp:228] Iteration 24240, loss = 0.00626455
I0317 11:52:57.739840  3513 solver.cpp:244]     Train net output #0: loss = 0.00626458 (* 1 = 0.00626458 loss)
I0317 11:52:57.739852  3513 sgd_solver.cpp:106] Iteration 24240, lr = 0.01
I0317 11:53:01.030391  3513 solver.cpp:337] Iteration 24250, Testing net (#0)
I0317 11:54:54.893141  3513 solver.cpp:404]     Test net output #0: loss = 0.0603335 (* 1 = 0.0603335 loss)
I0317 11:54:54.893334  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66344 (* 1 = 0.66344 loss)
I0317 11:54:58.841768  3513 solver.cpp:228] Iteration 24260, loss = 0.00203117
I0317 11:54:58.841835  3513 solver.cpp:244]     Train net output #0: loss = 0.0020312 (* 1 = 0.0020312 loss)
I0317 11:54:58.841846  3513 sgd_solver.cpp:106] Iteration 24260, lr = 0.01
I0317 11:55:06.123666  3513 solver.cpp:228] Iteration 24280, loss = 0.00277299
I0317 11:55:06.123739  3513 solver.cpp:244]     Train net output #0: loss = 0.00277302 (* 1 = 0.00277302 loss)
I0317 11:55:06.123754  3513 sgd_solver.cpp:106] Iteration 24280, lr = 0.01
I0317 11:55:13.436031  3513 solver.cpp:228] Iteration 24300, loss = 0.00367772
I0317 11:55:13.436097  3513 solver.cpp:244]     Train net output #0: loss = 0.00367774 (* 1 = 0.00367774 loss)
I0317 11:55:13.436111  3513 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0317 11:55:20.766505  3513 solver.cpp:228] Iteration 24320, loss = 0.00932478
I0317 11:55:20.766571  3513 solver.cpp:244]     Train net output #0: loss = 0.00932481 (* 1 = 0.00932481 loss)
I0317 11:55:20.766583  3513 sgd_solver.cpp:106] Iteration 24320, lr = 0.01
I0317 11:55:28.089819  3513 solver.cpp:228] Iteration 24340, loss = 0.00524033
I0317 11:55:28.089908  3513 solver.cpp:244]     Train net output #0: loss = 0.00524035 (* 1 = 0.00524035 loss)
I0317 11:55:28.089921  3513 sgd_solver.cpp:106] Iteration 24340, lr = 0.01
I0317 11:55:35.417058  3513 solver.cpp:228] Iteration 24360, loss = 0.00526099
I0317 11:55:35.417125  3513 solver.cpp:244]     Train net output #0: loss = 0.00526101 (* 1 = 0.00526101 loss)
I0317 11:55:35.417138  3513 sgd_solver.cpp:106] Iteration 24360, lr = 0.01
I0317 11:55:42.740852  3513 solver.cpp:228] Iteration 24380, loss = 0.00586799
I0317 11:55:42.740933  3513 solver.cpp:244]     Train net output #0: loss = 0.00586802 (* 1 = 0.00586802 loss)
I0317 11:55:42.740945  3513 sgd_solver.cpp:106] Iteration 24380, lr = 0.01
I0317 11:55:50.060734  3513 solver.cpp:228] Iteration 24400, loss = 0.00560894
I0317 11:55:50.060809  3513 solver.cpp:244]     Train net output #0: loss = 0.00560896 (* 1 = 0.00560896 loss)
I0317 11:55:50.060822  3513 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0317 11:55:57.387725  3513 solver.cpp:228] Iteration 24420, loss = 0.00299999
I0317 11:55:57.387791  3513 solver.cpp:244]     Train net output #0: loss = 0.00300001 (* 1 = 0.00300001 loss)
I0317 11:55:57.387804  3513 sgd_solver.cpp:106] Iteration 24420, lr = 0.01
I0317 11:56:04.724912  3513 solver.cpp:228] Iteration 24440, loss = 0.00283858
I0317 11:56:04.725069  3513 solver.cpp:244]     Train net output #0: loss = 0.0028386 (* 1 = 0.0028386 loss)
I0317 11:56:04.725085  3513 sgd_solver.cpp:106] Iteration 24440, lr = 0.01
I0317 11:56:12.051021  3513 solver.cpp:228] Iteration 24460, loss = 0.00261689
I0317 11:56:12.051089  3513 solver.cpp:244]     Train net output #0: loss = 0.00261691 (* 1 = 0.00261691 loss)
I0317 11:56:12.051101  3513 sgd_solver.cpp:106] Iteration 24460, lr = 0.01
I0317 11:56:19.376346  3513 solver.cpp:228] Iteration 24480, loss = 0.00383123
I0317 11:56:19.376415  3513 solver.cpp:244]     Train net output #0: loss = 0.00383125 (* 1 = 0.00383125 loss)
I0317 11:56:19.376427  3513 sgd_solver.cpp:106] Iteration 24480, lr = 0.01
I0317 11:56:26.333241  3513 solver.cpp:337] Iteration 24500, Testing net (#0)
I0317 11:58:20.214942  3513 solver.cpp:404]     Test net output #0: loss = 0.0634966 (* 1 = 0.0634966 loss)
I0317 11:58:20.215114  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673079 (* 1 = 0.673079 loss)
I0317 11:58:20.552836  3513 solver.cpp:228] Iteration 24500, loss = 0.00573717
I0317 11:58:20.552904  3513 solver.cpp:244]     Train net output #0: loss = 0.00573719 (* 1 = 0.00573719 loss)
I0317 11:58:20.552917  3513 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0317 11:58:27.799782  3513 solver.cpp:228] Iteration 24520, loss = 0.00297481
I0317 11:58:27.799850  3513 solver.cpp:244]     Train net output #0: loss = 0.00297483 (* 1 = 0.00297483 loss)
I0317 11:58:27.799863  3513 sgd_solver.cpp:106] Iteration 24520, lr = 0.01
I0317 11:58:35.089550  3513 solver.cpp:228] Iteration 24540, loss = 0.00698457
I0317 11:58:35.089618  3513 solver.cpp:244]     Train net output #0: loss = 0.00698459 (* 1 = 0.00698459 loss)
I0317 11:58:35.089632  3513 sgd_solver.cpp:106] Iteration 24540, lr = 0.01
I0317 11:58:42.399926  3513 solver.cpp:228] Iteration 24560, loss = 0.00452163
I0317 11:58:42.399993  3513 solver.cpp:244]     Train net output #0: loss = 0.00452165 (* 1 = 0.00452165 loss)
I0317 11:58:42.400007  3513 sgd_solver.cpp:106] Iteration 24560, lr = 0.01
I0317 11:58:49.722692  3513 solver.cpp:228] Iteration 24580, loss = 0.00651758
I0317 11:58:49.722755  3513 solver.cpp:244]     Train net output #0: loss = 0.00651761 (* 1 = 0.00651761 loss)
I0317 11:58:49.722769  3513 sgd_solver.cpp:106] Iteration 24580, lr = 0.01
I0317 11:58:57.049767  3513 solver.cpp:228] Iteration 24600, loss = 0.00273156
I0317 11:58:57.049913  3513 solver.cpp:244]     Train net output #0: loss = 0.00273159 (* 1 = 0.00273159 loss)
I0317 11:58:57.049927  3513 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0317 11:59:04.374680  3513 solver.cpp:228] Iteration 24620, loss = 0.00244376
I0317 11:59:04.374748  3513 solver.cpp:244]     Train net output #0: loss = 0.00244379 (* 1 = 0.00244379 loss)
I0317 11:59:04.374761  3513 sgd_solver.cpp:106] Iteration 24620, lr = 0.01
I0317 11:59:11.707303  3513 solver.cpp:228] Iteration 24640, loss = 0.00291302
I0317 11:59:11.707371  3513 solver.cpp:244]     Train net output #0: loss = 0.00291304 (* 1 = 0.00291304 loss)
I0317 11:59:11.707383  3513 sgd_solver.cpp:106] Iteration 24640, lr = 0.01
I0317 11:59:19.042006  3513 solver.cpp:228] Iteration 24660, loss = 0.0037148
I0317 11:59:19.042068  3513 solver.cpp:244]     Train net output #0: loss = 0.00371482 (* 1 = 0.00371482 loss)
I0317 11:59:19.042081  3513 sgd_solver.cpp:106] Iteration 24660, lr = 0.01
I0317 11:59:26.379405  3513 solver.cpp:228] Iteration 24680, loss = 0.00388575
I0317 11:59:26.379473  3513 solver.cpp:244]     Train net output #0: loss = 0.00388578 (* 1 = 0.00388578 loss)
I0317 11:59:26.379485  3513 sgd_solver.cpp:106] Iteration 24680, lr = 0.01
I0317 11:59:33.702765  3513 solver.cpp:228] Iteration 24700, loss = 0.00504263
I0317 11:59:33.702905  3513 solver.cpp:244]     Train net output #0: loss = 0.00504265 (* 1 = 0.00504265 loss)
I0317 11:59:33.702920  3513 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0317 11:59:41.028136  3513 solver.cpp:228] Iteration 24720, loss = 0.00867679
I0317 11:59:41.028201  3513 solver.cpp:244]     Train net output #0: loss = 0.00867681 (* 1 = 0.00867681 loss)
I0317 11:59:41.028214  3513 sgd_solver.cpp:106] Iteration 24720, lr = 0.01
I0317 11:59:48.354567  3513 solver.cpp:228] Iteration 24740, loss = 0.00596771
I0317 11:59:48.354634  3513 solver.cpp:244]     Train net output #0: loss = 0.00596773 (* 1 = 0.00596773 loss)
I0317 11:59:48.354646  3513 sgd_solver.cpp:106] Iteration 24740, lr = 0.01
I0317 11:59:51.651588  3513 solver.cpp:337] Iteration 24750, Testing net (#0)
I0317 12:01:45.536221  3513 solver.cpp:404]     Test net output #0: loss = 0.0604472 (* 1 = 0.0604472 loss)
I0317 12:01:45.536335  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64424 (* 1 = 0.64424 loss)
I0317 12:01:49.487507  3513 solver.cpp:228] Iteration 24760, loss = 0.00465244
I0317 12:01:49.487571  3513 solver.cpp:244]     Train net output #0: loss = 0.00465246 (* 1 = 0.00465246 loss)
I0317 12:01:49.487583  3513 sgd_solver.cpp:106] Iteration 24760, lr = 0.01
I0317 12:01:56.769248  3513 solver.cpp:228] Iteration 24780, loss = 0.00383926
I0317 12:01:56.769322  3513 solver.cpp:244]     Train net output #0: loss = 0.00383928 (* 1 = 0.00383928 loss)
I0317 12:01:56.769335  3513 sgd_solver.cpp:106] Iteration 24780, lr = 0.01
I0317 12:02:04.076525  3513 solver.cpp:228] Iteration 24800, loss = 0.00244766
I0317 12:02:04.076589  3513 solver.cpp:244]     Train net output #0: loss = 0.00244768 (* 1 = 0.00244768 loss)
I0317 12:02:04.076601  3513 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0317 12:02:11.403959  3513 solver.cpp:228] Iteration 24820, loss = 0.00258334
I0317 12:02:11.404024  3513 solver.cpp:244]     Train net output #0: loss = 0.00258336 (* 1 = 0.00258336 loss)
I0317 12:02:11.404036  3513 sgd_solver.cpp:106] Iteration 24820, lr = 0.01
I0317 12:02:18.735013  3513 solver.cpp:228] Iteration 24840, loss = 0.00360107
I0317 12:02:18.735158  3513 solver.cpp:244]     Train net output #0: loss = 0.00360109 (* 1 = 0.00360109 loss)
I0317 12:02:18.735172  3513 sgd_solver.cpp:106] Iteration 24840, lr = 0.01
I0317 12:02:26.063012  3513 solver.cpp:228] Iteration 24860, loss = 0.00784671
I0317 12:02:26.063082  3513 solver.cpp:244]     Train net output #0: loss = 0.00784673 (* 1 = 0.00784673 loss)
I0317 12:02:26.063094  3513 sgd_solver.cpp:106] Iteration 24860, lr = 0.01
I0317 12:02:33.382158  3513 solver.cpp:228] Iteration 24880, loss = 0.00379157
I0317 12:02:33.382226  3513 solver.cpp:244]     Train net output #0: loss = 0.00379159 (* 1 = 0.00379159 loss)
I0317 12:02:33.382239  3513 sgd_solver.cpp:106] Iteration 24880, lr = 0.01
I0317 12:02:40.707267  3513 solver.cpp:228] Iteration 24900, loss = 0.0064754
I0317 12:02:40.707336  3513 solver.cpp:244]     Train net output #0: loss = 0.00647542 (* 1 = 0.00647542 loss)
I0317 12:02:40.707350  3513 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0317 12:02:48.026942  3513 solver.cpp:228] Iteration 24920, loss = 0.00700917
I0317 12:02:48.027007  3513 solver.cpp:244]     Train net output #0: loss = 0.00700919 (* 1 = 0.00700919 loss)
I0317 12:02:48.027021  3513 sgd_solver.cpp:106] Iteration 24920, lr = 0.01
I0317 12:02:55.342870  3513 solver.cpp:228] Iteration 24940, loss = 0.00552179
I0317 12:02:55.343008  3513 solver.cpp:244]     Train net output #0: loss = 0.00552181 (* 1 = 0.00552181 loss)
I0317 12:02:55.343022  3513 sgd_solver.cpp:106] Iteration 24940, lr = 0.01
I0317 12:03:02.658879  3513 solver.cpp:228] Iteration 24960, loss = 0.00291648
I0317 12:03:02.658946  3513 solver.cpp:244]     Train net output #0: loss = 0.00291651 (* 1 = 0.00291651 loss)
I0317 12:03:02.658958  3513 sgd_solver.cpp:106] Iteration 24960, lr = 0.01
I0317 12:03:09.972426  3513 solver.cpp:228] Iteration 24980, loss = 0.00366325
I0317 12:03:09.972510  3513 solver.cpp:244]     Train net output #0: loss = 0.00366327 (* 1 = 0.00366327 loss)
I0317 12:03:09.972524  3513 sgd_solver.cpp:106] Iteration 24980, lr = 0.01
I0317 12:03:16.932401  3513 solver.cpp:454] Snapshotting to binary proto file ./caffe_alexnet_train_iter_25000.caffemodel
I0317 12:03:18.597005  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./caffe_alexnet_train_iter_25000.solverstate
I0317 12:03:19.007020  3513 solver.cpp:337] Iteration 25000, Testing net (#0)
I0317 12:05:12.814373  3513 solver.cpp:404]     Test net output #0: loss = 0.059732 (* 1 = 0.059732 loss)
I0317 12:05:12.814452  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6538 (* 1 = 0.6538 loss)
I0317 12:05:13.151408  3513 solver.cpp:228] Iteration 25000, loss = 0.00361738
I0317 12:05:13.151474  3513 solver.cpp:244]     Train net output #0: loss = 0.00361741 (* 1 = 0.00361741 loss)
I0317 12:05:13.151487  3513 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0317 12:05:20.424007  3513 solver.cpp:228] Iteration 25020, loss = 0.00450724
I0317 12:05:20.424070  3513 solver.cpp:244]     Train net output #0: loss = 0.00450726 (* 1 = 0.00450726 loss)
I0317 12:05:20.424082  3513 sgd_solver.cpp:106] Iteration 25020, lr = 0.01
I0317 12:05:27.724558  3513 solver.cpp:228] Iteration 25040, loss = 0.00391633
I0317 12:05:27.724627  3513 solver.cpp:244]     Train net output #0: loss = 0.00391635 (* 1 = 0.00391635 loss)
I0317 12:05:27.724639  3513 sgd_solver.cpp:106] Iteration 25040, lr = 0.01
I0317 12:05:35.042281  3513 solver.cpp:228] Iteration 25060, loss = 0.00377639
I0317 12:05:35.042352  3513 solver.cpp:244]     Train net output #0: loss = 0.00377641 (* 1 = 0.00377641 loss)
I0317 12:05:35.042366  3513 sgd_solver.cpp:106] Iteration 25060, lr = 0.01
I0317 12:05:42.369501  3513 solver.cpp:228] Iteration 25080, loss = 0.00634809
I0317 12:05:42.369570  3513 solver.cpp:244]     Train net output #0: loss = 0.00634811 (* 1 = 0.00634811 loss)
I0317 12:05:42.369583  3513 sgd_solver.cpp:106] Iteration 25080, lr = 0.01
I0317 12:05:49.704362  3513 solver.cpp:228] Iteration 25100, loss = 0.00266183
I0317 12:05:49.704537  3513 solver.cpp:244]     Train net output #0: loss = 0.00266186 (* 1 = 0.00266186 loss)
I0317 12:05:49.704551  3513 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0317 12:05:57.034888  3513 solver.cpp:228] Iteration 25120, loss = 0.00350864
I0317 12:05:57.034950  3513 solver.cpp:244]     Train net output #0: loss = 0.00350866 (* 1 = 0.00350866 loss)
I0317 12:05:57.034965  3513 sgd_solver.cpp:106] Iteration 25120, lr = 0.01
I0317 12:06:04.363454  3513 solver.cpp:228] Iteration 25140, loss = 0.00314934
I0317 12:06:04.363523  3513 solver.cpp:244]     Train net output #0: loss = 0.00314936 (* 1 = 0.00314936 loss)
I0317 12:06:04.363535  3513 sgd_solver.cpp:106] Iteration 25140, lr = 0.01
I0317 12:06:11.690953  3513 solver.cpp:228] Iteration 25160, loss = 0.00326331
I0317 12:06:11.691020  3513 solver.cpp:244]     Train net output #0: loss = 0.00326333 (* 1 = 0.00326333 loss)
I0317 12:06:11.691032  3513 sgd_solver.cpp:106] Iteration 25160, lr = 0.01
I0317 12:06:19.022624  3513 solver.cpp:228] Iteration 25180, loss = 0.00411143
I0317 12:06:19.022687  3513 solver.cpp:244]     Train net output #0: loss = 0.00411146 (* 1 = 0.00411146 loss)
I0317 12:06:19.022701  3513 sgd_solver.cpp:106] Iteration 25180, lr = 0.01
I0317 12:06:26.344545  3513 solver.cpp:228] Iteration 25200, loss = 0.00243733
I0317 12:06:26.344696  3513 solver.cpp:244]     Train net output #0: loss = 0.00243736 (* 1 = 0.00243736 loss)
I0317 12:06:26.344710  3513 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0317 12:06:33.668396  3513 solver.cpp:228] Iteration 25220, loss = 0.00478775
I0317 12:06:33.668460  3513 solver.cpp:244]     Train net output #0: loss = 0.00478778 (* 1 = 0.00478778 loss)
I0317 12:06:33.668473  3513 sgd_solver.cpp:106] Iteration 25220, lr = 0.01
I0317 12:06:40.989995  3513 solver.cpp:228] Iteration 25240, loss = 0.00351982
I0317 12:06:40.990069  3513 solver.cpp:244]     Train net output #0: loss = 0.00351984 (* 1 = 0.00351984 loss)
I0317 12:06:40.990083  3513 sgd_solver.cpp:106] Iteration 25240, lr = 0.01
I0317 12:06:44.290829  3513 solver.cpp:337] Iteration 25250, Testing net (#0)
I0317 12:08:38.189960  3513 solver.cpp:404]     Test net output #0: loss = 0.0592413 (* 1 = 0.0592413 loss)
I0317 12:08:38.190096  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6636 (* 1 = 0.6636 loss)
I0317 12:08:42.134344  3513 solver.cpp:228] Iteration 25260, loss = 0.00728304
I0317 12:08:42.134415  3513 solver.cpp:244]     Train net output #0: loss = 0.00728307 (* 1 = 0.00728307 loss)
I0317 12:08:42.134428  3513 sgd_solver.cpp:106] Iteration 25260, lr = 0.01
I0317 12:08:49.395788  3513 solver.cpp:228] Iteration 25280, loss = 0.00359931
I0317 12:08:49.395854  3513 solver.cpp:244]     Train net output #0: loss = 0.00359934 (* 1 = 0.00359934 loss)
I0317 12:08:49.395867  3513 sgd_solver.cpp:106] Iteration 25280, lr = 0.01
I0317 12:08:56.692519  3513 solver.cpp:228] Iteration 25300, loss = 0.00411914
I0317 12:08:56.692586  3513 solver.cpp:244]     Train net output #0: loss = 0.00411916 (* 1 = 0.00411916 loss)
I0317 12:08:56.692600  3513 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0317 12:09:04.010090  3513 solver.cpp:228] Iteration 25320, loss = 0.00245715
I0317 12:09:04.010162  3513 solver.cpp:244]     Train net output #0: loss = 0.00245717 (* 1 = 0.00245717 loss)
I0317 12:09:04.010175  3513 sgd_solver.cpp:106] Iteration 25320, lr = 0.01
I0317 12:09:11.334115  3513 solver.cpp:228] Iteration 25340, loss = 0.00391431
I0317 12:09:11.334308  3513 solver.cpp:244]     Train net output #0: loss = 0.00391433 (* 1 = 0.00391433 loss)
I0317 12:09:11.334322  3513 sgd_solver.cpp:106] Iteration 25340, lr = 0.01
I0317 12:09:18.671862  3513 solver.cpp:228] Iteration 25360, loss = 0.00527461
I0317 12:09:18.671924  3513 solver.cpp:244]     Train net output #0: loss = 0.00527464 (* 1 = 0.00527464 loss)
I0317 12:09:18.671937  3513 sgd_solver.cpp:106] Iteration 25360, lr = 0.01
I0317 12:09:26.005427  3513 solver.cpp:228] Iteration 25380, loss = 0.00392705
I0317 12:09:26.005496  3513 solver.cpp:244]     Train net output #0: loss = 0.00392708 (* 1 = 0.00392708 loss)
I0317 12:09:26.005508  3513 sgd_solver.cpp:106] Iteration 25380, lr = 0.01
I0317 12:09:33.332769  3513 solver.cpp:228] Iteration 25400, loss = 0.00419724
I0317 12:09:33.332839  3513 solver.cpp:244]     Train net output #0: loss = 0.00419727 (* 1 = 0.00419727 loss)
I0317 12:09:33.332852  3513 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0317 12:09:40.643942  3513 solver.cpp:228] Iteration 25420, loss = 0.0047013
I0317 12:09:40.644011  3513 solver.cpp:244]     Train net output #0: loss = 0.00470133 (* 1 = 0.00470133 loss)
I0317 12:09:40.644024  3513 sgd_solver.cpp:106] Iteration 25420, lr = 0.01
I0317 12:09:47.961654  3513 solver.cpp:228] Iteration 25440, loss = 0.0128586
I0317 12:09:47.961839  3513 solver.cpp:244]     Train net output #0: loss = 0.0128586 (* 1 = 0.0128586 loss)
I0317 12:09:47.961853  3513 sgd_solver.cpp:106] Iteration 25440, lr = 0.01
I0317 12:09:55.281309  3513 solver.cpp:228] Iteration 25460, loss = 0.00547162
I0317 12:09:55.281378  3513 solver.cpp:244]     Train net output #0: loss = 0.00547165 (* 1 = 0.00547165 loss)
I0317 12:09:55.281389  3513 sgd_solver.cpp:106] Iteration 25460, lr = 0.01
I0317 12:10:02.601691  3513 solver.cpp:228] Iteration 25480, loss = 0.00484766
I0317 12:10:02.601769  3513 solver.cpp:244]     Train net output #0: loss = 0.00484769 (* 1 = 0.00484769 loss)
I0317 12:10:02.601783  3513 sgd_solver.cpp:106] Iteration 25480, lr = 0.01
I0317 12:10:09.556236  3513 solver.cpp:337] Iteration 25500, Testing net (#0)
I0317 12:12:03.413684  3513 solver.cpp:404]     Test net output #0: loss = 0.0603139 (* 1 = 0.0603139 loss)
I0317 12:12:03.413816  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66336 (* 1 = 0.66336 loss)
I0317 12:12:03.750185  3513 solver.cpp:228] Iteration 25500, loss = 0.00361393
I0317 12:12:03.750250  3513 solver.cpp:244]     Train net output #0: loss = 0.00361395 (* 1 = 0.00361395 loss)
I0317 12:12:03.750263  3513 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0317 12:12:10.990211  3513 solver.cpp:228] Iteration 25520, loss = 0.00293576
I0317 12:12:10.990278  3513 solver.cpp:244]     Train net output #0: loss = 0.00293579 (* 1 = 0.00293579 loss)
I0317 12:12:10.990291  3513 sgd_solver.cpp:106] Iteration 25520, lr = 0.01
I0317 12:12:18.269330  3513 solver.cpp:228] Iteration 25540, loss = 0.00414745
I0317 12:12:18.269397  3513 solver.cpp:244]     Train net output #0: loss = 0.00414748 (* 1 = 0.00414748 loss)
I0317 12:12:18.269409  3513 sgd_solver.cpp:106] Iteration 25540, lr = 0.01
I0317 12:12:25.578915  3513 solver.cpp:228] Iteration 25560, loss = 0.00220726
I0317 12:12:25.578994  3513 solver.cpp:244]     Train net output #0: loss = 0.00220729 (* 1 = 0.00220729 loss)
I0317 12:12:25.579008  3513 sgd_solver.cpp:106] Iteration 25560, lr = 0.01
I0317 12:12:32.908846  3513 solver.cpp:228] Iteration 25580, loss = 0.00640749
I0317 12:12:32.908923  3513 solver.cpp:244]     Train net output #0: loss = 0.00640752 (* 1 = 0.00640752 loss)
I0317 12:12:32.908937  3513 sgd_solver.cpp:106] Iteration 25580, lr = 0.01
I0317 12:12:40.240639  3513 solver.cpp:228] Iteration 25600, loss = 0.00446554
I0317 12:12:40.240814  3513 solver.cpp:244]     Train net output #0: loss = 0.00446557 (* 1 = 0.00446557 loss)
I0317 12:12:40.240828  3513 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0317 12:12:47.563433  3513 solver.cpp:228] Iteration 25620, loss = 0.0057122
I0317 12:12:47.563499  3513 solver.cpp:244]     Train net output #0: loss = 0.00571223 (* 1 = 0.00571223 loss)
I0317 12:12:47.563513  3513 sgd_solver.cpp:106] Iteration 25620, lr = 0.01
I0317 12:12:54.895404  3513 solver.cpp:228] Iteration 25640, loss = 0.00841488
I0317 12:12:54.895467  3513 solver.cpp:244]     Train net output #0: loss = 0.0084149 (* 1 = 0.0084149 loss)
I0317 12:12:54.895479  3513 sgd_solver.cpp:106] Iteration 25640, lr = 0.01
I0317 12:13:02.219292  3513 solver.cpp:228] Iteration 25660, loss = 0.00536391
I0317 12:13:02.219362  3513 solver.cpp:244]     Train net output #0: loss = 0.00536393 (* 1 = 0.00536393 loss)
I0317 12:13:02.219375  3513 sgd_solver.cpp:106] Iteration 25660, lr = 0.01
I0317 12:13:09.544714  3513 solver.cpp:228] Iteration 25680, loss = 0.00367152
I0317 12:13:09.544782  3513 solver.cpp:244]     Train net output #0: loss = 0.00367155 (* 1 = 0.00367155 loss)
I0317 12:13:09.544795  3513 sgd_solver.cpp:106] Iteration 25680, lr = 0.01
I0317 12:13:16.868984  3513 solver.cpp:228] Iteration 25700, loss = 0.00274352
I0317 12:13:16.869140  3513 solver.cpp:244]     Train net output #0: loss = 0.00274354 (* 1 = 0.00274354 loss)
I0317 12:13:16.869154  3513 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0317 12:13:24.188696  3513 solver.cpp:228] Iteration 25720, loss = 0.00235165
I0317 12:13:24.188760  3513 solver.cpp:244]     Train net output #0: loss = 0.00235168 (* 1 = 0.00235168 loss)
I0317 12:13:24.188773  3513 sgd_solver.cpp:106] Iteration 25720, lr = 0.01
I0317 12:13:31.512173  3513 solver.cpp:228] Iteration 25740, loss = 0.00428363
I0317 12:13:31.512255  3513 solver.cpp:244]     Train net output #0: loss = 0.00428366 (* 1 = 0.00428366 loss)
I0317 12:13:31.512270  3513 sgd_solver.cpp:106] Iteration 25740, lr = 0.01
I0317 12:13:34.808555  3513 solver.cpp:337] Iteration 25750, Testing net (#0)
I0317 12:15:28.685349  3513 solver.cpp:404]     Test net output #0: loss = 0.0609109 (* 1 = 0.0609109 loss)
I0317 12:15:28.685462  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 12:15:32.628406  3513 solver.cpp:228] Iteration 25760, loss = 0.0025252
I0317 12:15:32.628473  3513 solver.cpp:244]     Train net output #0: loss = 0.00252522 (* 1 = 0.00252522 loss)
I0317 12:15:32.628486  3513 sgd_solver.cpp:106] Iteration 25760, lr = 0.01
I0317 12:15:39.881134  3513 solver.cpp:228] Iteration 25780, loss = 0.00327872
I0317 12:15:39.881206  3513 solver.cpp:244]     Train net output #0: loss = 0.00327874 (* 1 = 0.00327874 loss)
I0317 12:15:39.881219  3513 sgd_solver.cpp:106] Iteration 25780, lr = 0.01
I0317 12:15:47.173465  3513 solver.cpp:228] Iteration 25800, loss = 0.00811851
I0317 12:15:47.173532  3513 solver.cpp:244]     Train net output #0: loss = 0.00811854 (* 1 = 0.00811854 loss)
I0317 12:15:47.173545  3513 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0317 12:15:54.481673  3513 solver.cpp:228] Iteration 25820, loss = 0.00389059
I0317 12:15:54.481735  3513 solver.cpp:244]     Train net output #0: loss = 0.00389062 (* 1 = 0.00389062 loss)
I0317 12:15:54.481747  3513 sgd_solver.cpp:106] Iteration 25820, lr = 0.01
I0317 12:16:01.809012  3513 solver.cpp:228] Iteration 25840, loss = 0.00361088
I0317 12:16:01.809161  3513 solver.cpp:244]     Train net output #0: loss = 0.0036109 (* 1 = 0.0036109 loss)
I0317 12:16:01.809176  3513 sgd_solver.cpp:106] Iteration 25840, lr = 0.01
I0317 12:16:09.141301  3513 solver.cpp:228] Iteration 25860, loss = 0.00243111
I0317 12:16:09.141377  3513 solver.cpp:244]     Train net output #0: loss = 0.00243114 (* 1 = 0.00243114 loss)
I0317 12:16:09.141389  3513 sgd_solver.cpp:106] Iteration 25860, lr = 0.01
I0317 12:16:16.464622  3513 solver.cpp:228] Iteration 25880, loss = 0.00297172
I0317 12:16:16.464685  3513 solver.cpp:244]     Train net output #0: loss = 0.00297175 (* 1 = 0.00297175 loss)
I0317 12:16:16.464699  3513 sgd_solver.cpp:106] Iteration 25880, lr = 0.01
I0317 12:16:23.794176  3513 solver.cpp:228] Iteration 25900, loss = 0.0039254
I0317 12:16:23.794245  3513 solver.cpp:244]     Train net output #0: loss = 0.00392543 (* 1 = 0.00392543 loss)
I0317 12:16:23.794258  3513 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0317 12:16:31.121983  3513 solver.cpp:228] Iteration 25920, loss = 0.00305073
I0317 12:16:31.122045  3513 solver.cpp:244]     Train net output #0: loss = 0.00305076 (* 1 = 0.00305076 loss)
I0317 12:16:31.122058  3513 sgd_solver.cpp:106] Iteration 25920, lr = 0.01
I0317 12:16:38.439216  3513 solver.cpp:228] Iteration 25940, loss = 0.00578586
I0317 12:16:38.439383  3513 solver.cpp:244]     Train net output #0: loss = 0.00578588 (* 1 = 0.00578588 loss)
I0317 12:16:38.439398  3513 sgd_solver.cpp:106] Iteration 25940, lr = 0.01
I0317 12:16:45.761657  3513 solver.cpp:228] Iteration 25960, loss = 0.00404047
I0317 12:16:45.761725  3513 solver.cpp:244]     Train net output #0: loss = 0.0040405 (* 1 = 0.0040405 loss)
I0317 12:16:45.761747  3513 sgd_solver.cpp:106] Iteration 25960, lr = 0.01
I0317 12:16:53.085969  3513 solver.cpp:228] Iteration 25980, loss = 0.00920701
I0317 12:16:53.086043  3513 solver.cpp:244]     Train net output #0: loss = 0.00920703 (* 1 = 0.00920703 loss)
I0317 12:16:53.086058  3513 sgd_solver.cpp:106] Iteration 25980, lr = 0.01
I0317 12:17:00.054179  3513 solver.cpp:337] Iteration 26000, Testing net (#0)
I0317 12:18:53.925731  3513 solver.cpp:404]     Test net output #0: loss = 0.0618396 (* 1 = 0.0618396 loss)
I0317 12:18:53.925846  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64432 (* 1 = 0.64432 loss)
I0317 12:18:54.263038  3513 solver.cpp:228] Iteration 26000, loss = 0.00628109
I0317 12:18:54.263104  3513 solver.cpp:244]     Train net output #0: loss = 0.00628112 (* 1 = 0.00628112 loss)
I0317 12:18:54.263118  3513 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0317 12:19:01.514458  3513 solver.cpp:228] Iteration 26020, loss = 0.00575529
I0317 12:19:01.514528  3513 solver.cpp:244]     Train net output #0: loss = 0.00575531 (* 1 = 0.00575531 loss)
I0317 12:19:01.514542  3513 sgd_solver.cpp:106] Iteration 26020, lr = 0.01
I0317 12:19:08.790331  3513 solver.cpp:228] Iteration 26040, loss = 0.00232713
I0317 12:19:08.790402  3513 solver.cpp:244]     Train net output #0: loss = 0.00232715 (* 1 = 0.00232715 loss)
I0317 12:19:08.790417  3513 sgd_solver.cpp:106] Iteration 26040, lr = 0.01
I0317 12:19:16.095723  3513 solver.cpp:228] Iteration 26060, loss = 0.00458259
I0317 12:19:16.095799  3513 solver.cpp:244]     Train net output #0: loss = 0.00458262 (* 1 = 0.00458262 loss)
I0317 12:19:16.095813  3513 sgd_solver.cpp:106] Iteration 26060, lr = 0.01
I0317 12:19:23.405331  3513 solver.cpp:228] Iteration 26080, loss = 0.00354514
I0317 12:19:23.405400  3513 solver.cpp:244]     Train net output #0: loss = 0.00354517 (* 1 = 0.00354517 loss)
I0317 12:19:23.405412  3513 sgd_solver.cpp:106] Iteration 26080, lr = 0.01
I0317 12:19:30.726120  3513 solver.cpp:228] Iteration 26100, loss = 0.00664877
I0317 12:19:30.726253  3513 solver.cpp:244]     Train net output #0: loss = 0.0066488 (* 1 = 0.0066488 loss)
I0317 12:19:30.726266  3513 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0317 12:19:38.054076  3513 solver.cpp:228] Iteration 26120, loss = 0.00549096
I0317 12:19:38.054144  3513 solver.cpp:244]     Train net output #0: loss = 0.00549098 (* 1 = 0.00549098 loss)
I0317 12:19:38.054157  3513 sgd_solver.cpp:106] Iteration 26120, lr = 0.01
I0317 12:19:45.393582  3513 solver.cpp:228] Iteration 26140, loss = 0.00533305
I0317 12:19:45.393648  3513 solver.cpp:244]     Train net output #0: loss = 0.00533308 (* 1 = 0.00533308 loss)
I0317 12:19:45.393661  3513 sgd_solver.cpp:106] Iteration 26140, lr = 0.01
I0317 12:19:52.724748  3513 solver.cpp:228] Iteration 26160, loss = 0.00794865
I0317 12:19:52.724815  3513 solver.cpp:244]     Train net output #0: loss = 0.00794867 (* 1 = 0.00794867 loss)
I0317 12:19:52.724829  3513 sgd_solver.cpp:106] Iteration 26160, lr = 0.01
I0317 12:20:00.050829  3513 solver.cpp:228] Iteration 26180, loss = 0.00731667
I0317 12:20:00.050896  3513 solver.cpp:244]     Train net output #0: loss = 0.0073167 (* 1 = 0.0073167 loss)
I0317 12:20:00.050909  3513 sgd_solver.cpp:106] Iteration 26180, lr = 0.01
I0317 12:20:07.378582  3513 solver.cpp:228] Iteration 26200, loss = 0.00479948
I0317 12:20:07.378769  3513 solver.cpp:244]     Train net output #0: loss = 0.0047995 (* 1 = 0.0047995 loss)
I0317 12:20:07.378783  3513 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0317 12:20:14.707028  3513 solver.cpp:228] Iteration 26220, loss = 0.00203771
I0317 12:20:14.707092  3513 solver.cpp:244]     Train net output #0: loss = 0.00203774 (* 1 = 0.00203774 loss)
I0317 12:20:14.707103  3513 sgd_solver.cpp:106] Iteration 26220, lr = 0.01
I0317 12:20:22.032166  3513 solver.cpp:228] Iteration 26240, loss = 0.00259754
I0317 12:20:22.032234  3513 solver.cpp:244]     Train net output #0: loss = 0.00259757 (* 1 = 0.00259757 loss)
I0317 12:20:22.032248  3513 sgd_solver.cpp:106] Iteration 26240, lr = 0.01
I0317 12:20:25.330265  3513 solver.cpp:337] Iteration 26250, Testing net (#0)
I0317 12:22:19.223176  3513 solver.cpp:404]     Test net output #0: loss = 0.0591835 (* 1 = 0.0591835 loss)
I0317 12:22:19.223299  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65376 (* 1 = 0.65376 loss)
I0317 12:22:23.164214  3513 solver.cpp:228] Iteration 26260, loss = 0.00195812
I0317 12:22:23.164288  3513 solver.cpp:244]     Train net output #0: loss = 0.00195814 (* 1 = 0.00195814 loss)
I0317 12:22:23.164312  3513 sgd_solver.cpp:106] Iteration 26260, lr = 0.01
I0317 12:22:30.427101  3513 solver.cpp:228] Iteration 26280, loss = 0.00312841
I0317 12:22:30.427171  3513 solver.cpp:244]     Train net output #0: loss = 0.00312843 (* 1 = 0.00312843 loss)
I0317 12:22:30.427184  3513 sgd_solver.cpp:106] Iteration 26280, lr = 0.01
I0317 12:22:37.726974  3513 solver.cpp:228] Iteration 26300, loss = 0.004142
I0317 12:22:37.727041  3513 solver.cpp:244]     Train net output #0: loss = 0.00414203 (* 1 = 0.00414203 loss)
I0317 12:22:37.727054  3513 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0317 12:22:45.044534  3513 solver.cpp:228] Iteration 26320, loss = 0.00427088
I0317 12:22:45.044601  3513 solver.cpp:244]     Train net output #0: loss = 0.00427091 (* 1 = 0.00427091 loss)
I0317 12:22:45.044615  3513 sgd_solver.cpp:106] Iteration 26320, lr = 0.01
I0317 12:22:52.365950  3513 solver.cpp:228] Iteration 26340, loss = 0.00807001
I0317 12:22:52.366107  3513 solver.cpp:244]     Train net output #0: loss = 0.00807003 (* 1 = 0.00807003 loss)
I0317 12:22:52.366122  3513 sgd_solver.cpp:106] Iteration 26340, lr = 0.01
I0317 12:22:59.694257  3513 solver.cpp:228] Iteration 26360, loss = 0.00327168
I0317 12:22:59.694324  3513 solver.cpp:244]     Train net output #0: loss = 0.00327171 (* 1 = 0.00327171 loss)
I0317 12:22:59.694336  3513 sgd_solver.cpp:106] Iteration 26360, lr = 0.01
I0317 12:23:07.023712  3513 solver.cpp:228] Iteration 26380, loss = 0.00390102
I0317 12:23:07.023787  3513 solver.cpp:244]     Train net output #0: loss = 0.00390105 (* 1 = 0.00390105 loss)
I0317 12:23:07.023802  3513 sgd_solver.cpp:106] Iteration 26380, lr = 0.01
I0317 12:23:14.341447  3513 solver.cpp:228] Iteration 26400, loss = 0.00117011
I0317 12:23:14.341516  3513 solver.cpp:244]     Train net output #0: loss = 0.00117014 (* 1 = 0.00117014 loss)
I0317 12:23:14.341529  3513 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0317 12:23:21.666457  3513 solver.cpp:228] Iteration 26420, loss = 0.00214698
I0317 12:23:21.666522  3513 solver.cpp:244]     Train net output #0: loss = 0.00214701 (* 1 = 0.00214701 loss)
I0317 12:23:21.666534  3513 sgd_solver.cpp:106] Iteration 26420, lr = 0.01
I0317 12:23:28.997226  3513 solver.cpp:228] Iteration 26440, loss = 0.00211739
I0317 12:23:28.997395  3513 solver.cpp:244]     Train net output #0: loss = 0.00211742 (* 1 = 0.00211742 loss)
I0317 12:23:28.997409  3513 sgd_solver.cpp:106] Iteration 26440, lr = 0.01
I0317 12:23:36.329421  3513 solver.cpp:228] Iteration 26460, loss = 0.00376159
I0317 12:23:36.329488  3513 solver.cpp:244]     Train net output #0: loss = 0.00376161 (* 1 = 0.00376161 loss)
I0317 12:23:36.329500  3513 sgd_solver.cpp:106] Iteration 26460, lr = 0.01
I0317 12:23:43.663022  3513 solver.cpp:228] Iteration 26480, loss = 0.00552216
I0317 12:23:43.663085  3513 solver.cpp:244]     Train net output #0: loss = 0.00552219 (* 1 = 0.00552219 loss)
I0317 12:23:43.663099  3513 sgd_solver.cpp:106] Iteration 26480, lr = 0.01
I0317 12:23:50.626443  3513 solver.cpp:337] Iteration 26500, Testing net (#0)
I0317 12:25:44.509773  3513 solver.cpp:404]     Test net output #0: loss = 0.0635222 (* 1 = 0.0635222 loss)
I0317 12:25:44.509928  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 12:25:44.846323  3513 solver.cpp:228] Iteration 26500, loss = 0.00543266
I0317 12:25:44.846390  3513 solver.cpp:244]     Train net output #0: loss = 0.00543269 (* 1 = 0.00543269 loss)
I0317 12:25:44.846402  3513 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0317 12:25:52.098268  3513 solver.cpp:228] Iteration 26520, loss = 0.00773824
I0317 12:25:52.098335  3513 solver.cpp:244]     Train net output #0: loss = 0.00773827 (* 1 = 0.00773827 loss)
I0317 12:25:52.098348  3513 sgd_solver.cpp:106] Iteration 26520, lr = 0.01
I0317 12:25:59.388556  3513 solver.cpp:228] Iteration 26540, loss = 0.00708737
I0317 12:25:59.388625  3513 solver.cpp:244]     Train net output #0: loss = 0.0070874 (* 1 = 0.0070874 loss)
I0317 12:25:59.388638  3513 sgd_solver.cpp:106] Iteration 26540, lr = 0.01
I0317 12:26:06.705253  3513 solver.cpp:228] Iteration 26560, loss = 0.00484732
I0317 12:26:06.705315  3513 solver.cpp:244]     Train net output #0: loss = 0.00484735 (* 1 = 0.00484735 loss)
I0317 12:26:06.705328  3513 sgd_solver.cpp:106] Iteration 26560, lr = 0.01
I0317 12:26:14.026979  3513 solver.cpp:228] Iteration 26580, loss = 0.00373821
I0317 12:26:14.027048  3513 solver.cpp:244]     Train net output #0: loss = 0.00373824 (* 1 = 0.00373824 loss)
I0317 12:26:14.027061  3513 sgd_solver.cpp:106] Iteration 26580, lr = 0.01
I0317 12:26:21.353183  3513 solver.cpp:228] Iteration 26600, loss = 0.00123283
I0317 12:26:21.353349  3513 solver.cpp:244]     Train net output #0: loss = 0.00123286 (* 1 = 0.00123286 loss)
I0317 12:26:21.353364  3513 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0317 12:26:28.675516  3513 solver.cpp:228] Iteration 26620, loss = 0.0030995
I0317 12:26:28.675588  3513 solver.cpp:244]     Train net output #0: loss = 0.00309952 (* 1 = 0.00309952 loss)
I0317 12:26:28.675601  3513 sgd_solver.cpp:106] Iteration 26620, lr = 0.01
I0317 12:26:35.995424  3513 solver.cpp:228] Iteration 26640, loss = 0.00479805
I0317 12:26:35.995489  3513 solver.cpp:244]     Train net output #0: loss = 0.00479808 (* 1 = 0.00479808 loss)
I0317 12:26:35.995502  3513 sgd_solver.cpp:106] Iteration 26640, lr = 0.01
I0317 12:26:43.319437  3513 solver.cpp:228] Iteration 26660, loss = 0.00347613
I0317 12:26:43.319510  3513 solver.cpp:244]     Train net output #0: loss = 0.00347616 (* 1 = 0.00347616 loss)
I0317 12:26:43.319522  3513 sgd_solver.cpp:106] Iteration 26660, lr = 0.01
I0317 12:26:50.648515  3513 solver.cpp:228] Iteration 26680, loss = 0.00242653
I0317 12:26:50.648583  3513 solver.cpp:244]     Train net output #0: loss = 0.00242656 (* 1 = 0.00242656 loss)
I0317 12:26:50.648596  3513 sgd_solver.cpp:106] Iteration 26680, lr = 0.01
I0317 12:26:57.974053  3513 solver.cpp:228] Iteration 26700, loss = 0.00447884
I0317 12:26:57.974221  3513 solver.cpp:244]     Train net output #0: loss = 0.00447887 (* 1 = 0.00447887 loss)
I0317 12:26:57.974236  3513 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0317 12:27:05.295138  3513 solver.cpp:228] Iteration 26720, loss = 0.00561048
I0317 12:27:05.295227  3513 solver.cpp:244]     Train net output #0: loss = 0.00561051 (* 1 = 0.00561051 loss)
I0317 12:27:05.295240  3513 sgd_solver.cpp:106] Iteration 26720, lr = 0.01
I0317 12:27:12.625502  3513 solver.cpp:228] Iteration 26740, loss = 0.00671388
I0317 12:27:12.625566  3513 solver.cpp:244]     Train net output #0: loss = 0.00671391 (* 1 = 0.00671391 loss)
I0317 12:27:12.625578  3513 sgd_solver.cpp:106] Iteration 26740, lr = 0.01
I0317 12:27:15.922694  3513 solver.cpp:337] Iteration 26750, Testing net (#0)
I0317 12:29:09.759770  3513 solver.cpp:404]     Test net output #0: loss = 0.0615492 (* 1 = 0.0615492 loss)
I0317 12:29:09.759951  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66348 (* 1 = 0.66348 loss)
I0317 12:29:13.704752  3513 solver.cpp:228] Iteration 26760, loss = 0.0025025
I0317 12:29:13.704816  3513 solver.cpp:244]     Train net output #0: loss = 0.00250253 (* 1 = 0.00250253 loss)
I0317 12:29:13.704828  3513 sgd_solver.cpp:106] Iteration 26760, lr = 0.01
I0317 12:29:20.978348  3513 solver.cpp:228] Iteration 26780, loss = 0.00145561
I0317 12:29:20.978415  3513 solver.cpp:244]     Train net output #0: loss = 0.00145564 (* 1 = 0.00145564 loss)
I0317 12:29:20.978436  3513 sgd_solver.cpp:106] Iteration 26780, lr = 0.01
I0317 12:29:28.291337  3513 solver.cpp:228] Iteration 26800, loss = 0.00518923
I0317 12:29:28.291400  3513 solver.cpp:244]     Train net output #0: loss = 0.00518926 (* 1 = 0.00518926 loss)
I0317 12:29:28.291414  3513 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0317 12:29:35.615231  3513 solver.cpp:228] Iteration 26820, loss = 0.00236761
I0317 12:29:35.615306  3513 solver.cpp:244]     Train net output #0: loss = 0.00236764 (* 1 = 0.00236764 loss)
I0317 12:29:35.615320  3513 sgd_solver.cpp:106] Iteration 26820, lr = 0.01
I0317 12:29:42.946717  3513 solver.cpp:228] Iteration 26840, loss = 0.00574363
I0317 12:29:42.946876  3513 solver.cpp:244]     Train net output #0: loss = 0.00574366 (* 1 = 0.00574366 loss)
I0317 12:29:42.946890  3513 sgd_solver.cpp:106] Iteration 26840, lr = 0.01
I0317 12:29:50.281604  3513 solver.cpp:228] Iteration 26860, loss = 0.00357833
I0317 12:29:50.281671  3513 solver.cpp:244]     Train net output #0: loss = 0.00357836 (* 1 = 0.00357836 loss)
I0317 12:29:50.281683  3513 sgd_solver.cpp:106] Iteration 26860, lr = 0.01
I0317 12:29:57.606593  3513 solver.cpp:228] Iteration 26880, loss = 0.00627518
I0317 12:29:57.606660  3513 solver.cpp:244]     Train net output #0: loss = 0.00627521 (* 1 = 0.00627521 loss)
I0317 12:29:57.606673  3513 sgd_solver.cpp:106] Iteration 26880, lr = 0.01
I0317 12:30:04.931924  3513 solver.cpp:228] Iteration 26900, loss = 0.00605544
I0317 12:30:04.931988  3513 solver.cpp:244]     Train net output #0: loss = 0.00605547 (* 1 = 0.00605547 loss)
I0317 12:30:04.932001  3513 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0317 12:30:12.251689  3513 solver.cpp:228] Iteration 26920, loss = 0.00764367
I0317 12:30:12.251758  3513 solver.cpp:244]     Train net output #0: loss = 0.0076437 (* 1 = 0.0076437 loss)
I0317 12:30:12.251771  3513 sgd_solver.cpp:106] Iteration 26920, lr = 0.01
I0317 12:30:19.572023  3513 solver.cpp:228] Iteration 26940, loss = 0.00336032
I0317 12:30:19.572170  3513 solver.cpp:244]     Train net output #0: loss = 0.00336035 (* 1 = 0.00336035 loss)
I0317 12:30:19.572185  3513 sgd_solver.cpp:106] Iteration 26940, lr = 0.01
I0317 12:30:26.888185  3513 solver.cpp:228] Iteration 26960, loss = 0.000972109
I0317 12:30:26.888250  3513 solver.cpp:244]     Train net output #0: loss = 0.00097214 (* 1 = 0.00097214 loss)
I0317 12:30:26.888263  3513 sgd_solver.cpp:106] Iteration 26960, lr = 0.01
I0317 12:30:34.212740  3513 solver.cpp:228] Iteration 26980, loss = 0.00346361
I0317 12:30:34.212810  3513 solver.cpp:244]     Train net output #0: loss = 0.00346364 (* 1 = 0.00346364 loss)
I0317 12:30:34.212823  3513 sgd_solver.cpp:106] Iteration 26980, lr = 0.01
I0317 12:30:41.168128  3513 solver.cpp:337] Iteration 27000, Testing net (#0)
I0317 12:32:35.036743  3513 solver.cpp:404]     Test net output #0: loss = 0.0612862 (* 1 = 0.0612862 loss)
I0317 12:32:35.036882  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65376 (* 1 = 0.65376 loss)
I0317 12:32:35.372694  3513 solver.cpp:228] Iteration 27000, loss = 0.0028357
I0317 12:32:35.372761  3513 solver.cpp:244]     Train net output #0: loss = 0.00283573 (* 1 = 0.00283573 loss)
I0317 12:32:35.372774  3513 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0317 12:32:42.615260  3513 solver.cpp:228] Iteration 27020, loss = 0.00652683
I0317 12:32:42.615327  3513 solver.cpp:244]     Train net output #0: loss = 0.00652686 (* 1 = 0.00652686 loss)
I0317 12:32:42.615350  3513 sgd_solver.cpp:106] Iteration 27020, lr = 0.01
I0317 12:32:49.908679  3513 solver.cpp:228] Iteration 27040, loss = 0.00277018
I0317 12:32:49.908747  3513 solver.cpp:244]     Train net output #0: loss = 0.00277021 (* 1 = 0.00277021 loss)
I0317 12:32:49.908761  3513 sgd_solver.cpp:106] Iteration 27040, lr = 0.01
I0317 12:32:57.218724  3513 solver.cpp:228] Iteration 27060, loss = 0.00597727
I0317 12:32:57.218786  3513 solver.cpp:244]     Train net output #0: loss = 0.0059773 (* 1 = 0.0059773 loss)
I0317 12:32:57.218798  3513 sgd_solver.cpp:106] Iteration 27060, lr = 0.01
I0317 12:33:04.541796  3513 solver.cpp:228] Iteration 27080, loss = 0.0043139
I0317 12:33:04.541864  3513 solver.cpp:244]     Train net output #0: loss = 0.00431393 (* 1 = 0.00431393 loss)
I0317 12:33:04.541887  3513 sgd_solver.cpp:106] Iteration 27080, lr = 0.01
I0317 12:33:11.866523  3513 solver.cpp:228] Iteration 27100, loss = 0.00417736
I0317 12:33:11.866732  3513 solver.cpp:244]     Train net output #0: loss = 0.00417739 (* 1 = 0.00417739 loss)
I0317 12:33:11.866746  3513 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0317 12:33:19.196053  3513 solver.cpp:228] Iteration 27120, loss = 0.00313271
I0317 12:33:19.196116  3513 solver.cpp:244]     Train net output #0: loss = 0.00313274 (* 1 = 0.00313274 loss)
I0317 12:33:19.196130  3513 sgd_solver.cpp:106] Iteration 27120, lr = 0.01
I0317 12:33:26.531443  3513 solver.cpp:228] Iteration 27140, loss = 0.00162546
I0317 12:33:26.531514  3513 solver.cpp:244]     Train net output #0: loss = 0.00162549 (* 1 = 0.00162549 loss)
I0317 12:33:26.531527  3513 sgd_solver.cpp:106] Iteration 27140, lr = 0.01
I0317 12:33:33.859967  3513 solver.cpp:228] Iteration 27160, loss = 0.00289521
I0317 12:33:33.860039  3513 solver.cpp:244]     Train net output #0: loss = 0.00289524 (* 1 = 0.00289524 loss)
I0317 12:33:33.860061  3513 sgd_solver.cpp:106] Iteration 27160, lr = 0.01
I0317 12:33:41.187711  3513 solver.cpp:228] Iteration 27180, loss = 0.0020503
I0317 12:33:41.187778  3513 solver.cpp:244]     Train net output #0: loss = 0.00205033 (* 1 = 0.00205033 loss)
I0317 12:33:41.187793  3513 sgd_solver.cpp:106] Iteration 27180, lr = 0.01
I0317 12:33:48.513602  3513 solver.cpp:228] Iteration 27200, loss = 0.00396201
I0317 12:33:48.513761  3513 solver.cpp:244]     Train net output #0: loss = 0.00396204 (* 1 = 0.00396204 loss)
I0317 12:33:48.513775  3513 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0317 12:33:55.842874  3513 solver.cpp:228] Iteration 27220, loss = 0.00419632
I0317 12:33:55.842943  3513 solver.cpp:244]     Train net output #0: loss = 0.00419635 (* 1 = 0.00419635 loss)
I0317 12:33:55.842955  3513 sgd_solver.cpp:106] Iteration 27220, lr = 0.01
I0317 12:34:03.166123  3513 solver.cpp:228] Iteration 27240, loss = 0.0079114
I0317 12:34:03.166194  3513 solver.cpp:244]     Train net output #0: loss = 0.00791143 (* 1 = 0.00791143 loss)
I0317 12:34:03.166208  3513 sgd_solver.cpp:106] Iteration 27240, lr = 0.01
I0317 12:34:06.459918  3513 solver.cpp:337] Iteration 27250, Testing net (#0)
I0317 12:36:00.339001  3513 solver.cpp:404]     Test net output #0: loss = 0.0642707 (* 1 = 0.0642707 loss)
I0317 12:36:00.339140  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 12:36:04.284955  3513 solver.cpp:228] Iteration 27260, loss = 0.00342048
I0317 12:36:04.285025  3513 solver.cpp:244]     Train net output #0: loss = 0.00342051 (* 1 = 0.00342051 loss)
I0317 12:36:04.285038  3513 sgd_solver.cpp:106] Iteration 27260, lr = 0.01
I0317 12:36:11.558327  3513 solver.cpp:228] Iteration 27280, loss = 0.00522081
I0317 12:36:11.558395  3513 solver.cpp:244]     Train net output #0: loss = 0.00522084 (* 1 = 0.00522084 loss)
I0317 12:36:11.558408  3513 sgd_solver.cpp:106] Iteration 27280, lr = 0.01
I0317 12:36:18.859061  3513 solver.cpp:228] Iteration 27300, loss = 0.00204405
I0317 12:36:18.859124  3513 solver.cpp:244]     Train net output #0: loss = 0.00204408 (* 1 = 0.00204408 loss)
I0317 12:36:18.859138  3513 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0317 12:36:26.180730  3513 solver.cpp:228] Iteration 27320, loss = 0.00390135
I0317 12:36:26.180799  3513 solver.cpp:244]     Train net output #0: loss = 0.00390138 (* 1 = 0.00390138 loss)
I0317 12:36:26.180811  3513 sgd_solver.cpp:106] Iteration 27320, lr = 0.01
I0317 12:36:33.510866  3513 solver.cpp:228] Iteration 27340, loss = 0.00319513
I0317 12:36:33.511075  3513 solver.cpp:244]     Train net output #0: loss = 0.00319516 (* 1 = 0.00319516 loss)
I0317 12:36:33.511088  3513 sgd_solver.cpp:106] Iteration 27340, lr = 0.01
I0317 12:36:40.834064  3513 solver.cpp:228] Iteration 27360, loss = 0.00227045
I0317 12:36:40.834132  3513 solver.cpp:244]     Train net output #0: loss = 0.00227049 (* 1 = 0.00227049 loss)
I0317 12:36:40.834146  3513 sgd_solver.cpp:106] Iteration 27360, lr = 0.01
I0317 12:36:48.165494  3513 solver.cpp:228] Iteration 27380, loss = 0.00414638
I0317 12:36:48.165561  3513 solver.cpp:244]     Train net output #0: loss = 0.00414642 (* 1 = 0.00414642 loss)
I0317 12:36:48.165573  3513 sgd_solver.cpp:106] Iteration 27380, lr = 0.01
I0317 12:36:55.492620  3513 solver.cpp:228] Iteration 27400, loss = 0.00336602
I0317 12:36:55.492688  3513 solver.cpp:244]     Train net output #0: loss = 0.00336605 (* 1 = 0.00336605 loss)
I0317 12:36:55.492702  3513 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0317 12:37:02.812934  3513 solver.cpp:228] Iteration 27420, loss = 0.0129831
I0317 12:37:02.813006  3513 solver.cpp:244]     Train net output #0: loss = 0.0129831 (* 1 = 0.0129831 loss)
I0317 12:37:02.813020  3513 sgd_solver.cpp:106] Iteration 27420, lr = 0.01
I0317 12:37:10.141266  3513 solver.cpp:228] Iteration 27440, loss = 0.00500583
I0317 12:37:10.141417  3513 solver.cpp:244]     Train net output #0: loss = 0.00500586 (* 1 = 0.00500586 loss)
I0317 12:37:10.141432  3513 sgd_solver.cpp:106] Iteration 27440, lr = 0.01
I0317 12:37:17.469727  3513 solver.cpp:228] Iteration 27460, loss = 0.00530756
I0317 12:37:17.469807  3513 solver.cpp:244]     Train net output #0: loss = 0.00530759 (* 1 = 0.00530759 loss)
I0317 12:37:17.469822  3513 sgd_solver.cpp:106] Iteration 27460, lr = 0.01
I0317 12:37:24.795033  3513 solver.cpp:228] Iteration 27480, loss = 0.00202812
I0317 12:37:24.795101  3513 solver.cpp:244]     Train net output #0: loss = 0.00202815 (* 1 = 0.00202815 loss)
I0317 12:37:24.795114  3513 sgd_solver.cpp:106] Iteration 27480, lr = 0.01
I0317 12:37:31.754657  3513 solver.cpp:337] Iteration 27500, Testing net (#0)
I0317 12:39:25.650379  3513 solver.cpp:404]     Test net output #0: loss = 0.0580249 (* 1 = 0.0580249 loss)
I0317 12:39:25.650503  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6538 (* 1 = 0.6538 loss)
I0317 12:39:25.986819  3513 solver.cpp:228] Iteration 27500, loss = 0.00177956
I0317 12:39:25.986881  3513 solver.cpp:244]     Train net output #0: loss = 0.00177959 (* 1 = 0.00177959 loss)
I0317 12:39:25.986893  3513 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0317 12:39:33.231567  3513 solver.cpp:228] Iteration 27520, loss = 0.0026899
I0317 12:39:33.231631  3513 solver.cpp:244]     Train net output #0: loss = 0.00268994 (* 1 = 0.00268994 loss)
I0317 12:39:33.231643  3513 sgd_solver.cpp:106] Iteration 27520, lr = 0.01
I0317 12:39:40.519330  3513 solver.cpp:228] Iteration 27540, loss = 0.00301938
I0317 12:39:40.519407  3513 solver.cpp:244]     Train net output #0: loss = 0.00301942 (* 1 = 0.00301942 loss)
I0317 12:39:40.519419  3513 sgd_solver.cpp:106] Iteration 27540, lr = 0.01
I0317 12:39:47.841827  3513 solver.cpp:228] Iteration 27560, loss = 0.00475135
I0317 12:39:47.841895  3513 solver.cpp:244]     Train net output #0: loss = 0.00475139 (* 1 = 0.00475139 loss)
I0317 12:39:47.841907  3513 sgd_solver.cpp:106] Iteration 27560, lr = 0.01
I0317 12:39:55.168128  3513 solver.cpp:228] Iteration 27580, loss = 0.00569509
I0317 12:39:55.168196  3513 solver.cpp:244]     Train net output #0: loss = 0.00569513 (* 1 = 0.00569513 loss)
I0317 12:39:55.168210  3513 sgd_solver.cpp:106] Iteration 27580, lr = 0.01
I0317 12:40:02.495065  3513 solver.cpp:228] Iteration 27600, loss = 0.00493331
I0317 12:40:02.495262  3513 solver.cpp:244]     Train net output #0: loss = 0.00493335 (* 1 = 0.00493335 loss)
I0317 12:40:02.495277  3513 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0317 12:40:09.819226  3513 solver.cpp:228] Iteration 27620, loss = 0.00402028
I0317 12:40:09.819294  3513 solver.cpp:244]     Train net output #0: loss = 0.00402031 (* 1 = 0.00402031 loss)
I0317 12:40:09.819308  3513 sgd_solver.cpp:106] Iteration 27620, lr = 0.01
I0317 12:40:17.145036  3513 solver.cpp:228] Iteration 27640, loss = 0.00498778
I0317 12:40:17.145112  3513 solver.cpp:244]     Train net output #0: loss = 0.00498781 (* 1 = 0.00498781 loss)
I0317 12:40:17.145124  3513 sgd_solver.cpp:106] Iteration 27640, lr = 0.01
I0317 12:40:24.475739  3513 solver.cpp:228] Iteration 27660, loss = 0.00286742
I0317 12:40:24.475806  3513 solver.cpp:244]     Train net output #0: loss = 0.00286745 (* 1 = 0.00286745 loss)
I0317 12:40:24.475819  3513 sgd_solver.cpp:106] Iteration 27660, lr = 0.01
I0317 12:40:31.795770  3513 solver.cpp:228] Iteration 27680, loss = 0.00270437
I0317 12:40:31.795846  3513 solver.cpp:244]     Train net output #0: loss = 0.0027044 (* 1 = 0.0027044 loss)
I0317 12:40:31.795859  3513 sgd_solver.cpp:106] Iteration 27680, lr = 0.01
I0317 12:40:39.114715  3513 solver.cpp:228] Iteration 27700, loss = 0.00167483
I0317 12:40:39.114876  3513 solver.cpp:244]     Train net output #0: loss = 0.00167486 (* 1 = 0.00167486 loss)
I0317 12:40:39.114890  3513 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0317 12:40:46.426858  3513 solver.cpp:228] Iteration 27720, loss = 0.00388175
I0317 12:40:46.426926  3513 solver.cpp:244]     Train net output #0: loss = 0.00388178 (* 1 = 0.00388178 loss)
I0317 12:40:46.426939  3513 sgd_solver.cpp:106] Iteration 27720, lr = 0.01
I0317 12:40:53.739006  3513 solver.cpp:228] Iteration 27740, loss = 0.00859596
I0317 12:40:53.739068  3513 solver.cpp:244]     Train net output #0: loss = 0.008596 (* 1 = 0.008596 loss)
I0317 12:40:53.739081  3513 sgd_solver.cpp:106] Iteration 27740, lr = 0.01
I0317 12:40:57.028324  3513 solver.cpp:337] Iteration 27750, Testing net (#0)
I0317 12:42:50.888576  3513 solver.cpp:404]     Test net output #0: loss = 0.0628435 (* 1 = 0.0628435 loss)
I0317 12:42:50.888659  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64428 (* 1 = 0.64428 loss)
I0317 12:42:54.840355  3513 solver.cpp:228] Iteration 27760, loss = 0.00327728
I0317 12:42:54.840421  3513 solver.cpp:244]     Train net output #0: loss = 0.00327731 (* 1 = 0.00327731 loss)
I0317 12:42:54.840435  3513 sgd_solver.cpp:106] Iteration 27760, lr = 0.01
I0317 12:43:02.099257  3513 solver.cpp:228] Iteration 27780, loss = 0.00591469
I0317 12:43:02.099330  3513 solver.cpp:244]     Train net output #0: loss = 0.00591472 (* 1 = 0.00591472 loss)
I0317 12:43:02.099346  3513 sgd_solver.cpp:106] Iteration 27780, lr = 0.01
I0317 12:43:09.406996  3513 solver.cpp:228] Iteration 27800, loss = 0.00362788
I0317 12:43:09.407059  3513 solver.cpp:244]     Train net output #0: loss = 0.00362791 (* 1 = 0.00362791 loss)
I0317 12:43:09.407073  3513 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0317 12:43:16.734680  3513 solver.cpp:228] Iteration 27820, loss = 0.00604646
I0317 12:43:16.734750  3513 solver.cpp:244]     Train net output #0: loss = 0.00604649 (* 1 = 0.00604649 loss)
I0317 12:43:16.734763  3513 sgd_solver.cpp:106] Iteration 27820, lr = 0.01
I0317 12:43:24.061192  3513 solver.cpp:228] Iteration 27840, loss = 0.00247196
I0317 12:43:24.061342  3513 solver.cpp:244]     Train net output #0: loss = 0.00247199 (* 1 = 0.00247199 loss)
I0317 12:43:24.061355  3513 sgd_solver.cpp:106] Iteration 27840, lr = 0.01
I0317 12:43:31.394583  3513 solver.cpp:228] Iteration 27860, loss = 0.00175748
I0317 12:43:31.394645  3513 solver.cpp:244]     Train net output #0: loss = 0.00175752 (* 1 = 0.00175752 loss)
I0317 12:43:31.394659  3513 sgd_solver.cpp:106] Iteration 27860, lr = 0.01
I0317 12:43:38.725258  3513 solver.cpp:228] Iteration 27880, loss = 0.00551109
I0317 12:43:38.725322  3513 solver.cpp:244]     Train net output #0: loss = 0.00551113 (* 1 = 0.00551113 loss)
I0317 12:43:38.725334  3513 sgd_solver.cpp:106] Iteration 27880, lr = 0.01
I0317 12:43:46.059648  3513 solver.cpp:228] Iteration 27900, loss = 0.00490535
I0317 12:43:46.059715  3513 solver.cpp:244]     Train net output #0: loss = 0.00490539 (* 1 = 0.00490539 loss)
I0317 12:43:46.059728  3513 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0317 12:43:53.379822  3513 solver.cpp:228] Iteration 27920, loss = 0.00539699
I0317 12:43:53.379885  3513 solver.cpp:244]     Train net output #0: loss = 0.00539702 (* 1 = 0.00539702 loss)
I0317 12:43:53.379899  3513 sgd_solver.cpp:106] Iteration 27920, lr = 0.01
I0317 12:44:00.704977  3513 solver.cpp:228] Iteration 27940, loss = 0.00479264
I0317 12:44:00.705195  3513 solver.cpp:244]     Train net output #0: loss = 0.00479268 (* 1 = 0.00479268 loss)
I0317 12:44:00.705210  3513 sgd_solver.cpp:106] Iteration 27940, lr = 0.01
I0317 12:44:08.030797  3513 solver.cpp:228] Iteration 27960, loss = 0.00566372
I0317 12:44:08.030876  3513 solver.cpp:244]     Train net output #0: loss = 0.00566375 (* 1 = 0.00566375 loss)
I0317 12:44:08.030891  3513 sgd_solver.cpp:106] Iteration 27960, lr = 0.01
I0317 12:44:15.359642  3513 solver.cpp:228] Iteration 27980, loss = 0.00776174
I0317 12:44:15.359709  3513 solver.cpp:244]     Train net output #0: loss = 0.00776177 (* 1 = 0.00776177 loss)
I0317 12:44:15.359722  3513 sgd_solver.cpp:106] Iteration 27980, lr = 0.01
I0317 12:44:22.329339  3513 solver.cpp:337] Iteration 28000, Testing net (#0)
I0317 12:46:16.177842  3513 solver.cpp:404]     Test net output #0: loss = 0.0621785 (* 1 = 0.0621785 loss)
I0317 12:46:16.177979  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 12:46:16.513705  3513 solver.cpp:228] Iteration 28000, loss = 0.0043318
I0317 12:46:16.513779  3513 solver.cpp:244]     Train net output #0: loss = 0.00433184 (* 1 = 0.00433184 loss)
I0317 12:46:16.513793  3513 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0317 12:46:23.753427  3513 solver.cpp:228] Iteration 28020, loss = 0.00254973
I0317 12:46:23.753499  3513 solver.cpp:244]     Train net output #0: loss = 0.00254976 (* 1 = 0.00254976 loss)
I0317 12:46:23.753514  3513 sgd_solver.cpp:106] Iteration 28020, lr = 0.01
I0317 12:46:31.035145  3513 solver.cpp:228] Iteration 28040, loss = 0.00274527
I0317 12:46:31.035221  3513 solver.cpp:244]     Train net output #0: loss = 0.0027453 (* 1 = 0.0027453 loss)
I0317 12:46:31.035233  3513 sgd_solver.cpp:106] Iteration 28040, lr = 0.01
I0317 12:46:38.342474  3513 solver.cpp:228] Iteration 28060, loss = 0.00490679
I0317 12:46:38.342546  3513 solver.cpp:244]     Train net output #0: loss = 0.00490682 (* 1 = 0.00490682 loss)
I0317 12:46:38.342561  3513 sgd_solver.cpp:106] Iteration 28060, lr = 0.01
I0317 12:46:45.659850  3513 solver.cpp:228] Iteration 28080, loss = 0.00269177
I0317 12:46:45.659919  3513 solver.cpp:244]     Train net output #0: loss = 0.0026918 (* 1 = 0.0026918 loss)
I0317 12:46:45.659932  3513 sgd_solver.cpp:106] Iteration 28080, lr = 0.01
I0317 12:46:52.983582  3513 solver.cpp:228] Iteration 28100, loss = 0.00514169
I0317 12:46:52.983733  3513 solver.cpp:244]     Train net output #0: loss = 0.00514173 (* 1 = 0.00514173 loss)
I0317 12:46:52.983748  3513 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0317 12:47:00.312315  3513 solver.cpp:228] Iteration 28120, loss = 0.00358624
I0317 12:47:00.312381  3513 solver.cpp:244]     Train net output #0: loss = 0.00358628 (* 1 = 0.00358628 loss)
I0317 12:47:00.312394  3513 sgd_solver.cpp:106] Iteration 28120, lr = 0.01
I0317 12:47:07.641070  3513 solver.cpp:228] Iteration 28140, loss = 0.00431195
I0317 12:47:07.641137  3513 solver.cpp:244]     Train net output #0: loss = 0.00431199 (* 1 = 0.00431199 loss)
I0317 12:47:07.641150  3513 sgd_solver.cpp:106] Iteration 28140, lr = 0.01
I0317 12:47:14.964841  3513 solver.cpp:228] Iteration 28160, loss = 0.00718629
I0317 12:47:14.964907  3513 solver.cpp:244]     Train net output #0: loss = 0.00718632 (* 1 = 0.00718632 loss)
I0317 12:47:14.964920  3513 sgd_solver.cpp:106] Iteration 28160, lr = 0.01
I0317 12:47:22.294018  3513 solver.cpp:228] Iteration 28180, loss = 0.00431461
I0317 12:47:22.294085  3513 solver.cpp:244]     Train net output #0: loss = 0.00431465 (* 1 = 0.00431465 loss)
I0317 12:47:22.294098  3513 sgd_solver.cpp:106] Iteration 28180, lr = 0.01
I0317 12:47:29.618110  3513 solver.cpp:228] Iteration 28200, loss = 0.00337349
I0317 12:47:29.618325  3513 solver.cpp:244]     Train net output #0: loss = 0.00337352 (* 1 = 0.00337352 loss)
I0317 12:47:29.618340  3513 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0317 12:47:36.943352  3513 solver.cpp:228] Iteration 28220, loss = 0.003033
I0317 12:47:36.943419  3513 solver.cpp:244]     Train net output #0: loss = 0.00303303 (* 1 = 0.00303303 loss)
I0317 12:47:36.943434  3513 sgd_solver.cpp:106] Iteration 28220, lr = 0.01
I0317 12:47:44.260951  3513 solver.cpp:228] Iteration 28240, loss = 0.00275708
I0317 12:47:44.261018  3513 solver.cpp:244]     Train net output #0: loss = 0.00275711 (* 1 = 0.00275711 loss)
I0317 12:47:44.261031  3513 sgd_solver.cpp:106] Iteration 28240, lr = 0.01
I0317 12:47:47.557518  3513 solver.cpp:337] Iteration 28250, Testing net (#0)
I0317 12:49:41.378322  3513 solver.cpp:404]     Test net output #0: loss = 0.0610827 (* 1 = 0.0610827 loss)
I0317 12:49:41.378460  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.63448 (* 1 = 0.63448 loss)
I0317 12:49:45.326222  3513 solver.cpp:228] Iteration 28260, loss = 0.0078336
I0317 12:49:45.326289  3513 solver.cpp:244]     Train net output #0: loss = 0.00783363 (* 1 = 0.00783363 loss)
I0317 12:49:45.326303  3513 sgd_solver.cpp:106] Iteration 28260, lr = 0.01
I0317 12:49:52.622123  3513 solver.cpp:228] Iteration 28280, loss = 0.00547099
I0317 12:49:52.622189  3513 solver.cpp:244]     Train net output #0: loss = 0.00547103 (* 1 = 0.00547103 loss)
I0317 12:49:52.622202  3513 sgd_solver.cpp:106] Iteration 28280, lr = 0.01
I0317 12:49:59.930974  3513 solver.cpp:228] Iteration 28300, loss = 0.0027534
I0317 12:49:59.931043  3513 solver.cpp:244]     Train net output #0: loss = 0.00275343 (* 1 = 0.00275343 loss)
I0317 12:49:59.931056  3513 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0317 12:50:07.249135  3513 solver.cpp:228] Iteration 28320, loss = 0.00706238
I0317 12:50:07.249214  3513 solver.cpp:244]     Train net output #0: loss = 0.00706241 (* 1 = 0.00706241 loss)
I0317 12:50:07.249228  3513 sgd_solver.cpp:106] Iteration 28320, lr = 0.01
I0317 12:50:14.579423  3513 solver.cpp:228] Iteration 28340, loss = 0.00409296
I0317 12:50:14.579591  3513 solver.cpp:244]     Train net output #0: loss = 0.004093 (* 1 = 0.004093 loss)
I0317 12:50:14.579605  3513 sgd_solver.cpp:106] Iteration 28340, lr = 0.01
I0317 12:50:21.904966  3513 solver.cpp:228] Iteration 28360, loss = 0.00525867
I0317 12:50:21.905035  3513 solver.cpp:244]     Train net output #0: loss = 0.0052587 (* 1 = 0.0052587 loss)
I0317 12:50:21.905047  3513 sgd_solver.cpp:106] Iteration 28360, lr = 0.01
I0317 12:50:29.228441  3513 solver.cpp:228] Iteration 28380, loss = 0.00507533
I0317 12:50:29.228502  3513 solver.cpp:244]     Train net output #0: loss = 0.00507536 (* 1 = 0.00507536 loss)
I0317 12:50:29.228514  3513 sgd_solver.cpp:106] Iteration 28380, lr = 0.01
I0317 12:50:36.550178  3513 solver.cpp:228] Iteration 28400, loss = 0.00350507
I0317 12:50:36.550246  3513 solver.cpp:244]     Train net output #0: loss = 0.00350511 (* 1 = 0.00350511 loss)
I0317 12:50:36.550258  3513 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0317 12:50:43.859448  3513 solver.cpp:228] Iteration 28420, loss = 0.00363989
I0317 12:50:43.859510  3513 solver.cpp:244]     Train net output #0: loss = 0.00363992 (* 1 = 0.00363992 loss)
I0317 12:50:43.859524  3513 sgd_solver.cpp:106] Iteration 28420, lr = 0.01
I0317 12:50:51.178766  3513 solver.cpp:228] Iteration 28440, loss = 0.00415936
I0317 12:50:51.178922  3513 solver.cpp:244]     Train net output #0: loss = 0.00415939 (* 1 = 0.00415939 loss)
I0317 12:50:51.178936  3513 sgd_solver.cpp:106] Iteration 28440, lr = 0.01
I0317 12:50:58.498703  3513 solver.cpp:228] Iteration 28460, loss = 0.00773936
I0317 12:50:58.498772  3513 solver.cpp:244]     Train net output #0: loss = 0.00773939 (* 1 = 0.00773939 loss)
I0317 12:50:58.498791  3513 sgd_solver.cpp:106] Iteration 28460, lr = 0.01
I0317 12:51:05.827870  3513 solver.cpp:228] Iteration 28480, loss = 0.00410766
I0317 12:51:05.827939  3513 solver.cpp:244]     Train net output #0: loss = 0.00410769 (* 1 = 0.00410769 loss)
I0317 12:51:05.827952  3513 sgd_solver.cpp:106] Iteration 28480, lr = 0.01
I0317 12:51:12.785907  3513 solver.cpp:337] Iteration 28500, Testing net (#0)
I0317 12:53:06.637490  3513 solver.cpp:404]     Test net output #0: loss = 0.0555731 (* 1 = 0.0555731 loss)
I0317 12:53:06.637670  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.62512 (* 1 = 0.62512 loss)
I0317 12:53:06.974867  3513 solver.cpp:228] Iteration 28500, loss = 0.00572398
I0317 12:53:06.974932  3513 solver.cpp:244]     Train net output #0: loss = 0.00572401 (* 1 = 0.00572401 loss)
I0317 12:53:06.974946  3513 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0317 12:53:14.236202  3513 solver.cpp:228] Iteration 28520, loss = 0.00867293
I0317 12:53:14.236282  3513 solver.cpp:244]     Train net output #0: loss = 0.00867296 (* 1 = 0.00867296 loss)
I0317 12:53:14.236297  3513 sgd_solver.cpp:106] Iteration 28520, lr = 0.01
I0317 12:53:21.550632  3513 solver.cpp:228] Iteration 28540, loss = 0.00605404
I0317 12:53:21.550699  3513 solver.cpp:244]     Train net output #0: loss = 0.00605407 (* 1 = 0.00605407 loss)
I0317 12:53:21.550714  3513 sgd_solver.cpp:106] Iteration 28540, lr = 0.01
I0317 12:53:28.871232  3513 solver.cpp:228] Iteration 28560, loss = 0.00262535
I0317 12:53:28.871302  3513 solver.cpp:244]     Train net output #0: loss = 0.00262539 (* 1 = 0.00262539 loss)
I0317 12:53:28.871316  3513 sgd_solver.cpp:106] Iteration 28560, lr = 0.01
I0317 12:53:36.198716  3513 solver.cpp:228] Iteration 28580, loss = 0.00179822
I0317 12:53:36.198784  3513 solver.cpp:244]     Train net output #0: loss = 0.00179825 (* 1 = 0.00179825 loss)
I0317 12:53:36.198797  3513 sgd_solver.cpp:106] Iteration 28580, lr = 0.01
I0317 12:53:43.533313  3513 solver.cpp:228] Iteration 28600, loss = 0.0034835
I0317 12:53:43.533520  3513 solver.cpp:244]     Train net output #0: loss = 0.00348354 (* 1 = 0.00348354 loss)
I0317 12:53:43.533535  3513 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0317 12:53:50.856884  3513 solver.cpp:228] Iteration 28620, loss = 0.00259217
I0317 12:53:50.856951  3513 solver.cpp:244]     Train net output #0: loss = 0.0025922 (* 1 = 0.0025922 loss)
I0317 12:53:50.856964  3513 sgd_solver.cpp:106] Iteration 28620, lr = 0.01
I0317 12:53:58.180171  3513 solver.cpp:228] Iteration 28640, loss = 0.00366878
I0317 12:53:58.180234  3513 solver.cpp:244]     Train net output #0: loss = 0.00366881 (* 1 = 0.00366881 loss)
I0317 12:53:58.180248  3513 sgd_solver.cpp:106] Iteration 28640, lr = 0.01
I0317 12:54:05.499433  3513 solver.cpp:228] Iteration 28660, loss = 0.00515445
I0317 12:54:05.499511  3513 solver.cpp:244]     Train net output #0: loss = 0.00515448 (* 1 = 0.00515448 loss)
I0317 12:54:05.499522  3513 sgd_solver.cpp:106] Iteration 28660, lr = 0.01
I0317 12:54:12.826645  3513 solver.cpp:228] Iteration 28680, loss = 0.00591055
I0317 12:54:12.826710  3513 solver.cpp:244]     Train net output #0: loss = 0.00591058 (* 1 = 0.00591058 loss)
I0317 12:54:12.826723  3513 sgd_solver.cpp:106] Iteration 28680, lr = 0.01
I0317 12:54:20.154942  3513 solver.cpp:228] Iteration 28700, loss = 0.00465691
I0317 12:54:20.155102  3513 solver.cpp:244]     Train net output #0: loss = 0.00465694 (* 1 = 0.00465694 loss)
I0317 12:54:20.155122  3513 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0317 12:54:27.481060  3513 solver.cpp:228] Iteration 28720, loss = 0.00478706
I0317 12:54:27.481122  3513 solver.cpp:244]     Train net output #0: loss = 0.0047871 (* 1 = 0.0047871 loss)
I0317 12:54:27.481135  3513 sgd_solver.cpp:106] Iteration 28720, lr = 0.01
I0317 12:54:34.795892  3513 solver.cpp:228] Iteration 28740, loss = 0.00477951
I0317 12:54:34.795958  3513 solver.cpp:244]     Train net output #0: loss = 0.00477955 (* 1 = 0.00477955 loss)
I0317 12:54:34.795971  3513 sgd_solver.cpp:106] Iteration 28740, lr = 0.01
I0317 12:54:38.088891  3513 solver.cpp:337] Iteration 28750, Testing net (#0)
I0317 12:56:31.932970  3513 solver.cpp:404]     Test net output #0: loss = 0.0570734 (* 1 = 0.0570734 loss)
I0317 12:56:31.933164  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6538 (* 1 = 0.6538 loss)
I0317 12:56:35.874606  3513 solver.cpp:228] Iteration 28760, loss = 0.00274504
I0317 12:56:35.874677  3513 solver.cpp:244]     Train net output #0: loss = 0.00274508 (* 1 = 0.00274508 loss)
I0317 12:56:35.874691  3513 sgd_solver.cpp:106] Iteration 28760, lr = 0.01
I0317 12:56:43.140810  3513 solver.cpp:228] Iteration 28780, loss = 0.0036398
I0317 12:56:43.140878  3513 solver.cpp:244]     Train net output #0: loss = 0.00363983 (* 1 = 0.00363983 loss)
I0317 12:56:43.140892  3513 sgd_solver.cpp:106] Iteration 28780, lr = 0.01
I0317 12:56:50.444628  3513 solver.cpp:228] Iteration 28800, loss = 0.00217125
I0317 12:56:50.444701  3513 solver.cpp:244]     Train net output #0: loss = 0.00217129 (* 1 = 0.00217129 loss)
I0317 12:56:50.444715  3513 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0317 12:56:57.767935  3513 solver.cpp:228] Iteration 28820, loss = 0.00504234
I0317 12:56:57.767999  3513 solver.cpp:244]     Train net output #0: loss = 0.00504237 (* 1 = 0.00504237 loss)
I0317 12:56:57.768013  3513 sgd_solver.cpp:106] Iteration 28820, lr = 0.01
I0317 12:57:05.095078  3513 solver.cpp:228] Iteration 28840, loss = 0.00442043
I0317 12:57:05.095228  3513 solver.cpp:244]     Train net output #0: loss = 0.00442047 (* 1 = 0.00442047 loss)
I0317 12:57:05.095242  3513 sgd_solver.cpp:106] Iteration 28840, lr = 0.01
I0317 12:57:12.417399  3513 solver.cpp:228] Iteration 28860, loss = 0.00542603
I0317 12:57:12.417462  3513 solver.cpp:244]     Train net output #0: loss = 0.00542607 (* 1 = 0.00542607 loss)
I0317 12:57:12.417475  3513 sgd_solver.cpp:106] Iteration 28860, lr = 0.01
I0317 12:57:19.755568  3513 solver.cpp:228] Iteration 28880, loss = 0.00390327
I0317 12:57:19.755637  3513 solver.cpp:244]     Train net output #0: loss = 0.00390331 (* 1 = 0.00390331 loss)
I0317 12:57:19.755650  3513 sgd_solver.cpp:106] Iteration 28880, lr = 0.01
I0317 12:57:27.092382  3513 solver.cpp:228] Iteration 28900, loss = 0.0045775
I0317 12:57:27.092448  3513 solver.cpp:244]     Train net output #0: loss = 0.00457753 (* 1 = 0.00457753 loss)
I0317 12:57:27.092461  3513 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0317 12:57:34.421908  3513 solver.cpp:228] Iteration 28920, loss = 0.00449868
I0317 12:57:34.421984  3513 solver.cpp:244]     Train net output #0: loss = 0.00449872 (* 1 = 0.00449872 loss)
I0317 12:57:34.421998  3513 sgd_solver.cpp:106] Iteration 28920, lr = 0.01
I0317 12:57:41.746634  3513 solver.cpp:228] Iteration 28940, loss = 0.00164705
I0317 12:57:41.746788  3513 solver.cpp:244]     Train net output #0: loss = 0.00164708 (* 1 = 0.00164708 loss)
I0317 12:57:41.746803  3513 sgd_solver.cpp:106] Iteration 28940, lr = 0.01
I0317 12:57:49.064595  3513 solver.cpp:228] Iteration 28960, loss = 0.00345388
I0317 12:57:49.064662  3513 solver.cpp:244]     Train net output #0: loss = 0.00345391 (* 1 = 0.00345391 loss)
I0317 12:57:49.064677  3513 sgd_solver.cpp:106] Iteration 28960, lr = 0.01
I0317 12:57:56.387539  3513 solver.cpp:228] Iteration 28980, loss = 0.00166218
I0317 12:57:56.387616  3513 solver.cpp:244]     Train net output #0: loss = 0.00166221 (* 1 = 0.00166221 loss)
I0317 12:57:56.387629  3513 sgd_solver.cpp:106] Iteration 28980, lr = 0.01
I0317 12:58:03.343794  3513 solver.cpp:337] Iteration 29000, Testing net (#0)
I0317 12:59:57.213785  3513 solver.cpp:404]     Test net output #0: loss = 0.0577384 (* 1 = 0.0577384 loss)
I0317 12:59:57.213909  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 12:59:57.550395  3513 solver.cpp:228] Iteration 29000, loss = 0.00672757
I0317 12:59:57.550462  3513 solver.cpp:244]     Train net output #0: loss = 0.0067276 (* 1 = 0.0067276 loss)
I0317 12:59:57.550474  3513 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0317 13:00:04.770437  3513 solver.cpp:228] Iteration 29020, loss = 0.00339281
I0317 13:00:04.770514  3513 solver.cpp:244]     Train net output #0: loss = 0.00339285 (* 1 = 0.00339285 loss)
I0317 13:00:04.770527  3513 sgd_solver.cpp:106] Iteration 29020, lr = 0.01
I0317 13:00:12.042701  3513 solver.cpp:228] Iteration 29040, loss = 0.00660562
I0317 13:00:12.042768  3513 solver.cpp:244]     Train net output #0: loss = 0.00660566 (* 1 = 0.00660566 loss)
I0317 13:00:12.042781  3513 sgd_solver.cpp:106] Iteration 29040, lr = 0.01
I0317 13:00:19.344892  3513 solver.cpp:228] Iteration 29060, loss = 0.00446059
I0317 13:00:19.344960  3513 solver.cpp:244]     Train net output #0: loss = 0.00446062 (* 1 = 0.00446062 loss)
I0317 13:00:19.344974  3513 sgd_solver.cpp:106] Iteration 29060, lr = 0.01
I0317 13:00:26.661484  3513 solver.cpp:228] Iteration 29080, loss = 0.00474658
I0317 13:00:26.661551  3513 solver.cpp:244]     Train net output #0: loss = 0.00474661 (* 1 = 0.00474661 loss)
I0317 13:00:26.661566  3513 sgd_solver.cpp:106] Iteration 29080, lr = 0.01
I0317 13:00:33.986656  3513 solver.cpp:228] Iteration 29100, loss = 0.00173153
I0317 13:00:33.986867  3513 solver.cpp:244]     Train net output #0: loss = 0.00173156 (* 1 = 0.00173156 loss)
I0317 13:00:33.986881  3513 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0317 13:00:41.323099  3513 solver.cpp:228] Iteration 29120, loss = 0.00301563
I0317 13:00:41.323166  3513 solver.cpp:244]     Train net output #0: loss = 0.00301567 (* 1 = 0.00301567 loss)
I0317 13:00:41.323179  3513 sgd_solver.cpp:106] Iteration 29120, lr = 0.01
I0317 13:00:48.657272  3513 solver.cpp:228] Iteration 29140, loss = 0.00253056
I0317 13:00:48.657341  3513 solver.cpp:244]     Train net output #0: loss = 0.00253059 (* 1 = 0.00253059 loss)
I0317 13:00:48.657353  3513 sgd_solver.cpp:106] Iteration 29140, lr = 0.01
I0317 13:00:55.995132  3513 solver.cpp:228] Iteration 29160, loss = 0.0028428
I0317 13:00:55.995203  3513 solver.cpp:244]     Train net output #0: loss = 0.00284284 (* 1 = 0.00284284 loss)
I0317 13:00:55.995215  3513 sgd_solver.cpp:106] Iteration 29160, lr = 0.01
I0317 13:01:03.330708  3513 solver.cpp:228] Iteration 29180, loss = 0.00351824
I0317 13:01:03.330780  3513 solver.cpp:244]     Train net output #0: loss = 0.00351827 (* 1 = 0.00351827 loss)
I0317 13:01:03.330792  3513 sgd_solver.cpp:106] Iteration 29180, lr = 0.01
I0317 13:01:10.659601  3513 solver.cpp:228] Iteration 29200, loss = 0.00458638
I0317 13:01:10.659749  3513 solver.cpp:244]     Train net output #0: loss = 0.00458641 (* 1 = 0.00458641 loss)
I0317 13:01:10.659764  3513 sgd_solver.cpp:106] Iteration 29200, lr = 0.01
I0317 13:01:17.998482  3513 solver.cpp:228] Iteration 29220, loss = 0.00481714
I0317 13:01:17.998545  3513 solver.cpp:244]     Train net output #0: loss = 0.00481717 (* 1 = 0.00481717 loss)
I0317 13:01:17.998558  3513 sgd_solver.cpp:106] Iteration 29220, lr = 0.01
I0317 13:01:25.333258  3513 solver.cpp:228] Iteration 29240, loss = 0.00676939
I0317 13:01:25.333325  3513 solver.cpp:244]     Train net output #0: loss = 0.00676942 (* 1 = 0.00676942 loss)
I0317 13:01:25.333338  3513 sgd_solver.cpp:106] Iteration 29240, lr = 0.01
I0317 13:01:28.631306  3513 solver.cpp:337] Iteration 29250, Testing net (#0)
I0317 13:03:22.499085  3513 solver.cpp:404]     Test net output #0: loss = 0.0621633 (* 1 = 0.0621633 loss)
I0317 13:03:22.499199  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66356 (* 1 = 0.66356 loss)
I0317 13:03:26.452921  3513 solver.cpp:228] Iteration 29260, loss = 0.00654108
I0317 13:03:26.452996  3513 solver.cpp:244]     Train net output #0: loss = 0.00654111 (* 1 = 0.00654111 loss)
I0317 13:03:26.453009  3513 sgd_solver.cpp:106] Iteration 29260, lr = 0.01
I0317 13:03:33.736438  3513 solver.cpp:228] Iteration 29280, loss = 0.00282988
I0317 13:03:33.736507  3513 solver.cpp:244]     Train net output #0: loss = 0.00282992 (* 1 = 0.00282992 loss)
I0317 13:03:33.736521  3513 sgd_solver.cpp:106] Iteration 29280, lr = 0.01
I0317 13:03:41.047979  3513 solver.cpp:228] Iteration 29300, loss = 0.00160776
I0317 13:03:41.048046  3513 solver.cpp:244]     Train net output #0: loss = 0.0016078 (* 1 = 0.0016078 loss)
I0317 13:03:41.048059  3513 sgd_solver.cpp:106] Iteration 29300, lr = 0.01
I0317 13:03:48.370321  3513 solver.cpp:228] Iteration 29320, loss = 0.00354254
I0317 13:03:48.370385  3513 solver.cpp:244]     Train net output #0: loss = 0.00354258 (* 1 = 0.00354258 loss)
I0317 13:03:48.370398  3513 sgd_solver.cpp:106] Iteration 29320, lr = 0.01
I0317 13:03:55.702289  3513 solver.cpp:228] Iteration 29340, loss = 0.00211493
I0317 13:03:55.702481  3513 solver.cpp:244]     Train net output #0: loss = 0.00211496 (* 1 = 0.00211496 loss)
I0317 13:03:55.702496  3513 sgd_solver.cpp:106] Iteration 29340, lr = 0.01
I0317 13:04:03.041740  3513 solver.cpp:228] Iteration 29360, loss = 0.0038656
I0317 13:04:03.041808  3513 solver.cpp:244]     Train net output #0: loss = 0.00386564 (* 1 = 0.00386564 loss)
I0317 13:04:03.041821  3513 sgd_solver.cpp:106] Iteration 29360, lr = 0.01
I0317 13:04:10.376410  3513 solver.cpp:228] Iteration 29380, loss = 0.00296948
I0317 13:04:10.376478  3513 solver.cpp:244]     Train net output #0: loss = 0.00296952 (* 1 = 0.00296952 loss)
I0317 13:04:10.376492  3513 sgd_solver.cpp:106] Iteration 29380, lr = 0.01
I0317 13:04:17.712366  3513 solver.cpp:228] Iteration 29400, loss = 0.00490974
I0317 13:04:17.712441  3513 solver.cpp:244]     Train net output #0: loss = 0.00490978 (* 1 = 0.00490978 loss)
I0317 13:04:17.712458  3513 sgd_solver.cpp:106] Iteration 29400, lr = 0.01
I0317 13:04:25.044697  3513 solver.cpp:228] Iteration 29420, loss = 0.00316596
I0317 13:04:25.044764  3513 solver.cpp:244]     Train net output #0: loss = 0.00316599 (* 1 = 0.00316599 loss)
I0317 13:04:25.044776  3513 sgd_solver.cpp:106] Iteration 29420, lr = 0.01
I0317 13:04:32.376322  3513 solver.cpp:228] Iteration 29440, loss = 0.00368184
I0317 13:04:32.376476  3513 solver.cpp:244]     Train net output #0: loss = 0.00368187 (* 1 = 0.00368187 loss)
I0317 13:04:32.376490  3513 sgd_solver.cpp:106] Iteration 29440, lr = 0.01
I0317 13:04:39.690089  3513 solver.cpp:228] Iteration 29460, loss = 0.00487271
I0317 13:04:39.690153  3513 solver.cpp:244]     Train net output #0: loss = 0.00487275 (* 1 = 0.00487275 loss)
I0317 13:04:39.690166  3513 sgd_solver.cpp:106] Iteration 29460, lr = 0.01
I0317 13:04:47.009213  3513 solver.cpp:228] Iteration 29480, loss = 0.00357978
I0317 13:04:47.009279  3513 solver.cpp:244]     Train net output #0: loss = 0.00357982 (* 1 = 0.00357982 loss)
I0317 13:04:47.009291  3513 sgd_solver.cpp:106] Iteration 29480, lr = 0.01
I0317 13:04:53.965595  3513 solver.cpp:337] Iteration 29500, Testing net (#0)
I0317 13:06:47.826459  3513 solver.cpp:404]     Test net output #0: loss = 0.0549819 (* 1 = 0.0549819 loss)
I0317 13:06:47.826581  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.596079 (* 1 = 0.596079 loss)
I0317 13:06:48.162492  3513 solver.cpp:228] Iteration 29500, loss = 0.00386588
I0317 13:06:48.162559  3513 solver.cpp:244]     Train net output #0: loss = 0.00386592 (* 1 = 0.00386592 loss)
I0317 13:06:48.162570  3513 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0317 13:06:55.401502  3513 solver.cpp:228] Iteration 29520, loss = 0.00337394
I0317 13:06:55.401571  3513 solver.cpp:244]     Train net output #0: loss = 0.00337397 (* 1 = 0.00337397 loss)
I0317 13:06:55.401583  3513 sgd_solver.cpp:106] Iteration 29520, lr = 0.01
I0317 13:07:02.689105  3513 solver.cpp:228] Iteration 29540, loss = 0.00684887
I0317 13:07:02.689184  3513 solver.cpp:244]     Train net output #0: loss = 0.00684891 (* 1 = 0.00684891 loss)
I0317 13:07:02.689199  3513 sgd_solver.cpp:106] Iteration 29540, lr = 0.01
I0317 13:07:09.995357  3513 solver.cpp:228] Iteration 29560, loss = 0.0026317
I0317 13:07:09.995431  3513 solver.cpp:244]     Train net output #0: loss = 0.00263173 (* 1 = 0.00263173 loss)
I0317 13:07:09.995445  3513 sgd_solver.cpp:106] Iteration 29560, lr = 0.01
I0317 13:07:17.320389  3513 solver.cpp:228] Iteration 29580, loss = 0.00706538
I0317 13:07:17.320457  3513 solver.cpp:244]     Train net output #0: loss = 0.00706542 (* 1 = 0.00706542 loss)
I0317 13:07:17.320471  3513 sgd_solver.cpp:106] Iteration 29580, lr = 0.01
I0317 13:07:24.646916  3513 solver.cpp:228] Iteration 29600, loss = 0.00671254
I0317 13:07:24.647104  3513 solver.cpp:244]     Train net output #0: loss = 0.00671257 (* 1 = 0.00671257 loss)
I0317 13:07:24.647119  3513 sgd_solver.cpp:106] Iteration 29600, lr = 0.01
I0317 13:07:31.969025  3513 solver.cpp:228] Iteration 29620, loss = 0.00319705
I0317 13:07:31.969089  3513 solver.cpp:244]     Train net output #0: loss = 0.00319709 (* 1 = 0.00319709 loss)
I0317 13:07:31.969101  3513 sgd_solver.cpp:106] Iteration 29620, lr = 0.01
I0317 13:07:39.294354  3513 solver.cpp:228] Iteration 29640, loss = 0.00321569
I0317 13:07:39.294419  3513 solver.cpp:244]     Train net output #0: loss = 0.00321573 (* 1 = 0.00321573 loss)
I0317 13:07:39.294431  3513 sgd_solver.cpp:106] Iteration 29640, lr = 0.01
I0317 13:07:46.634385  3513 solver.cpp:228] Iteration 29660, loss = 0.00281822
I0317 13:07:46.634454  3513 solver.cpp:244]     Train net output #0: loss = 0.00281826 (* 1 = 0.00281826 loss)
I0317 13:07:46.634467  3513 sgd_solver.cpp:106] Iteration 29660, lr = 0.01
I0317 13:07:53.960487  3513 solver.cpp:228] Iteration 29680, loss = 0.00361229
I0317 13:07:53.960556  3513 solver.cpp:244]     Train net output #0: loss = 0.00361233 (* 1 = 0.00361233 loss)
I0317 13:07:53.960571  3513 sgd_solver.cpp:106] Iteration 29680, lr = 0.01
I0317 13:08:01.292253  3513 solver.cpp:228] Iteration 29700, loss = 0.00319252
I0317 13:08:01.292407  3513 solver.cpp:244]     Train net output #0: loss = 0.00319256 (* 1 = 0.00319256 loss)
I0317 13:08:01.292421  3513 sgd_solver.cpp:106] Iteration 29700, lr = 0.01
I0317 13:08:08.609400  3513 solver.cpp:228] Iteration 29720, loss = 0.00544847
I0317 13:08:08.609468  3513 solver.cpp:244]     Train net output #0: loss = 0.00544851 (* 1 = 0.00544851 loss)
I0317 13:08:08.609482  3513 sgd_solver.cpp:106] Iteration 29720, lr = 0.01
I0317 13:08:15.935827  3513 solver.cpp:228] Iteration 29740, loss = 0.00435085
I0317 13:08:15.935892  3513 solver.cpp:244]     Train net output #0: loss = 0.00435089 (* 1 = 0.00435089 loss)
I0317 13:08:15.935905  3513 sgd_solver.cpp:106] Iteration 29740, lr = 0.01
I0317 13:08:19.231637  3513 solver.cpp:337] Iteration 29750, Testing net (#0)
I0317 13:10:13.086266  3513 solver.cpp:404]     Test net output #0: loss = 0.0632546 (* 1 = 0.0632546 loss)
I0317 13:10:13.086345  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6346 (* 1 = 0.6346 loss)
I0317 13:10:17.042037  3513 solver.cpp:228] Iteration 29760, loss = 0.00552962
I0317 13:10:17.042104  3513 solver.cpp:244]     Train net output #0: loss = 0.00552966 (* 1 = 0.00552966 loss)
I0317 13:10:17.042117  3513 sgd_solver.cpp:106] Iteration 29760, lr = 0.01
I0317 13:10:24.322343  3513 solver.cpp:228] Iteration 29780, loss = 0.00482198
I0317 13:10:24.322413  3513 solver.cpp:244]     Train net output #0: loss = 0.00482201 (* 1 = 0.00482201 loss)
I0317 13:10:24.322427  3513 sgd_solver.cpp:106] Iteration 29780, lr = 0.01
I0317 13:10:31.626055  3513 solver.cpp:228] Iteration 29800, loss = 0.00484651
I0317 13:10:31.626118  3513 solver.cpp:244]     Train net output #0: loss = 0.00484655 (* 1 = 0.00484655 loss)
I0317 13:10:31.626134  3513 sgd_solver.cpp:106] Iteration 29800, lr = 0.01
I0317 13:10:38.946049  3513 solver.cpp:228] Iteration 29820, loss = 0.00521935
I0317 13:10:38.946112  3513 solver.cpp:244]     Train net output #0: loss = 0.00521939 (* 1 = 0.00521939 loss)
I0317 13:10:38.946125  3513 sgd_solver.cpp:106] Iteration 29820, lr = 0.01
I0317 13:10:46.256521  3513 solver.cpp:228] Iteration 29840, loss = 0.00156705
I0317 13:10:46.256667  3513 solver.cpp:244]     Train net output #0: loss = 0.00156708 (* 1 = 0.00156708 loss)
I0317 13:10:46.256682  3513 sgd_solver.cpp:106] Iteration 29840, lr = 0.01
I0317 13:10:53.575414  3513 solver.cpp:228] Iteration 29860, loss = 0.00341872
I0317 13:10:53.575485  3513 solver.cpp:244]     Train net output #0: loss = 0.00341875 (* 1 = 0.00341875 loss)
I0317 13:10:53.575500  3513 sgd_solver.cpp:106] Iteration 29860, lr = 0.01
I0317 13:11:00.898592  3513 solver.cpp:228] Iteration 29880, loss = 0.00462142
I0317 13:11:00.898671  3513 solver.cpp:244]     Train net output #0: loss = 0.00462145 (* 1 = 0.00462145 loss)
I0317 13:11:00.898685  3513 sgd_solver.cpp:106] Iteration 29880, lr = 0.01
I0317 13:11:08.226959  3513 solver.cpp:228] Iteration 29900, loss = 0.00341176
I0317 13:11:08.227041  3513 solver.cpp:244]     Train net output #0: loss = 0.00341179 (* 1 = 0.00341179 loss)
I0317 13:11:08.227053  3513 sgd_solver.cpp:106] Iteration 29900, lr = 0.01
I0317 13:11:15.558295  3513 solver.cpp:228] Iteration 29920, loss = 0.00279483
I0317 13:11:15.558362  3513 solver.cpp:244]     Train net output #0: loss = 0.00279487 (* 1 = 0.00279487 loss)
I0317 13:11:15.558374  3513 sgd_solver.cpp:106] Iteration 29920, lr = 0.01
I0317 13:11:22.887915  3513 solver.cpp:228] Iteration 29940, loss = 0.00791989
I0317 13:11:22.888104  3513 solver.cpp:244]     Train net output #0: loss = 0.00791992 (* 1 = 0.00791992 loss)
I0317 13:11:22.888118  3513 sgd_solver.cpp:106] Iteration 29940, lr = 0.01
I0317 13:11:30.221384  3513 solver.cpp:228] Iteration 29960, loss = 0.00564846
I0317 13:11:30.221452  3513 solver.cpp:244]     Train net output #0: loss = 0.0056485 (* 1 = 0.0056485 loss)
I0317 13:11:30.221465  3513 sgd_solver.cpp:106] Iteration 29960, lr = 0.01
I0317 13:11:37.540165  3513 solver.cpp:228] Iteration 29980, loss = 0.0039803
I0317 13:11:37.540238  3513 solver.cpp:244]     Train net output #0: loss = 0.00398033 (* 1 = 0.00398033 loss)
I0317 13:11:37.540251  3513 sgd_solver.cpp:106] Iteration 29980, lr = 0.01
I0317 13:11:44.499199  3513 solver.cpp:454] Snapshotting to binary proto file ./caffe_alexnet_train_iter_30000.caffemodel
I0317 13:11:46.143004  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./caffe_alexnet_train_iter_30000.solverstate
I0317 13:11:46.552570  3513 solver.cpp:337] Iteration 30000, Testing net (#0)
I0317 13:13:40.364171  3513 solver.cpp:404]     Test net output #0: loss = 0.0592965 (* 1 = 0.0592965 loss)
I0317 13:13:40.364289  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65392 (* 1 = 0.65392 loss)
I0317 13:13:40.700078  3513 solver.cpp:228] Iteration 30000, loss = 0.0035252
I0317 13:13:40.700148  3513 solver.cpp:244]     Train net output #0: loss = 0.00352523 (* 1 = 0.00352523 loss)
I0317 13:13:40.700161  3513 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0317 13:13:47.940296  3513 solver.cpp:228] Iteration 30020, loss = 0.00132609
I0317 13:13:47.940364  3513 solver.cpp:244]     Train net output #0: loss = 0.00132613 (* 1 = 0.00132613 loss)
I0317 13:13:47.940377  3513 sgd_solver.cpp:106] Iteration 30020, lr = 0.01
I0317 13:13:55.228121  3513 solver.cpp:228] Iteration 30040, loss = 0.00382082
I0317 13:13:55.228190  3513 solver.cpp:244]     Train net output #0: loss = 0.00382086 (* 1 = 0.00382086 loss)
I0317 13:13:55.228204  3513 sgd_solver.cpp:106] Iteration 30040, lr = 0.01
I0317 13:14:02.533963  3513 solver.cpp:228] Iteration 30060, loss = 0.00318212
I0317 13:14:02.534035  3513 solver.cpp:244]     Train net output #0: loss = 0.00318215 (* 1 = 0.00318215 loss)
I0317 13:14:02.534049  3513 sgd_solver.cpp:106] Iteration 30060, lr = 0.01
I0317 13:14:09.854430  3513 solver.cpp:228] Iteration 30080, loss = 0.00572587
I0317 13:14:09.854493  3513 solver.cpp:244]     Train net output #0: loss = 0.0057259 (* 1 = 0.0057259 loss)
I0317 13:14:09.854514  3513 sgd_solver.cpp:106] Iteration 30080, lr = 0.01
I0317 13:14:17.189345  3513 solver.cpp:228] Iteration 30100, loss = 0.0043743
I0317 13:14:17.189491  3513 solver.cpp:244]     Train net output #0: loss = 0.00437434 (* 1 = 0.00437434 loss)
I0317 13:14:17.189514  3513 sgd_solver.cpp:106] Iteration 30100, lr = 0.01
I0317 13:14:24.514746  3513 solver.cpp:228] Iteration 30120, loss = 0.00609616
I0317 13:14:24.514817  3513 solver.cpp:244]     Train net output #0: loss = 0.00609619 (* 1 = 0.00609619 loss)
I0317 13:14:24.514832  3513 sgd_solver.cpp:106] Iteration 30120, lr = 0.01
I0317 13:14:31.839946  3513 solver.cpp:228] Iteration 30140, loss = 0.00374346
I0317 13:14:31.840014  3513 solver.cpp:244]     Train net output #0: loss = 0.0037435 (* 1 = 0.0037435 loss)
I0317 13:14:31.840028  3513 sgd_solver.cpp:106] Iteration 30140, lr = 0.01
I0317 13:14:39.166837  3513 solver.cpp:228] Iteration 30160, loss = 0.0064622
I0317 13:14:39.166899  3513 solver.cpp:244]     Train net output #0: loss = 0.00646224 (* 1 = 0.00646224 loss)
I0317 13:14:39.166913  3513 sgd_solver.cpp:106] Iteration 30160, lr = 0.01
I0317 13:14:46.490499  3513 solver.cpp:228] Iteration 30180, loss = 0.00221534
I0317 13:14:46.490567  3513 solver.cpp:244]     Train net output #0: loss = 0.00221537 (* 1 = 0.00221537 loss)
I0317 13:14:46.490581  3513 sgd_solver.cpp:106] Iteration 30180, lr = 0.01
I0317 13:14:53.814641  3513 solver.cpp:228] Iteration 30200, loss = 0.00252718
I0317 13:14:53.814813  3513 solver.cpp:244]     Train net output #0: loss = 0.00252722 (* 1 = 0.00252722 loss)
I0317 13:14:53.814826  3513 sgd_solver.cpp:106] Iteration 30200, lr = 0.01
I0317 13:15:01.145007  3513 solver.cpp:228] Iteration 30220, loss = 0.00375158
I0317 13:15:01.145076  3513 solver.cpp:244]     Train net output #0: loss = 0.00375161 (* 1 = 0.00375161 loss)
I0317 13:15:01.145088  3513 sgd_solver.cpp:106] Iteration 30220, lr = 0.01
I0317 13:15:08.473296  3513 solver.cpp:228] Iteration 30240, loss = 0.00430359
I0317 13:15:08.473366  3513 solver.cpp:244]     Train net output #0: loss = 0.00430362 (* 1 = 0.00430362 loss)
I0317 13:15:08.473379  3513 sgd_solver.cpp:106] Iteration 30240, lr = 0.01
I0317 13:15:11.768429  3513 solver.cpp:337] Iteration 30250, Testing net (#0)
I0317 13:17:05.616039  3513 solver.cpp:404]     Test net output #0: loss = 0.057182 (* 1 = 0.057182 loss)
I0317 13:17:05.616130  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 13:17:09.568357  3513 solver.cpp:228] Iteration 30260, loss = 0.00380702
I0317 13:17:09.568421  3513 solver.cpp:244]     Train net output #0: loss = 0.00380706 (* 1 = 0.00380706 loss)
I0317 13:17:09.568434  3513 sgd_solver.cpp:106] Iteration 30260, lr = 0.01
I0317 13:17:16.846906  3513 solver.cpp:228] Iteration 30280, loss = 0.00362871
I0317 13:17:16.846973  3513 solver.cpp:244]     Train net output #0: loss = 0.00362874 (* 1 = 0.00362874 loss)
I0317 13:17:16.846987  3513 sgd_solver.cpp:106] Iteration 30280, lr = 0.01
I0317 13:17:24.159981  3513 solver.cpp:228] Iteration 30300, loss = 0.00728222
I0317 13:17:24.160046  3513 solver.cpp:244]     Train net output #0: loss = 0.00728225 (* 1 = 0.00728225 loss)
I0317 13:17:24.160059  3513 sgd_solver.cpp:106] Iteration 30300, lr = 0.01
I0317 13:17:31.474088  3513 solver.cpp:228] Iteration 30320, loss = 0.00387025
I0317 13:17:31.474149  3513 solver.cpp:244]     Train net output #0: loss = 0.00387029 (* 1 = 0.00387029 loss)
I0317 13:17:31.474161  3513 sgd_solver.cpp:106] Iteration 30320, lr = 0.01
I0317 13:17:38.800163  3513 solver.cpp:228] Iteration 30340, loss = 0.00628036
I0317 13:17:38.800315  3513 solver.cpp:244]     Train net output #0: loss = 0.00628039 (* 1 = 0.00628039 loss)
I0317 13:17:38.800329  3513 sgd_solver.cpp:106] Iteration 30340, lr = 0.01
I0317 13:17:46.130836  3513 solver.cpp:228] Iteration 30360, loss = 0.00370247
I0317 13:17:46.130904  3513 solver.cpp:244]     Train net output #0: loss = 0.0037025 (* 1 = 0.0037025 loss)
I0317 13:17:46.130916  3513 sgd_solver.cpp:106] Iteration 30360, lr = 0.01
I0317 13:17:53.459411  3513 solver.cpp:228] Iteration 30380, loss = 0.00295426
I0317 13:17:53.459484  3513 solver.cpp:244]     Train net output #0: loss = 0.00295429 (* 1 = 0.00295429 loss)
I0317 13:17:53.459497  3513 sgd_solver.cpp:106] Iteration 30380, lr = 0.01
I0317 13:18:00.780987  3513 solver.cpp:228] Iteration 30400, loss = 0.00462796
I0317 13:18:00.781067  3513 solver.cpp:244]     Train net output #0: loss = 0.004628 (* 1 = 0.004628 loss)
I0317 13:18:00.781090  3513 sgd_solver.cpp:106] Iteration 30400, lr = 0.01
I0317 13:18:08.119194  3513 solver.cpp:228] Iteration 30420, loss = 0.0045534
I0317 13:18:08.119272  3513 solver.cpp:244]     Train net output #0: loss = 0.00455344 (* 1 = 0.00455344 loss)
I0317 13:18:08.119287  3513 sgd_solver.cpp:106] Iteration 30420, lr = 0.01
I0317 13:18:15.456188  3513 solver.cpp:228] Iteration 30440, loss = 0.00493265
I0317 13:18:15.456384  3513 solver.cpp:244]     Train net output #0: loss = 0.00493269 (* 1 = 0.00493269 loss)
I0317 13:18:15.456399  3513 sgd_solver.cpp:106] Iteration 30440, lr = 0.01
I0317 13:18:22.782708  3513 solver.cpp:228] Iteration 30460, loss = 0.00162875
I0317 13:18:22.782773  3513 solver.cpp:244]     Train net output #0: loss = 0.00162878 (* 1 = 0.00162878 loss)
I0317 13:18:22.782786  3513 sgd_solver.cpp:106] Iteration 30460, lr = 0.01
I0317 13:18:30.100006  3513 solver.cpp:228] Iteration 30480, loss = 0.00530162
I0317 13:18:30.100069  3513 solver.cpp:244]     Train net output #0: loss = 0.00530165 (* 1 = 0.00530165 loss)
I0317 13:18:30.100082  3513 sgd_solver.cpp:106] Iteration 30480, lr = 0.01
I0317 13:18:37.048010  3513 solver.cpp:337] Iteration 30500, Testing net (#0)
I0317 13:20:30.921062  3513 solver.cpp:404]     Test net output #0: loss = 0.058678 (* 1 = 0.058678 loss)
I0317 13:20:30.921197  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 13:20:31.256788  3513 solver.cpp:228] Iteration 30500, loss = 0.00411611
I0317 13:20:31.256852  3513 solver.cpp:244]     Train net output #0: loss = 0.00411615 (* 1 = 0.00411615 loss)
I0317 13:20:31.256866  3513 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0317 13:20:38.492589  3513 solver.cpp:228] Iteration 30520, loss = 0.00575648
I0317 13:20:38.492656  3513 solver.cpp:244]     Train net output #0: loss = 0.00575652 (* 1 = 0.00575652 loss)
I0317 13:20:38.492669  3513 sgd_solver.cpp:106] Iteration 30520, lr = 0.01
I0317 13:20:45.779786  3513 solver.cpp:228] Iteration 30540, loss = 0.00398917
I0317 13:20:45.779855  3513 solver.cpp:244]     Train net output #0: loss = 0.00398921 (* 1 = 0.00398921 loss)
I0317 13:20:45.779866  3513 sgd_solver.cpp:106] Iteration 30540, lr = 0.01
I0317 13:20:53.092344  3513 solver.cpp:228] Iteration 30560, loss = 0.00120078
I0317 13:20:53.092417  3513 solver.cpp:244]     Train net output #0: loss = 0.00120082 (* 1 = 0.00120082 loss)
I0317 13:20:53.092430  3513 sgd_solver.cpp:106] Iteration 30560, lr = 0.01
I0317 13:21:00.409454  3513 solver.cpp:228] Iteration 30580, loss = 0.00223946
I0317 13:21:00.409518  3513 solver.cpp:244]     Train net output #0: loss = 0.0022395 (* 1 = 0.0022395 loss)
I0317 13:21:00.409531  3513 sgd_solver.cpp:106] Iteration 30580, lr = 0.01
I0317 13:21:07.735299  3513 solver.cpp:228] Iteration 30600, loss = 0.00314624
I0317 13:21:07.735472  3513 solver.cpp:244]     Train net output #0: loss = 0.00314628 (* 1 = 0.00314628 loss)
I0317 13:21:07.735487  3513 sgd_solver.cpp:106] Iteration 30600, lr = 0.01
I0317 13:21:15.057637  3513 solver.cpp:228] Iteration 30620, loss = 0.00472949
I0317 13:21:15.057709  3513 solver.cpp:244]     Train net output #0: loss = 0.00472953 (* 1 = 0.00472953 loss)
I0317 13:21:15.057723  3513 sgd_solver.cpp:106] Iteration 30620, lr = 0.01
I0317 13:21:22.377256  3513 solver.cpp:228] Iteration 30640, loss = 0.00338354
I0317 13:21:22.377326  3513 solver.cpp:244]     Train net output #0: loss = 0.00338358 (* 1 = 0.00338358 loss)
I0317 13:21:22.377338  3513 sgd_solver.cpp:106] Iteration 30640, lr = 0.01
I0317 13:21:29.700098  3513 solver.cpp:228] Iteration 30660, loss = 0.00441296
I0317 13:21:29.700161  3513 solver.cpp:244]     Train net output #0: loss = 0.004413 (* 1 = 0.004413 loss)
I0317 13:21:29.700175  3513 sgd_solver.cpp:106] Iteration 30660, lr = 0.01
I0317 13:21:37.023134  3513 solver.cpp:228] Iteration 30680, loss = 0.00420451
I0317 13:21:37.023200  3513 solver.cpp:244]     Train net output #0: loss = 0.00420455 (* 1 = 0.00420455 loss)
I0317 13:21:37.023213  3513 sgd_solver.cpp:106] Iteration 30680, lr = 0.01
I0317 13:21:44.354676  3513 solver.cpp:228] Iteration 30700, loss = 0.00324114
I0317 13:21:44.354882  3513 solver.cpp:244]     Train net output #0: loss = 0.00324118 (* 1 = 0.00324118 loss)
I0317 13:21:44.354902  3513 sgd_solver.cpp:106] Iteration 30700, lr = 0.01
I0317 13:21:51.677716  3513 solver.cpp:228] Iteration 30720, loss = 0.00385102
I0317 13:21:51.677778  3513 solver.cpp:244]     Train net output #0: loss = 0.00385106 (* 1 = 0.00385106 loss)
I0317 13:21:51.677790  3513 sgd_solver.cpp:106] Iteration 30720, lr = 0.01
I0317 13:21:58.999272  3513 solver.cpp:228] Iteration 30740, loss = 0.0014902
I0317 13:21:58.999348  3513 solver.cpp:244]     Train net output #0: loss = 0.00149024 (* 1 = 0.00149024 loss)
I0317 13:21:58.999361  3513 sgd_solver.cpp:106] Iteration 30740, lr = 0.01
I0317 13:22:02.294529  3513 solver.cpp:337] Iteration 30750, Testing net (#0)
I0317 13:23:56.160317  3513 solver.cpp:404]     Test net output #0: loss = 0.0600759 (* 1 = 0.0600759 loss)
I0317 13:23:56.160436  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 13:24:00.118717  3513 solver.cpp:228] Iteration 30760, loss = 0.00541792
I0317 13:24:00.118780  3513 solver.cpp:244]     Train net output #0: loss = 0.00541796 (* 1 = 0.00541796 loss)
I0317 13:24:00.118793  3513 sgd_solver.cpp:106] Iteration 30760, lr = 0.01
I0317 13:24:07.395766  3513 solver.cpp:228] Iteration 30780, loss = 0.00513538
I0317 13:24:07.395835  3513 solver.cpp:244]     Train net output #0: loss = 0.00513542 (* 1 = 0.00513542 loss)
I0317 13:24:07.395848  3513 sgd_solver.cpp:106] Iteration 30780, lr = 0.01
I0317 13:24:14.700093  3513 solver.cpp:228] Iteration 30800, loss = 0.00424616
I0317 13:24:14.700162  3513 solver.cpp:244]     Train net output #0: loss = 0.0042462 (* 1 = 0.0042462 loss)
I0317 13:24:14.700184  3513 sgd_solver.cpp:106] Iteration 30800, lr = 0.01
I0317 13:24:22.009485  3513 solver.cpp:228] Iteration 30820, loss = 0.00323955
I0317 13:24:22.009549  3513 solver.cpp:244]     Train net output #0: loss = 0.00323959 (* 1 = 0.00323959 loss)
I0317 13:24:22.009563  3513 sgd_solver.cpp:106] Iteration 30820, lr = 0.01
I0317 13:24:29.326506  3513 solver.cpp:228] Iteration 30840, loss = 0.00437522
I0317 13:24:29.326653  3513 solver.cpp:244]     Train net output #0: loss = 0.00437526 (* 1 = 0.00437526 loss)
I0317 13:24:29.326668  3513 sgd_solver.cpp:106] Iteration 30840, lr = 0.01
I0317 13:24:36.653151  3513 solver.cpp:228] Iteration 30860, loss = 0.00503735
I0317 13:24:36.653229  3513 solver.cpp:244]     Train net output #0: loss = 0.00503739 (* 1 = 0.00503739 loss)
I0317 13:24:36.653242  3513 sgd_solver.cpp:106] Iteration 30860, lr = 0.01
I0317 13:24:43.981480  3513 solver.cpp:228] Iteration 30880, loss = 0.00507494
I0317 13:24:43.981549  3513 solver.cpp:244]     Train net output #0: loss = 0.00507498 (* 1 = 0.00507498 loss)
I0317 13:24:43.981561  3513 sgd_solver.cpp:106] Iteration 30880, lr = 0.01
I0317 13:24:51.309396  3513 solver.cpp:228] Iteration 30900, loss = 0.00331814
I0317 13:24:51.309464  3513 solver.cpp:244]     Train net output #0: loss = 0.00331818 (* 1 = 0.00331818 loss)
I0317 13:24:51.309476  3513 sgd_solver.cpp:106] Iteration 30900, lr = 0.01
I0317 13:24:58.638607  3513 solver.cpp:228] Iteration 30920, loss = 0.0010895
I0317 13:24:58.638674  3513 solver.cpp:244]     Train net output #0: loss = 0.00108954 (* 1 = 0.00108954 loss)
I0317 13:24:58.638686  3513 sgd_solver.cpp:106] Iteration 30920, lr = 0.01
I0317 13:25:05.969213  3513 solver.cpp:228] Iteration 30940, loss = 0.00344771
I0317 13:25:05.969357  3513 solver.cpp:244]     Train net output #0: loss = 0.00344775 (* 1 = 0.00344775 loss)
I0317 13:25:05.969372  3513 sgd_solver.cpp:106] Iteration 30940, lr = 0.01
I0317 13:25:13.298071  3513 solver.cpp:228] Iteration 30960, loss = 0.00380858
I0317 13:25:13.298142  3513 solver.cpp:244]     Train net output #0: loss = 0.00380862 (* 1 = 0.00380862 loss)
I0317 13:25:13.298156  3513 sgd_solver.cpp:106] Iteration 30960, lr = 0.01
I0317 13:25:20.622303  3513 solver.cpp:228] Iteration 30980, loss = 0.00477217
I0317 13:25:20.622370  3513 solver.cpp:244]     Train net output #0: loss = 0.00477221 (* 1 = 0.00477221 loss)
I0317 13:25:20.622383  3513 sgd_solver.cpp:106] Iteration 30980, lr = 0.01
I0317 13:25:27.580452  3513 solver.cpp:337] Iteration 31000, Testing net (#0)
I0317 13:27:21.436595  3513 solver.cpp:404]     Test net output #0: loss = 0.0625556 (* 1 = 0.0625556 loss)
I0317 13:27:21.436712  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64428 (* 1 = 0.64428 loss)
I0317 13:27:21.772433  3513 solver.cpp:228] Iteration 31000, loss = 0.00302359
I0317 13:27:21.772500  3513 solver.cpp:244]     Train net output #0: loss = 0.00302363 (* 1 = 0.00302363 loss)
I0317 13:27:21.772514  3513 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0317 13:27:29.020762  3513 solver.cpp:228] Iteration 31020, loss = 0.00762502
I0317 13:27:29.020823  3513 solver.cpp:244]     Train net output #0: loss = 0.00762506 (* 1 = 0.00762506 loss)
I0317 13:27:29.020835  3513 sgd_solver.cpp:106] Iteration 31020, lr = 0.01
I0317 13:27:36.329550  3513 solver.cpp:228] Iteration 31040, loss = 0.00367364
I0317 13:27:36.329617  3513 solver.cpp:244]     Train net output #0: loss = 0.00367368 (* 1 = 0.00367368 loss)
I0317 13:27:36.329629  3513 sgd_solver.cpp:106] Iteration 31040, lr = 0.01
I0317 13:27:43.659441  3513 solver.cpp:228] Iteration 31060, loss = 0.00479483
I0317 13:27:43.659512  3513 solver.cpp:244]     Train net output #0: loss = 0.00479486 (* 1 = 0.00479486 loss)
I0317 13:27:43.659524  3513 sgd_solver.cpp:106] Iteration 31060, lr = 0.01
I0317 13:27:50.989442  3513 solver.cpp:228] Iteration 31080, loss = 0.00366806
I0317 13:27:50.989504  3513 solver.cpp:244]     Train net output #0: loss = 0.0036681 (* 1 = 0.0036681 loss)
I0317 13:27:50.989517  3513 sgd_solver.cpp:106] Iteration 31080, lr = 0.01
I0317 13:27:58.324173  3513 solver.cpp:228] Iteration 31100, loss = 0.00463544
I0317 13:27:58.324329  3513 solver.cpp:244]     Train net output #0: loss = 0.00463548 (* 1 = 0.00463548 loss)
I0317 13:27:58.324343  3513 sgd_solver.cpp:106] Iteration 31100, lr = 0.01
I0317 13:28:05.653401  3513 solver.cpp:228] Iteration 31120, loss = 0.00267148
I0317 13:28:05.653466  3513 solver.cpp:244]     Train net output #0: loss = 0.00267152 (* 1 = 0.00267152 loss)
I0317 13:28:05.653479  3513 sgd_solver.cpp:106] Iteration 31120, lr = 0.01
I0317 13:28:12.989624  3513 solver.cpp:228] Iteration 31140, loss = 0.0036826
I0317 13:28:12.989692  3513 solver.cpp:244]     Train net output #0: loss = 0.00368264 (* 1 = 0.00368264 loss)
I0317 13:28:12.989706  3513 sgd_solver.cpp:106] Iteration 31140, lr = 0.01
I0317 13:28:20.317344  3513 solver.cpp:228] Iteration 31160, loss = 0.00466827
I0317 13:28:20.317435  3513 solver.cpp:244]     Train net output #0: loss = 0.00466831 (* 1 = 0.00466831 loss)
I0317 13:28:20.317450  3513 sgd_solver.cpp:106] Iteration 31160, lr = 0.01
I0317 13:28:27.643455  3513 solver.cpp:228] Iteration 31180, loss = 0.0029301
I0317 13:28:27.643529  3513 solver.cpp:244]     Train net output #0: loss = 0.00293013 (* 1 = 0.00293013 loss)
I0317 13:28:27.643543  3513 sgd_solver.cpp:106] Iteration 31180, lr = 0.01
I0317 13:28:34.971046  3513 solver.cpp:228] Iteration 31200, loss = 0.00436216
I0317 13:28:34.971199  3513 solver.cpp:244]     Train net output #0: loss = 0.0043622 (* 1 = 0.0043622 loss)
I0317 13:28:34.971212  3513 sgd_solver.cpp:106] Iteration 31200, lr = 0.01
I0317 13:28:42.301682  3513 solver.cpp:228] Iteration 31220, loss = 0.00435269
I0317 13:28:42.301767  3513 solver.cpp:244]     Train net output #0: loss = 0.00435273 (* 1 = 0.00435273 loss)
I0317 13:28:42.301780  3513 sgd_solver.cpp:106] Iteration 31220, lr = 0.01
I0317 13:28:49.634588  3513 solver.cpp:228] Iteration 31240, loss = 0.00350676
I0317 13:28:49.634651  3513 solver.cpp:244]     Train net output #0: loss = 0.00350679 (* 1 = 0.00350679 loss)
I0317 13:28:49.634665  3513 sgd_solver.cpp:106] Iteration 31240, lr = 0.01
I0317 13:28:52.934849  3513 solver.cpp:337] Iteration 31250, Testing net (#0)
I0317 13:30:46.802471  3513 solver.cpp:404]     Test net output #0: loss = 0.0631227 (* 1 = 0.0631227 loss)
I0317 13:30:46.802646  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64424 (* 1 = 0.64424 loss)
I0317 13:30:50.751703  3513 solver.cpp:228] Iteration 31260, loss = 0.00270002
I0317 13:30:50.751770  3513 solver.cpp:244]     Train net output #0: loss = 0.00270005 (* 1 = 0.00270005 loss)
I0317 13:30:50.751782  3513 sgd_solver.cpp:106] Iteration 31260, lr = 0.01
I0317 13:30:58.032024  3513 solver.cpp:228] Iteration 31280, loss = 0.00173054
I0317 13:30:58.032094  3513 solver.cpp:244]     Train net output #0: loss = 0.00173058 (* 1 = 0.00173058 loss)
I0317 13:30:58.032107  3513 sgd_solver.cpp:106] Iteration 31280, lr = 0.01
I0317 13:31:05.355933  3513 solver.cpp:228] Iteration 31300, loss = 0.00305476
I0317 13:31:05.356001  3513 solver.cpp:244]     Train net output #0: loss = 0.0030548 (* 1 = 0.0030548 loss)
I0317 13:31:05.356014  3513 sgd_solver.cpp:106] Iteration 31300, lr = 0.01
I0317 13:31:12.683441  3513 solver.cpp:228] Iteration 31320, loss = 0.0047487
I0317 13:31:12.683504  3513 solver.cpp:244]     Train net output #0: loss = 0.00474874 (* 1 = 0.00474874 loss)
I0317 13:31:12.683516  3513 sgd_solver.cpp:106] Iteration 31320, lr = 0.01
I0317 13:31:20.015455  3513 solver.cpp:228] Iteration 31340, loss = 0.00478412
I0317 13:31:20.015616  3513 solver.cpp:244]     Train net output #0: loss = 0.00478415 (* 1 = 0.00478415 loss)
I0317 13:31:20.015631  3513 sgd_solver.cpp:106] Iteration 31340, lr = 0.01
I0317 13:31:27.348485  3513 solver.cpp:228] Iteration 31360, loss = 0.00372326
I0317 13:31:27.348562  3513 solver.cpp:244]     Train net output #0: loss = 0.00372329 (* 1 = 0.00372329 loss)
I0317 13:31:27.348574  3513 sgd_solver.cpp:106] Iteration 31360, lr = 0.01
I0317 13:31:34.678030  3513 solver.cpp:228] Iteration 31380, loss = 0.00563495
I0317 13:31:34.678094  3513 solver.cpp:244]     Train net output #0: loss = 0.00563499 (* 1 = 0.00563499 loss)
I0317 13:31:34.678107  3513 sgd_solver.cpp:106] Iteration 31380, lr = 0.01
I0317 13:31:42.013885  3513 solver.cpp:228] Iteration 31400, loss = 0.00428346
I0317 13:31:42.013954  3513 solver.cpp:244]     Train net output #0: loss = 0.00428349 (* 1 = 0.00428349 loss)
I0317 13:31:42.013967  3513 sgd_solver.cpp:106] Iteration 31400, lr = 0.01
I0317 13:31:49.341537  3513 solver.cpp:228] Iteration 31420, loss = 0.00568877
I0317 13:31:49.341603  3513 solver.cpp:244]     Train net output #0: loss = 0.00568881 (* 1 = 0.00568881 loss)
I0317 13:31:49.341615  3513 sgd_solver.cpp:106] Iteration 31420, lr = 0.01
I0317 13:31:56.668969  3513 solver.cpp:228] Iteration 31440, loss = 0.00252411
I0317 13:31:56.669150  3513 solver.cpp:244]     Train net output #0: loss = 0.00252415 (* 1 = 0.00252415 loss)
I0317 13:31:56.669165  3513 sgd_solver.cpp:106] Iteration 31440, lr = 0.01
I0317 13:32:03.993865  3513 solver.cpp:228] Iteration 31460, loss = 0.003503
I0317 13:32:03.993932  3513 solver.cpp:244]     Train net output #0: loss = 0.00350303 (* 1 = 0.00350303 loss)
I0317 13:32:03.993945  3513 sgd_solver.cpp:106] Iteration 31460, lr = 0.01
I0317 13:32:11.311821  3513 solver.cpp:228] Iteration 31480, loss = 0.0033034
I0317 13:32:11.311887  3513 solver.cpp:244]     Train net output #0: loss = 0.00330344 (* 1 = 0.00330344 loss)
I0317 13:32:11.311900  3513 sgd_solver.cpp:106] Iteration 31480, lr = 0.01
I0317 13:32:18.265466  3513 solver.cpp:337] Iteration 31500, Testing net (#0)
I0317 13:34:12.115742  3513 solver.cpp:404]     Test net output #0: loss = 0.0602934 (* 1 = 0.0602934 loss)
I0317 13:34:12.115869  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65376 (* 1 = 0.65376 loss)
I0317 13:34:12.451874  3513 solver.cpp:228] Iteration 31500, loss = 0.00219035
I0317 13:34:12.451939  3513 solver.cpp:244]     Train net output #0: loss = 0.00219039 (* 1 = 0.00219039 loss)
I0317 13:34:12.451952  3513 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I0317 13:34:19.692822  3513 solver.cpp:228] Iteration 31520, loss = 0.00576325
I0317 13:34:19.692888  3513 solver.cpp:244]     Train net output #0: loss = 0.00576329 (* 1 = 0.00576329 loss)
I0317 13:34:19.692901  3513 sgd_solver.cpp:106] Iteration 31520, lr = 0.01
I0317 13:34:26.975641  3513 solver.cpp:228] Iteration 31540, loss = 0.00371544
I0317 13:34:26.975708  3513 solver.cpp:244]     Train net output #0: loss = 0.00371548 (* 1 = 0.00371548 loss)
I0317 13:34:26.975721  3513 sgd_solver.cpp:106] Iteration 31540, lr = 0.01
I0317 13:34:34.296648  3513 solver.cpp:228] Iteration 31560, loss = 0.00582718
I0317 13:34:34.296710  3513 solver.cpp:244]     Train net output #0: loss = 0.00582721 (* 1 = 0.00582721 loss)
I0317 13:34:34.296723  3513 sgd_solver.cpp:106] Iteration 31560, lr = 0.01
I0317 13:34:41.617780  3513 solver.cpp:228] Iteration 31580, loss = 0.00444185
I0317 13:34:41.617852  3513 solver.cpp:244]     Train net output #0: loss = 0.00444189 (* 1 = 0.00444189 loss)
I0317 13:34:41.617866  3513 sgd_solver.cpp:106] Iteration 31580, lr = 0.01
I0317 13:34:48.947382  3513 solver.cpp:228] Iteration 31600, loss = 0.00513728
I0317 13:34:48.947559  3513 solver.cpp:244]     Train net output #0: loss = 0.00513732 (* 1 = 0.00513732 loss)
I0317 13:34:48.947573  3513 sgd_solver.cpp:106] Iteration 31600, lr = 0.01
I0317 13:34:56.273315  3513 solver.cpp:228] Iteration 31620, loss = 0.00271372
I0317 13:34:56.273391  3513 solver.cpp:244]     Train net output #0: loss = 0.00271376 (* 1 = 0.00271376 loss)
I0317 13:34:56.273403  3513 sgd_solver.cpp:106] Iteration 31620, lr = 0.01
I0317 13:35:03.598778  3513 solver.cpp:228] Iteration 31640, loss = 0.00319691
I0317 13:35:03.598845  3513 solver.cpp:244]     Train net output #0: loss = 0.00319695 (* 1 = 0.00319695 loss)
I0317 13:35:03.598860  3513 sgd_solver.cpp:106] Iteration 31640, lr = 0.01
I0317 13:35:10.929204  3513 solver.cpp:228] Iteration 31660, loss = 0.0045747
I0317 13:35:10.929272  3513 solver.cpp:244]     Train net output #0: loss = 0.00457473 (* 1 = 0.00457473 loss)
I0317 13:35:10.929286  3513 sgd_solver.cpp:106] Iteration 31660, lr = 0.01
I0317 13:35:18.265004  3513 solver.cpp:228] Iteration 31680, loss = 0.00397925
I0317 13:35:18.265069  3513 solver.cpp:244]     Train net output #0: loss = 0.00397929 (* 1 = 0.00397929 loss)
I0317 13:35:18.265081  3513 sgd_solver.cpp:106] Iteration 31680, lr = 0.01
I0317 13:35:25.589582  3513 solver.cpp:228] Iteration 31700, loss = 0.0046067
I0317 13:35:25.589735  3513 solver.cpp:244]     Train net output #0: loss = 0.00460674 (* 1 = 0.00460674 loss)
I0317 13:35:25.589748  3513 sgd_solver.cpp:106] Iteration 31700, lr = 0.01
I0317 13:35:32.909598  3513 solver.cpp:228] Iteration 31720, loss = 0.00281775
I0317 13:35:32.909667  3513 solver.cpp:244]     Train net output #0: loss = 0.00281779 (* 1 = 0.00281779 loss)
I0317 13:35:32.909679  3513 sgd_solver.cpp:106] Iteration 31720, lr = 0.01
I0317 13:35:40.233525  3513 solver.cpp:228] Iteration 31740, loss = 0.00427738
I0317 13:35:40.233595  3513 solver.cpp:244]     Train net output #0: loss = 0.00427742 (* 1 = 0.00427742 loss)
I0317 13:35:40.233608  3513 sgd_solver.cpp:106] Iteration 31740, lr = 0.01
I0317 13:35:43.535082  3513 solver.cpp:337] Iteration 31750, Testing net (#0)
I0317 13:37:37.392202  3513 solver.cpp:404]     Test net output #0: loss = 0.0605275 (* 1 = 0.0605275 loss)
I0317 13:37:37.392330  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6636 (* 1 = 0.6636 loss)
I0317 13:37:41.337900  3513 solver.cpp:228] Iteration 31760, loss = 0.00453467
I0317 13:37:41.337967  3513 solver.cpp:244]     Train net output #0: loss = 0.00453471 (* 1 = 0.00453471 loss)
I0317 13:37:41.337980  3513 sgd_solver.cpp:106] Iteration 31760, lr = 0.01
I0317 13:37:48.592325  3513 solver.cpp:228] Iteration 31780, loss = 0.00710965
I0317 13:37:48.592399  3513 solver.cpp:244]     Train net output #0: loss = 0.00710969 (* 1 = 0.00710969 loss)
I0317 13:37:48.592413  3513 sgd_solver.cpp:106] Iteration 31780, lr = 0.01
I0317 13:37:55.881225  3513 solver.cpp:228] Iteration 31800, loss = 0.00339743
I0317 13:37:55.881291  3513 solver.cpp:244]     Train net output #0: loss = 0.00339747 (* 1 = 0.00339747 loss)
I0317 13:37:55.881304  3513 sgd_solver.cpp:106] Iteration 31800, lr = 0.01
I0317 13:38:03.190065  3513 solver.cpp:228] Iteration 31820, loss = 0.00437324
I0317 13:38:03.190136  3513 solver.cpp:244]     Train net output #0: loss = 0.00437328 (* 1 = 0.00437328 loss)
I0317 13:38:03.190150  3513 sgd_solver.cpp:106] Iteration 31820, lr = 0.01
I0317 13:38:10.515856  3513 solver.cpp:228] Iteration 31840, loss = 0.00254867
I0317 13:38:10.516077  3513 solver.cpp:244]     Train net output #0: loss = 0.00254871 (* 1 = 0.00254871 loss)
I0317 13:38:10.516091  3513 sgd_solver.cpp:106] Iteration 31840, lr = 0.01
I0317 13:38:17.842752  3513 solver.cpp:228] Iteration 31860, loss = 0.00219803
I0317 13:38:17.842821  3513 solver.cpp:244]     Train net output #0: loss = 0.00219807 (* 1 = 0.00219807 loss)
I0317 13:38:17.842833  3513 sgd_solver.cpp:106] Iteration 31860, lr = 0.01
I0317 13:38:25.173589  3513 solver.cpp:228] Iteration 31880, loss = 0.00839086
I0317 13:38:25.173652  3513 solver.cpp:244]     Train net output #0: loss = 0.0083909 (* 1 = 0.0083909 loss)
I0317 13:38:25.173665  3513 sgd_solver.cpp:106] Iteration 31880, lr = 0.01
I0317 13:38:32.504711  3513 solver.cpp:228] Iteration 31900, loss = 0.00430589
I0317 13:38:32.504807  3513 solver.cpp:244]     Train net output #0: loss = 0.00430593 (* 1 = 0.00430593 loss)
I0317 13:38:32.504822  3513 sgd_solver.cpp:106] Iteration 31900, lr = 0.01
I0317 13:38:39.828982  3513 solver.cpp:228] Iteration 31920, loss = 0.00460525
I0317 13:38:39.829048  3513 solver.cpp:244]     Train net output #0: loss = 0.00460529 (* 1 = 0.00460529 loss)
I0317 13:38:39.829061  3513 sgd_solver.cpp:106] Iteration 31920, lr = 0.01
I0317 13:38:47.143178  3513 solver.cpp:228] Iteration 31940, loss = 0.00499548
I0317 13:38:47.143344  3513 solver.cpp:244]     Train net output #0: loss = 0.00499552 (* 1 = 0.00499552 loss)
I0317 13:38:47.143358  3513 sgd_solver.cpp:106] Iteration 31940, lr = 0.01
I0317 13:38:54.466133  3513 solver.cpp:228] Iteration 31960, loss = 0.00610593
I0317 13:38:54.466207  3513 solver.cpp:244]     Train net output #0: loss = 0.00610597 (* 1 = 0.00610597 loss)
I0317 13:38:54.466222  3513 sgd_solver.cpp:106] Iteration 31960, lr = 0.01
I0317 13:39:01.796537  3513 solver.cpp:228] Iteration 31980, loss = 0.00256327
I0317 13:39:01.796610  3513 solver.cpp:244]     Train net output #0: loss = 0.00256331 (* 1 = 0.00256331 loss)
I0317 13:39:01.796623  3513 sgd_solver.cpp:106] Iteration 31980, lr = 0.01
I0317 13:39:08.748345  3513 solver.cpp:337] Iteration 32000, Testing net (#0)
I0317 13:41:02.617936  3513 solver.cpp:404]     Test net output #0: loss = 0.0617409 (* 1 = 0.0617409 loss)
I0317 13:41:02.618044  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66336 (* 1 = 0.66336 loss)
I0317 13:41:02.954398  3513 solver.cpp:228] Iteration 32000, loss = 0.00342955
I0317 13:41:02.954463  3513 solver.cpp:244]     Train net output #0: loss = 0.00342959 (* 1 = 0.00342959 loss)
I0317 13:41:02.954478  3513 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I0317 13:41:10.198302  3513 solver.cpp:228] Iteration 32020, loss = 0.00225726
I0317 13:41:10.198371  3513 solver.cpp:244]     Train net output #0: loss = 0.0022573 (* 1 = 0.0022573 loss)
I0317 13:41:10.198385  3513 sgd_solver.cpp:106] Iteration 32020, lr = 0.01
I0317 13:41:17.494559  3513 solver.cpp:228] Iteration 32040, loss = 0.00339229
I0317 13:41:17.494626  3513 solver.cpp:244]     Train net output #0: loss = 0.00339233 (* 1 = 0.00339233 loss)
I0317 13:41:17.494638  3513 sgd_solver.cpp:106] Iteration 32040, lr = 0.01
I0317 13:41:24.811868  3513 solver.cpp:228] Iteration 32060, loss = 0.00547877
I0317 13:41:24.811935  3513 solver.cpp:244]     Train net output #0: loss = 0.00547881 (* 1 = 0.00547881 loss)
I0317 13:41:24.811949  3513 sgd_solver.cpp:106] Iteration 32060, lr = 0.01
I0317 13:41:32.130650  3513 solver.cpp:228] Iteration 32080, loss = 0.00291285
I0317 13:41:32.130720  3513 solver.cpp:244]     Train net output #0: loss = 0.00291289 (* 1 = 0.00291289 loss)
I0317 13:41:32.130733  3513 sgd_solver.cpp:106] Iteration 32080, lr = 0.01
I0317 13:41:39.462968  3513 solver.cpp:228] Iteration 32100, loss = 0.00679472
I0317 13:41:39.463105  3513 solver.cpp:244]     Train net output #0: loss = 0.00679476 (* 1 = 0.00679476 loss)
I0317 13:41:39.463119  3513 sgd_solver.cpp:106] Iteration 32100, lr = 0.01
I0317 13:41:46.796525  3513 solver.cpp:228] Iteration 32120, loss = 0.00520315
I0317 13:41:46.796594  3513 solver.cpp:244]     Train net output #0: loss = 0.00520319 (* 1 = 0.00520319 loss)
I0317 13:41:46.796607  3513 sgd_solver.cpp:106] Iteration 32120, lr = 0.01
I0317 13:41:54.129809  3513 solver.cpp:228] Iteration 32140, loss = 0.00533561
I0317 13:41:54.129876  3513 solver.cpp:244]     Train net output #0: loss = 0.00533565 (* 1 = 0.00533565 loss)
I0317 13:41:54.129889  3513 sgd_solver.cpp:106] Iteration 32140, lr = 0.01
I0317 13:42:01.455158  3513 solver.cpp:228] Iteration 32160, loss = 0.00166696
I0317 13:42:01.455225  3513 solver.cpp:244]     Train net output #0: loss = 0.001667 (* 1 = 0.001667 loss)
I0317 13:42:01.455238  3513 sgd_solver.cpp:106] Iteration 32160, lr = 0.01
I0317 13:42:08.789845  3513 solver.cpp:228] Iteration 32180, loss = 0.0017931
I0317 13:42:08.789916  3513 solver.cpp:244]     Train net output #0: loss = 0.00179314 (* 1 = 0.00179314 loss)
I0317 13:42:08.789928  3513 sgd_solver.cpp:106] Iteration 32180, lr = 0.01
I0317 13:42:16.130388  3513 solver.cpp:228] Iteration 32200, loss = 0.00228637
I0317 13:42:16.130580  3513 solver.cpp:244]     Train net output #0: loss = 0.00228641 (* 1 = 0.00228641 loss)
I0317 13:42:16.130594  3513 sgd_solver.cpp:106] Iteration 32200, lr = 0.01
I0317 13:42:23.464617  3513 solver.cpp:228] Iteration 32220, loss = 0.00462373
I0317 13:42:23.464685  3513 solver.cpp:244]     Train net output #0: loss = 0.00462377 (* 1 = 0.00462377 loss)
I0317 13:42:23.464699  3513 sgd_solver.cpp:106] Iteration 32220, lr = 0.01
I0317 13:42:30.787824  3513 solver.cpp:228] Iteration 32240, loss = 0.00517674
I0317 13:42:30.787894  3513 solver.cpp:244]     Train net output #0: loss = 0.00517678 (* 1 = 0.00517678 loss)
I0317 13:42:30.787909  3513 sgd_solver.cpp:106] Iteration 32240, lr = 0.01
I0317 13:42:34.081558  3513 solver.cpp:337] Iteration 32250, Testing net (#0)
I0317 13:44:28.003332  3513 solver.cpp:404]     Test net output #0: loss = 0.0582296 (* 1 = 0.0582296 loss)
I0317 13:44:28.003471  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65384 (* 1 = 0.65384 loss)
I0317 13:44:31.953646  3513 solver.cpp:228] Iteration 32260, loss = 0.00254318
I0317 13:44:31.953709  3513 solver.cpp:244]     Train net output #0: loss = 0.00254322 (* 1 = 0.00254322 loss)
I0317 13:44:31.953722  3513 sgd_solver.cpp:106] Iteration 32260, lr = 0.01
I0317 13:44:39.221639  3513 solver.cpp:228] Iteration 32280, loss = 0.00585451
I0317 13:44:39.221700  3513 solver.cpp:244]     Train net output #0: loss = 0.00585455 (* 1 = 0.00585455 loss)
I0317 13:44:39.221714  3513 sgd_solver.cpp:106] Iteration 32280, lr = 0.01
I0317 13:44:46.522923  3513 solver.cpp:228] Iteration 32300, loss = 0.00646438
I0317 13:44:46.522997  3513 solver.cpp:244]     Train net output #0: loss = 0.00646442 (* 1 = 0.00646442 loss)
I0317 13:44:46.523011  3513 sgd_solver.cpp:106] Iteration 32300, lr = 0.01
I0317 13:44:53.834674  3513 solver.cpp:228] Iteration 32320, loss = 0.0071218
I0317 13:44:53.834738  3513 solver.cpp:244]     Train net output #0: loss = 0.00712184 (* 1 = 0.00712184 loss)
I0317 13:44:53.834750  3513 sgd_solver.cpp:106] Iteration 32320, lr = 0.01
I0317 13:45:01.156777  3513 solver.cpp:228] Iteration 32340, loss = 0.00231973
I0317 13:45:01.156925  3513 solver.cpp:244]     Train net output #0: loss = 0.00231977 (* 1 = 0.00231977 loss)
I0317 13:45:01.156939  3513 sgd_solver.cpp:106] Iteration 32340, lr = 0.01
I0317 13:45:08.491827  3513 solver.cpp:228] Iteration 32360, loss = 0.00297122
I0317 13:45:08.491895  3513 solver.cpp:244]     Train net output #0: loss = 0.00297126 (* 1 = 0.00297126 loss)
I0317 13:45:08.491909  3513 sgd_solver.cpp:106] Iteration 32360, lr = 0.01
I0317 13:45:15.830301  3513 solver.cpp:228] Iteration 32380, loss = 0.00390541
I0317 13:45:15.830369  3513 solver.cpp:244]     Train net output #0: loss = 0.00390545 (* 1 = 0.00390545 loss)
I0317 13:45:15.830385  3513 sgd_solver.cpp:106] Iteration 32380, lr = 0.01
I0317 13:45:23.162641  3513 solver.cpp:228] Iteration 32400, loss = 0.00324957
I0317 13:45:23.162705  3513 solver.cpp:244]     Train net output #0: loss = 0.00324961 (* 1 = 0.00324961 loss)
I0317 13:45:23.162719  3513 sgd_solver.cpp:106] Iteration 32400, lr = 0.01
I0317 13:45:30.497305  3513 solver.cpp:228] Iteration 32420, loss = 0.00398915
I0317 13:45:30.497383  3513 solver.cpp:244]     Train net output #0: loss = 0.00398919 (* 1 = 0.00398919 loss)
I0317 13:45:30.497397  3513 sgd_solver.cpp:106] Iteration 32420, lr = 0.01
I0317 13:45:37.834949  3513 solver.cpp:228] Iteration 32440, loss = 0.00484314
I0317 13:45:37.835125  3513 solver.cpp:244]     Train net output #0: loss = 0.00484318 (* 1 = 0.00484318 loss)
I0317 13:45:37.835139  3513 sgd_solver.cpp:106] Iteration 32440, lr = 0.01
I0317 13:45:45.173614  3513 solver.cpp:228] Iteration 32460, loss = 0.0068124
I0317 13:45:45.173676  3513 solver.cpp:244]     Train net output #0: loss = 0.00681244 (* 1 = 0.00681244 loss)
I0317 13:45:45.173688  3513 sgd_solver.cpp:106] Iteration 32460, lr = 0.01
I0317 13:45:52.504787  3513 solver.cpp:228] Iteration 32480, loss = 0.00646557
I0317 13:45:52.504855  3513 solver.cpp:244]     Train net output #0: loss = 0.00646561 (* 1 = 0.00646561 loss)
I0317 13:45:52.504868  3513 sgd_solver.cpp:106] Iteration 32480, lr = 0.01
I0317 13:45:59.472491  3513 solver.cpp:337] Iteration 32500, Testing net (#0)
I0317 13:47:53.347235  3513 solver.cpp:404]     Test net output #0: loss = 0.064197 (* 1 = 0.064197 loss)
I0317 13:47:53.347371  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65396 (* 1 = 0.65396 loss)
I0317 13:47:53.683228  3513 solver.cpp:228] Iteration 32500, loss = 0.00370179
I0317 13:47:53.683292  3513 solver.cpp:244]     Train net output #0: loss = 0.00370183 (* 1 = 0.00370183 loss)
I0317 13:47:53.683306  3513 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I0317 13:48:00.927255  3513 solver.cpp:228] Iteration 32520, loss = 0.000866652
I0317 13:48:00.927325  3513 solver.cpp:244]     Train net output #0: loss = 0.000866691 (* 1 = 0.000866691 loss)
I0317 13:48:00.927338  3513 sgd_solver.cpp:106] Iteration 32520, lr = 0.01
I0317 13:48:08.224215  3513 solver.cpp:228] Iteration 32540, loss = 0.00112029
I0317 13:48:08.224288  3513 solver.cpp:244]     Train net output #0: loss = 0.00112033 (* 1 = 0.00112033 loss)
I0317 13:48:08.224303  3513 sgd_solver.cpp:106] Iteration 32540, lr = 0.01
I0317 13:48:15.545526  3513 solver.cpp:228] Iteration 32560, loss = 0.00256196
I0317 13:48:15.545601  3513 solver.cpp:244]     Train net output #0: loss = 0.002562 (* 1 = 0.002562 loss)
I0317 13:48:15.545616  3513 sgd_solver.cpp:106] Iteration 32560, lr = 0.01
I0317 13:48:22.878689  3513 solver.cpp:228] Iteration 32580, loss = 0.00381384
I0317 13:48:22.878763  3513 solver.cpp:244]     Train net output #0: loss = 0.00381388 (* 1 = 0.00381388 loss)
I0317 13:48:22.878777  3513 sgd_solver.cpp:106] Iteration 32580, lr = 0.01
I0317 13:48:30.207418  3513 solver.cpp:228] Iteration 32600, loss = 0.00254601
I0317 13:48:30.207562  3513 solver.cpp:244]     Train net output #0: loss = 0.00254605 (* 1 = 0.00254605 loss)
I0317 13:48:30.207576  3513 sgd_solver.cpp:106] Iteration 32600, lr = 0.01
I0317 13:48:37.535419  3513 solver.cpp:228] Iteration 32620, loss = 0.00419648
I0317 13:48:37.535482  3513 solver.cpp:244]     Train net output #0: loss = 0.00419652 (* 1 = 0.00419652 loss)
I0317 13:48:37.535495  3513 sgd_solver.cpp:106] Iteration 32620, lr = 0.01
I0317 13:48:44.864711  3513 solver.cpp:228] Iteration 32640, loss = 0.0116764
I0317 13:48:44.864778  3513 solver.cpp:244]     Train net output #0: loss = 0.0116764 (* 1 = 0.0116764 loss)
I0317 13:48:44.864790  3513 sgd_solver.cpp:106] Iteration 32640, lr = 0.01
I0317 13:48:52.192765  3513 solver.cpp:228] Iteration 32660, loss = 0.00522025
I0317 13:48:52.192836  3513 solver.cpp:244]     Train net output #0: loss = 0.00522029 (* 1 = 0.00522029 loss)
I0317 13:48:52.192849  3513 sgd_solver.cpp:106] Iteration 32660, lr = 0.01
I0317 13:48:59.529691  3513 solver.cpp:228] Iteration 32680, loss = 0.00666253
I0317 13:48:59.529757  3513 solver.cpp:244]     Train net output #0: loss = 0.00666257 (* 1 = 0.00666257 loss)
I0317 13:48:59.529770  3513 sgd_solver.cpp:106] Iteration 32680, lr = 0.01
I0317 13:49:06.866924  3513 solver.cpp:228] Iteration 32700, loss = 0.00366359
I0317 13:49:06.867113  3513 solver.cpp:244]     Train net output #0: loss = 0.00366363 (* 1 = 0.00366363 loss)
I0317 13:49:06.867127  3513 sgd_solver.cpp:106] Iteration 32700, lr = 0.01
I0317 13:49:14.187922  3513 solver.cpp:228] Iteration 32720, loss = 0.00195634
I0317 13:49:14.187985  3513 solver.cpp:244]     Train net output #0: loss = 0.00195638 (* 1 = 0.00195638 loss)
I0317 13:49:14.187999  3513 sgd_solver.cpp:106] Iteration 32720, lr = 0.01
I0317 13:49:21.511088  3513 solver.cpp:228] Iteration 32740, loss = 0.00303427
I0317 13:49:21.511159  3513 solver.cpp:244]     Train net output #0: loss = 0.00303431 (* 1 = 0.00303431 loss)
I0317 13:49:21.511173  3513 sgd_solver.cpp:106] Iteration 32740, lr = 0.01
I0317 13:49:24.803231  3513 solver.cpp:337] Iteration 32750, Testing net (#0)
I0317 13:51:18.658632  3513 solver.cpp:404]     Test net output #0: loss = 0.0606452 (* 1 = 0.0606452 loss)
I0317 13:51:18.658751  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64412 (* 1 = 0.64412 loss)
I0317 13:51:22.610750  3513 solver.cpp:228] Iteration 32760, loss = 0.00365084
I0317 13:51:22.610822  3513 solver.cpp:244]     Train net output #0: loss = 0.00365088 (* 1 = 0.00365088 loss)
I0317 13:51:22.610836  3513 sgd_solver.cpp:106] Iteration 32760, lr = 0.01
I0317 13:51:29.884169  3513 solver.cpp:228] Iteration 32780, loss = 0.00320121
I0317 13:51:29.884238  3513 solver.cpp:244]     Train net output #0: loss = 0.00320126 (* 1 = 0.00320126 loss)
I0317 13:51:29.884251  3513 sgd_solver.cpp:106] Iteration 32780, lr = 0.01
I0317 13:51:37.196353  3513 solver.cpp:228] Iteration 32800, loss = 0.00508048
I0317 13:51:37.196420  3513 solver.cpp:244]     Train net output #0: loss = 0.00508052 (* 1 = 0.00508052 loss)
I0317 13:51:37.196434  3513 sgd_solver.cpp:106] Iteration 32800, lr = 0.01
I0317 13:51:44.511976  3513 solver.cpp:228] Iteration 32820, loss = 0.0081766
I0317 13:51:44.512040  3513 solver.cpp:244]     Train net output #0: loss = 0.00817664 (* 1 = 0.00817664 loss)
I0317 13:51:44.512053  3513 sgd_solver.cpp:106] Iteration 32820, lr = 0.01
I0317 13:51:51.828444  3513 solver.cpp:228] Iteration 32840, loss = 0.00406551
I0317 13:51:51.828585  3513 solver.cpp:244]     Train net output #0: loss = 0.00406555 (* 1 = 0.00406555 loss)
I0317 13:51:51.828600  3513 sgd_solver.cpp:106] Iteration 32840, lr = 0.01
I0317 13:51:59.152545  3513 solver.cpp:228] Iteration 32860, loss = 0.0041441
I0317 13:51:59.152606  3513 solver.cpp:244]     Train net output #0: loss = 0.00414414 (* 1 = 0.00414414 loss)
I0317 13:51:59.152618  3513 sgd_solver.cpp:106] Iteration 32860, lr = 0.01
I0317 13:52:06.468142  3513 solver.cpp:228] Iteration 32880, loss = 0.00243494
I0317 13:52:06.468209  3513 solver.cpp:244]     Train net output #0: loss = 0.00243498 (* 1 = 0.00243498 loss)
I0317 13:52:06.468222  3513 sgd_solver.cpp:106] Iteration 32880, lr = 0.01
I0317 13:52:13.785424  3513 solver.cpp:228] Iteration 32900, loss = 0.00252379
I0317 13:52:13.785493  3513 solver.cpp:244]     Train net output #0: loss = 0.00252383 (* 1 = 0.00252383 loss)
I0317 13:52:13.785506  3513 sgd_solver.cpp:106] Iteration 32900, lr = 0.01
I0317 13:52:21.107798  3513 solver.cpp:228] Iteration 32920, loss = 0.00270693
I0317 13:52:21.107866  3513 solver.cpp:244]     Train net output #0: loss = 0.00270697 (* 1 = 0.00270697 loss)
I0317 13:52:21.107878  3513 sgd_solver.cpp:106] Iteration 32920, lr = 0.01
I0317 13:52:28.427947  3513 solver.cpp:228] Iteration 32940, loss = 0.00240527
I0317 13:52:28.428094  3513 solver.cpp:244]     Train net output #0: loss = 0.00240531 (* 1 = 0.00240531 loss)
I0317 13:52:28.428109  3513 sgd_solver.cpp:106] Iteration 32940, lr = 0.01
I0317 13:52:35.748303  3513 solver.cpp:228] Iteration 32960, loss = 0.00584585
I0317 13:52:35.748371  3513 solver.cpp:244]     Train net output #0: loss = 0.00584589 (* 1 = 0.00584589 loss)
I0317 13:52:35.748384  3513 sgd_solver.cpp:106] Iteration 32960, lr = 0.01
I0317 13:52:43.070431  3513 solver.cpp:228] Iteration 32980, loss = 0.00517825
I0317 13:52:43.070495  3513 solver.cpp:244]     Train net output #0: loss = 0.00517829 (* 1 = 0.00517829 loss)
I0317 13:52:43.070508  3513 sgd_solver.cpp:106] Iteration 32980, lr = 0.01
I0317 13:52:50.034523  3513 solver.cpp:337] Iteration 33000, Testing net (#0)
I0317 13:54:43.917047  3513 solver.cpp:404]     Test net output #0: loss = 0.0606749 (* 1 = 0.0606749 loss)
I0317 13:54:43.917197  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64424 (* 1 = 0.64424 loss)
I0317 13:54:44.253242  3513 solver.cpp:228] Iteration 33000, loss = 0.00777532
I0317 13:54:44.253309  3513 solver.cpp:244]     Train net output #0: loss = 0.00777536 (* 1 = 0.00777536 loss)
I0317 13:54:44.253321  3513 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I0317 13:54:51.496407  3513 solver.cpp:228] Iteration 33020, loss = 0.00380438
I0317 13:54:51.496474  3513 solver.cpp:244]     Train net output #0: loss = 0.00380443 (* 1 = 0.00380443 loss)
I0317 13:54:51.496486  3513 sgd_solver.cpp:106] Iteration 33020, lr = 0.01
I0317 13:54:58.793264  3513 solver.cpp:228] Iteration 33040, loss = 0.00396655
I0317 13:54:58.793332  3513 solver.cpp:244]     Train net output #0: loss = 0.0039666 (* 1 = 0.0039666 loss)
I0317 13:54:58.793345  3513 sgd_solver.cpp:106] Iteration 33040, lr = 0.01
I0317 13:55:06.118739  3513 solver.cpp:228] Iteration 33060, loss = 0.00237094
I0317 13:55:06.118808  3513 solver.cpp:244]     Train net output #0: loss = 0.00237098 (* 1 = 0.00237098 loss)
I0317 13:55:06.118820  3513 sgd_solver.cpp:106] Iteration 33060, lr = 0.01
I0317 13:55:13.449584  3513 solver.cpp:228] Iteration 33080, loss = 0.00165665
I0317 13:55:13.449653  3513 solver.cpp:244]     Train net output #0: loss = 0.00165669 (* 1 = 0.00165669 loss)
I0317 13:55:13.449666  3513 sgd_solver.cpp:106] Iteration 33080, lr = 0.01
I0317 13:55:20.788318  3513 solver.cpp:228] Iteration 33100, loss = 0.00302039
I0317 13:55:20.788465  3513 solver.cpp:244]     Train net output #0: loss = 0.00302043 (* 1 = 0.00302043 loss)
I0317 13:55:20.788478  3513 sgd_solver.cpp:106] Iteration 33100, lr = 0.01
I0317 13:55:28.126605  3513 solver.cpp:228] Iteration 33120, loss = 0.00307469
I0317 13:55:28.126675  3513 solver.cpp:244]     Train net output #0: loss = 0.00307473 (* 1 = 0.00307473 loss)
I0317 13:55:28.126688  3513 sgd_solver.cpp:106] Iteration 33120, lr = 0.01
I0317 13:55:35.445333  3513 solver.cpp:228] Iteration 33140, loss = 0.00554311
I0317 13:55:35.445399  3513 solver.cpp:244]     Train net output #0: loss = 0.00554315 (* 1 = 0.00554315 loss)
I0317 13:55:35.445412  3513 sgd_solver.cpp:106] Iteration 33140, lr = 0.01
I0317 13:55:42.764601  3513 solver.cpp:228] Iteration 33160, loss = 0.0034255
I0317 13:55:42.764665  3513 solver.cpp:244]     Train net output #0: loss = 0.00342554 (* 1 = 0.00342554 loss)
I0317 13:55:42.764678  3513 sgd_solver.cpp:106] Iteration 33160, lr = 0.01
I0317 13:55:50.088798  3513 solver.cpp:228] Iteration 33180, loss = 0.0058233
I0317 13:55:50.088870  3513 solver.cpp:244]     Train net output #0: loss = 0.00582334 (* 1 = 0.00582334 loss)
I0317 13:55:50.088882  3513 sgd_solver.cpp:106] Iteration 33180, lr = 0.01
I0317 13:55:57.418133  3513 solver.cpp:228] Iteration 33200, loss = 0.00614537
I0317 13:55:57.418280  3513 solver.cpp:244]     Train net output #0: loss = 0.00614541 (* 1 = 0.00614541 loss)
I0317 13:55:57.418294  3513 sgd_solver.cpp:106] Iteration 33200, lr = 0.01
I0317 13:56:04.739639  3513 solver.cpp:228] Iteration 33220, loss = 0.00540932
I0317 13:56:04.739707  3513 solver.cpp:244]     Train net output #0: loss = 0.00540936 (* 1 = 0.00540936 loss)
I0317 13:56:04.739720  3513 sgd_solver.cpp:106] Iteration 33220, lr = 0.01
I0317 13:56:12.069334  3513 solver.cpp:228] Iteration 33240, loss = 0.00176159
I0317 13:56:12.069406  3513 solver.cpp:244]     Train net output #0: loss = 0.00176163 (* 1 = 0.00176163 loss)
I0317 13:56:12.069418  3513 sgd_solver.cpp:106] Iteration 33240, lr = 0.01
I0317 13:56:15.372341  3513 solver.cpp:337] Iteration 33250, Testing net (#0)
I0317 13:58:09.215278  3513 solver.cpp:404]     Test net output #0: loss = 0.0623275 (* 1 = 0.0623275 loss)
I0317 13:58:09.215436  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.63468 (* 1 = 0.63468 loss)
I0317 13:58:13.162709  3513 solver.cpp:228] Iteration 33260, loss = 0.00234019
I0317 13:58:13.162793  3513 solver.cpp:244]     Train net output #0: loss = 0.00234023 (* 1 = 0.00234023 loss)
I0317 13:58:13.162806  3513 sgd_solver.cpp:106] Iteration 33260, lr = 0.01
I0317 13:58:20.433881  3513 solver.cpp:228] Iteration 33280, loss = 0.00174921
I0317 13:58:20.433951  3513 solver.cpp:244]     Train net output #0: loss = 0.00174925 (* 1 = 0.00174925 loss)
I0317 13:58:20.433965  3513 sgd_solver.cpp:106] Iteration 33280, lr = 0.01
I0317 13:58:27.729863  3513 solver.cpp:228] Iteration 33300, loss = 0.00657682
I0317 13:58:27.729930  3513 solver.cpp:244]     Train net output #0: loss = 0.00657686 (* 1 = 0.00657686 loss)
I0317 13:58:27.729943  3513 sgd_solver.cpp:106] Iteration 33300, lr = 0.01
I0317 13:58:35.051612  3513 solver.cpp:228] Iteration 33320, loss = 0.00447993
I0317 13:58:35.051674  3513 solver.cpp:244]     Train net output #0: loss = 0.00447997 (* 1 = 0.00447997 loss)
I0317 13:58:35.051687  3513 sgd_solver.cpp:106] Iteration 33320, lr = 0.01
I0317 13:58:42.379673  3513 solver.cpp:228] Iteration 33340, loss = 0.00338558
I0317 13:58:42.379828  3513 solver.cpp:244]     Train net output #0: loss = 0.00338562 (* 1 = 0.00338562 loss)
I0317 13:58:42.379842  3513 sgd_solver.cpp:106] Iteration 33340, lr = 0.01
I0317 13:58:49.702913  3513 solver.cpp:228] Iteration 33360, loss = 0.00704582
I0317 13:58:49.702987  3513 solver.cpp:244]     Train net output #0: loss = 0.00704586 (* 1 = 0.00704586 loss)
I0317 13:58:49.703001  3513 sgd_solver.cpp:106] Iteration 33360, lr = 0.01
I0317 13:58:57.031299  3513 solver.cpp:228] Iteration 33380, loss = 0.00420073
I0317 13:58:57.031364  3513 solver.cpp:244]     Train net output #0: loss = 0.00420077 (* 1 = 0.00420077 loss)
I0317 13:58:57.031378  3513 sgd_solver.cpp:106] Iteration 33380, lr = 0.01
I0317 13:59:04.361400  3513 solver.cpp:228] Iteration 33400, loss = 0.00546266
I0317 13:59:04.361471  3513 solver.cpp:244]     Train net output #0: loss = 0.0054627 (* 1 = 0.0054627 loss)
I0317 13:59:04.361485  3513 sgd_solver.cpp:106] Iteration 33400, lr = 0.01
I0317 13:59:11.685219  3513 solver.cpp:228] Iteration 33420, loss = 0.00344215
I0317 13:59:11.685282  3513 solver.cpp:244]     Train net output #0: loss = 0.00344219 (* 1 = 0.00344219 loss)
I0317 13:59:11.685294  3513 sgd_solver.cpp:106] Iteration 33420, lr = 0.01
I0317 13:59:19.002185  3513 solver.cpp:228] Iteration 33440, loss = 0.000992578
I0317 13:59:19.002308  3513 solver.cpp:244]     Train net output #0: loss = 0.000992617 (* 1 = 0.000992617 loss)
I0317 13:59:19.002321  3513 sgd_solver.cpp:106] Iteration 33440, lr = 0.01
I0317 13:59:26.324396  3513 solver.cpp:228] Iteration 33460, loss = 0.0034908
I0317 13:59:26.324465  3513 solver.cpp:244]     Train net output #0: loss = 0.00349084 (* 1 = 0.00349084 loss)
I0317 13:59:26.324477  3513 sgd_solver.cpp:106] Iteration 33460, lr = 0.01
I0317 13:59:33.652257  3513 solver.cpp:228] Iteration 33480, loss = 0.00277211
I0317 13:59:33.652326  3513 solver.cpp:244]     Train net output #0: loss = 0.00277215 (* 1 = 0.00277215 loss)
I0317 13:59:33.652339  3513 sgd_solver.cpp:106] Iteration 33480, lr = 0.01
I0317 13:59:40.614972  3513 solver.cpp:337] Iteration 33500, Testing net (#0)
I0317 14:01:34.484612  3513 solver.cpp:404]     Test net output #0: loss = 0.0586381 (* 1 = 0.0586381 loss)
I0317 14:01:34.484727  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 14:01:34.822093  3513 solver.cpp:228] Iteration 33500, loss = 0.00510659
I0317 14:01:34.822160  3513 solver.cpp:244]     Train net output #0: loss = 0.00510663 (* 1 = 0.00510663 loss)
I0317 14:01:34.822172  3513 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I0317 14:01:42.058338  3513 solver.cpp:228] Iteration 33520, loss = 0.00597389
I0317 14:01:42.058403  3513 solver.cpp:244]     Train net output #0: loss = 0.00597393 (* 1 = 0.00597393 loss)
I0317 14:01:42.058416  3513 sgd_solver.cpp:106] Iteration 33520, lr = 0.01
I0317 14:01:49.344492  3513 solver.cpp:228] Iteration 33540, loss = 0.00896251
I0317 14:01:49.344560  3513 solver.cpp:244]     Train net output #0: loss = 0.00896255 (* 1 = 0.00896255 loss)
I0317 14:01:49.344574  3513 sgd_solver.cpp:106] Iteration 33540, lr = 0.01
I0317 14:01:56.656915  3513 solver.cpp:228] Iteration 33560, loss = 0.00581195
I0317 14:01:56.656983  3513 solver.cpp:244]     Train net output #0: loss = 0.00581199 (* 1 = 0.00581199 loss)
I0317 14:01:56.656997  3513 sgd_solver.cpp:106] Iteration 33560, lr = 0.01
I0317 14:02:03.979399  3513 solver.cpp:228] Iteration 33580, loss = 0.00707195
I0317 14:02:03.979467  3513 solver.cpp:244]     Train net output #0: loss = 0.00707199 (* 1 = 0.00707199 loss)
I0317 14:02:03.979480  3513 sgd_solver.cpp:106] Iteration 33580, lr = 0.01
I0317 14:02:11.302824  3513 solver.cpp:228] Iteration 33600, loss = 0.00198799
I0317 14:02:11.303031  3513 solver.cpp:244]     Train net output #0: loss = 0.00198803 (* 1 = 0.00198803 loss)
I0317 14:02:11.303046  3513 sgd_solver.cpp:106] Iteration 33600, lr = 0.01
I0317 14:02:18.624657  3513 solver.cpp:228] Iteration 33620, loss = 0.00284514
I0317 14:02:18.624727  3513 solver.cpp:244]     Train net output #0: loss = 0.00284517 (* 1 = 0.00284517 loss)
I0317 14:02:18.624740  3513 sgd_solver.cpp:106] Iteration 33620, lr = 0.01
I0317 14:02:25.939688  3513 solver.cpp:228] Iteration 33640, loss = 0.00270897
I0317 14:02:25.939760  3513 solver.cpp:244]     Train net output #0: loss = 0.002709 (* 1 = 0.002709 loss)
I0317 14:02:25.939774  3513 sgd_solver.cpp:106] Iteration 33640, lr = 0.01
I0317 14:02:33.246196  3513 solver.cpp:228] Iteration 33660, loss = 0.00303847
I0317 14:02:33.246258  3513 solver.cpp:244]     Train net output #0: loss = 0.0030385 (* 1 = 0.0030385 loss)
I0317 14:02:33.246271  3513 sgd_solver.cpp:106] Iteration 33660, lr = 0.01
I0317 14:02:40.555871  3513 solver.cpp:228] Iteration 33680, loss = 0.00355196
I0317 14:02:40.555934  3513 solver.cpp:244]     Train net output #0: loss = 0.003552 (* 1 = 0.003552 loss)
I0317 14:02:40.555946  3513 sgd_solver.cpp:106] Iteration 33680, lr = 0.01
I0317 14:02:47.863659  3513 solver.cpp:228] Iteration 33700, loss = 0.00369176
I0317 14:02:47.863814  3513 solver.cpp:244]     Train net output #0: loss = 0.0036918 (* 1 = 0.0036918 loss)
I0317 14:02:47.863828  3513 sgd_solver.cpp:106] Iteration 33700, lr = 0.01
I0317 14:02:55.187492  3513 solver.cpp:228] Iteration 33720, loss = 0.00560153
I0317 14:02:55.187561  3513 solver.cpp:244]     Train net output #0: loss = 0.00560157 (* 1 = 0.00560157 loss)
I0317 14:02:55.187573  3513 sgd_solver.cpp:106] Iteration 33720, lr = 0.01
I0317 14:03:02.523195  3513 solver.cpp:228] Iteration 33740, loss = 0.00508586
I0317 14:03:02.523270  3513 solver.cpp:244]     Train net output #0: loss = 0.00508589 (* 1 = 0.00508589 loss)
I0317 14:03:02.523283  3513 sgd_solver.cpp:106] Iteration 33740, lr = 0.01
I0317 14:03:05.821208  3513 solver.cpp:337] Iteration 33750, Testing net (#0)
I0317 14:04:59.710556  3513 solver.cpp:404]     Test net output #0: loss = 0.0602871 (* 1 = 0.0602871 loss)
I0317 14:04:59.710671  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 14:05:03.654727  3513 solver.cpp:228] Iteration 33760, loss = 0.0040048
I0317 14:05:03.654798  3513 solver.cpp:244]     Train net output #0: loss = 0.00400483 (* 1 = 0.00400483 loss)
I0317 14:05:03.654810  3513 sgd_solver.cpp:106] Iteration 33760, lr = 0.01
I0317 14:05:10.912590  3513 solver.cpp:228] Iteration 33780, loss = 0.00599841
I0317 14:05:10.912658  3513 solver.cpp:244]     Train net output #0: loss = 0.00599845 (* 1 = 0.00599845 loss)
I0317 14:05:10.912672  3513 sgd_solver.cpp:106] Iteration 33780, lr = 0.01
I0317 14:05:18.202792  3513 solver.cpp:228] Iteration 33800, loss = 0.00222322
I0317 14:05:18.202859  3513 solver.cpp:244]     Train net output #0: loss = 0.00222325 (* 1 = 0.00222325 loss)
I0317 14:05:18.202872  3513 sgd_solver.cpp:106] Iteration 33800, lr = 0.01
I0317 14:05:25.509456  3513 solver.cpp:228] Iteration 33820, loss = 0.00312302
I0317 14:05:25.509523  3513 solver.cpp:244]     Train net output #0: loss = 0.00312306 (* 1 = 0.00312306 loss)
I0317 14:05:25.509536  3513 sgd_solver.cpp:106] Iteration 33820, lr = 0.01
I0317 14:05:32.826000  3513 solver.cpp:228] Iteration 33840, loss = 0.00510702
I0317 14:05:32.826186  3513 solver.cpp:244]     Train net output #0: loss = 0.00510706 (* 1 = 0.00510706 loss)
I0317 14:05:32.826201  3513 sgd_solver.cpp:106] Iteration 33840, lr = 0.01
I0317 14:05:40.152772  3513 solver.cpp:228] Iteration 33860, loss = 0.00455746
I0317 14:05:40.152843  3513 solver.cpp:244]     Train net output #0: loss = 0.00455749 (* 1 = 0.00455749 loss)
I0317 14:05:40.152856  3513 sgd_solver.cpp:106] Iteration 33860, lr = 0.01
I0317 14:05:47.484757  3513 solver.cpp:228] Iteration 33880, loss = 0.003354
I0317 14:05:47.484822  3513 solver.cpp:244]     Train net output #0: loss = 0.00335403 (* 1 = 0.00335403 loss)
I0317 14:05:47.484835  3513 sgd_solver.cpp:106] Iteration 33880, lr = 0.01
I0317 14:05:54.820415  3513 solver.cpp:228] Iteration 33900, loss = 0.00553804
I0317 14:05:54.820482  3513 solver.cpp:244]     Train net output #0: loss = 0.00553807 (* 1 = 0.00553807 loss)
I0317 14:05:54.820495  3513 sgd_solver.cpp:106] Iteration 33900, lr = 0.01
I0317 14:06:02.161041  3513 solver.cpp:228] Iteration 33920, loss = 0.00326532
I0317 14:06:02.161110  3513 solver.cpp:244]     Train net output #0: loss = 0.00326535 (* 1 = 0.00326535 loss)
I0317 14:06:02.161123  3513 sgd_solver.cpp:106] Iteration 33920, lr = 0.01
I0317 14:06:09.495239  3513 solver.cpp:228] Iteration 33940, loss = 0.00811724
I0317 14:06:09.495384  3513 solver.cpp:244]     Train net output #0: loss = 0.00811727 (* 1 = 0.00811727 loss)
I0317 14:06:09.495398  3513 sgd_solver.cpp:106] Iteration 33940, lr = 0.01
I0317 14:06:16.821738  3513 solver.cpp:228] Iteration 33960, loss = 0.00181495
I0317 14:06:16.821801  3513 solver.cpp:244]     Train net output #0: loss = 0.00181498 (* 1 = 0.00181498 loss)
I0317 14:06:16.821813  3513 sgd_solver.cpp:106] Iteration 33960, lr = 0.01
I0317 14:06:24.147179  3513 solver.cpp:228] Iteration 33980, loss = 0.00277776
I0317 14:06:24.147243  3513 solver.cpp:244]     Train net output #0: loss = 0.0027778 (* 1 = 0.0027778 loss)
I0317 14:06:24.147260  3513 sgd_solver.cpp:106] Iteration 33980, lr = 0.01
I0317 14:06:31.102942  3513 solver.cpp:337] Iteration 34000, Testing net (#0)
I0317 14:08:24.961444  3513 solver.cpp:404]     Test net output #0: loss = 0.0616093 (* 1 = 0.0616093 loss)
I0317 14:08:24.961563  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64416 (* 1 = 0.64416 loss)
I0317 14:08:25.297924  3513 solver.cpp:228] Iteration 34000, loss = 0.0021828
I0317 14:08:25.297987  3513 solver.cpp:244]     Train net output #0: loss = 0.00218283 (* 1 = 0.00218283 loss)
I0317 14:08:25.298001  3513 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I0317 14:08:32.542376  3513 solver.cpp:228] Iteration 34020, loss = 0.00257888
I0317 14:08:32.542446  3513 solver.cpp:244]     Train net output #0: loss = 0.00257892 (* 1 = 0.00257892 loss)
I0317 14:08:32.542459  3513 sgd_solver.cpp:106] Iteration 34020, lr = 0.01
I0317 14:08:39.838490  3513 solver.cpp:228] Iteration 34040, loss = 0.00532718
I0317 14:08:39.838562  3513 solver.cpp:244]     Train net output #0: loss = 0.00532721 (* 1 = 0.00532721 loss)
I0317 14:08:39.838577  3513 sgd_solver.cpp:106] Iteration 34040, lr = 0.01
I0317 14:08:47.161450  3513 solver.cpp:228] Iteration 34060, loss = 0.00308851
I0317 14:08:47.161520  3513 solver.cpp:244]     Train net output #0: loss = 0.00308854 (* 1 = 0.00308854 loss)
I0317 14:08:47.161533  3513 sgd_solver.cpp:106] Iteration 34060, lr = 0.01
I0317 14:08:54.493580  3513 solver.cpp:228] Iteration 34080, loss = 0.00641549
I0317 14:08:54.493657  3513 solver.cpp:244]     Train net output #0: loss = 0.00641552 (* 1 = 0.00641552 loss)
I0317 14:08:54.493670  3513 sgd_solver.cpp:106] Iteration 34080, lr = 0.01
I0317 14:09:01.828167  3513 solver.cpp:228] Iteration 34100, loss = 0.00318844
I0317 14:09:01.828354  3513 solver.cpp:244]     Train net output #0: loss = 0.00318847 (* 1 = 0.00318847 loss)
I0317 14:09:01.828369  3513 sgd_solver.cpp:106] Iteration 34100, lr = 0.01
I0317 14:09:09.167652  3513 solver.cpp:228] Iteration 34120, loss = 0.0044134
I0317 14:09:09.167721  3513 solver.cpp:244]     Train net output #0: loss = 0.00441343 (* 1 = 0.00441343 loss)
I0317 14:09:09.167735  3513 sgd_solver.cpp:106] Iteration 34120, lr = 0.01
I0317 14:09:16.497768  3513 solver.cpp:228] Iteration 34140, loss = 0.00398918
I0317 14:09:16.497834  3513 solver.cpp:244]     Train net output #0: loss = 0.00398921 (* 1 = 0.00398921 loss)
I0317 14:09:16.497848  3513 sgd_solver.cpp:106] Iteration 34140, lr = 0.01
I0317 14:09:23.827069  3513 solver.cpp:228] Iteration 34160, loss = 0.00426008
I0317 14:09:23.827147  3513 solver.cpp:244]     Train net output #0: loss = 0.00426011 (* 1 = 0.00426011 loss)
I0317 14:09:23.827160  3513 sgd_solver.cpp:106] Iteration 34160, lr = 0.01
I0317 14:09:31.156244  3513 solver.cpp:228] Iteration 34180, loss = 0.00303448
I0317 14:09:31.156318  3513 solver.cpp:244]     Train net output #0: loss = 0.00303451 (* 1 = 0.00303451 loss)
I0317 14:09:31.156333  3513 sgd_solver.cpp:106] Iteration 34180, lr = 0.01
I0317 14:09:38.483387  3513 solver.cpp:228] Iteration 34200, loss = 0.0043826
I0317 14:09:38.483533  3513 solver.cpp:244]     Train net output #0: loss = 0.00438263 (* 1 = 0.00438263 loss)
I0317 14:09:38.483547  3513 sgd_solver.cpp:106] Iteration 34200, lr = 0.01
I0317 14:09:45.808382  3513 solver.cpp:228] Iteration 34220, loss = 0.00630338
I0317 14:09:45.808451  3513 solver.cpp:244]     Train net output #0: loss = 0.00630342 (* 1 = 0.00630342 loss)
I0317 14:09:45.808465  3513 sgd_solver.cpp:106] Iteration 34220, lr = 0.01
I0317 14:09:53.131531  3513 solver.cpp:228] Iteration 34240, loss = 0.00334345
I0317 14:09:53.131606  3513 solver.cpp:244]     Train net output #0: loss = 0.00334348 (* 1 = 0.00334348 loss)
I0317 14:09:53.131621  3513 sgd_solver.cpp:106] Iteration 34240, lr = 0.01
I0317 14:09:56.429594  3513 solver.cpp:337] Iteration 34250, Testing net (#0)
I0317 14:11:50.275120  3513 solver.cpp:404]     Test net output #0: loss = 0.0597475 (* 1 = 0.0597475 loss)
I0317 14:11:50.275230  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 14:11:54.216997  3513 solver.cpp:228] Iteration 34260, loss = 0.00635282
I0317 14:11:54.217064  3513 solver.cpp:244]     Train net output #0: loss = 0.00635286 (* 1 = 0.00635286 loss)
I0317 14:11:54.217077  3513 sgd_solver.cpp:106] Iteration 34260, lr = 0.01
I0317 14:12:01.471194  3513 solver.cpp:228] Iteration 34280, loss = 0.00533698
I0317 14:12:01.471264  3513 solver.cpp:244]     Train net output #0: loss = 0.00533702 (* 1 = 0.00533702 loss)
I0317 14:12:01.471277  3513 sgd_solver.cpp:106] Iteration 34280, lr = 0.01
I0317 14:12:08.775924  3513 solver.cpp:228] Iteration 34300, loss = 0.00684526
I0317 14:12:08.775991  3513 solver.cpp:244]     Train net output #0: loss = 0.00684529 (* 1 = 0.00684529 loss)
I0317 14:12:08.776005  3513 sgd_solver.cpp:106] Iteration 34300, lr = 0.01
I0317 14:12:16.097283  3513 solver.cpp:228] Iteration 34320, loss = 0.00299686
I0317 14:12:16.097347  3513 solver.cpp:244]     Train net output #0: loss = 0.00299689 (* 1 = 0.00299689 loss)
I0317 14:12:16.097360  3513 sgd_solver.cpp:106] Iteration 34320, lr = 0.01
I0317 14:12:23.422740  3513 solver.cpp:228] Iteration 34340, loss = 0.00159035
I0317 14:12:23.422883  3513 solver.cpp:244]     Train net output #0: loss = 0.00159038 (* 1 = 0.00159038 loss)
I0317 14:12:23.422896  3513 sgd_solver.cpp:106] Iteration 34340, lr = 0.01
I0317 14:12:30.754287  3513 solver.cpp:228] Iteration 34360, loss = 0.00206746
I0317 14:12:30.754350  3513 solver.cpp:244]     Train net output #0: loss = 0.0020675 (* 1 = 0.0020675 loss)
I0317 14:12:30.754362  3513 sgd_solver.cpp:106] Iteration 34360, lr = 0.01
I0317 14:12:38.093093  3513 solver.cpp:228] Iteration 34380, loss = 0.00233935
I0317 14:12:38.093166  3513 solver.cpp:244]     Train net output #0: loss = 0.00233939 (* 1 = 0.00233939 loss)
I0317 14:12:38.093181  3513 sgd_solver.cpp:106] Iteration 34380, lr = 0.01
I0317 14:12:45.425120  3513 solver.cpp:228] Iteration 34400, loss = 0.00377165
I0317 14:12:45.425199  3513 solver.cpp:244]     Train net output #0: loss = 0.00377168 (* 1 = 0.00377168 loss)
I0317 14:12:45.425211  3513 sgd_solver.cpp:106] Iteration 34400, lr = 0.01
I0317 14:12:52.750047  3513 solver.cpp:228] Iteration 34420, loss = 0.00357647
I0317 14:12:52.750115  3513 solver.cpp:244]     Train net output #0: loss = 0.0035765 (* 1 = 0.0035765 loss)
I0317 14:12:52.750131  3513 sgd_solver.cpp:106] Iteration 34420, lr = 0.01
I0317 14:13:00.076979  3513 solver.cpp:228] Iteration 34440, loss = 0.00833034
I0317 14:13:00.077167  3513 solver.cpp:244]     Train net output #0: loss = 0.00833037 (* 1 = 0.00833037 loss)
I0317 14:13:00.077183  3513 sgd_solver.cpp:106] Iteration 34440, lr = 0.01
I0317 14:13:07.404451  3513 solver.cpp:228] Iteration 34460, loss = 0.00408406
I0317 14:13:07.404517  3513 solver.cpp:244]     Train net output #0: loss = 0.00408409 (* 1 = 0.00408409 loss)
I0317 14:13:07.404531  3513 sgd_solver.cpp:106] Iteration 34460, lr = 0.01
I0317 14:13:14.727306  3513 solver.cpp:228] Iteration 34480, loss = 0.00483115
I0317 14:13:14.727378  3513 solver.cpp:244]     Train net output #0: loss = 0.00483118 (* 1 = 0.00483118 loss)
I0317 14:13:14.727392  3513 sgd_solver.cpp:106] Iteration 34480, lr = 0.01
I0317 14:13:21.679873  3513 solver.cpp:337] Iteration 34500, Testing net (#0)
I0317 14:15:15.560786  3513 solver.cpp:404]     Test net output #0: loss = 0.0605885 (* 1 = 0.0605885 loss)
I0317 14:15:15.560909  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64424 (* 1 = 0.64424 loss)
I0317 14:15:15.897820  3513 solver.cpp:228] Iteration 34500, loss = 0.00192547
I0317 14:15:15.897888  3513 solver.cpp:244]     Train net output #0: loss = 0.00192551 (* 1 = 0.00192551 loss)
I0317 14:15:15.897902  3513 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I0317 14:15:23.146436  3513 solver.cpp:228] Iteration 34520, loss = 0.0045276
I0317 14:15:23.146507  3513 solver.cpp:244]     Train net output #0: loss = 0.00452763 (* 1 = 0.00452763 loss)
I0317 14:15:23.146519  3513 sgd_solver.cpp:106] Iteration 34520, lr = 0.01
I0317 14:15:30.440237  3513 solver.cpp:228] Iteration 34540, loss = 0.00372999
I0317 14:15:30.440304  3513 solver.cpp:244]     Train net output #0: loss = 0.00373002 (* 1 = 0.00373002 loss)
I0317 14:15:30.440316  3513 sgd_solver.cpp:106] Iteration 34540, lr = 0.01
I0317 14:15:37.764731  3513 solver.cpp:228] Iteration 34560, loss = 0.00241731
I0317 14:15:37.764793  3513 solver.cpp:244]     Train net output #0: loss = 0.00241734 (* 1 = 0.00241734 loss)
I0317 14:15:37.764806  3513 sgd_solver.cpp:106] Iteration 34560, lr = 0.01
I0317 14:15:45.097332  3513 solver.cpp:228] Iteration 34580, loss = 0.00419192
I0317 14:15:45.097399  3513 solver.cpp:244]     Train net output #0: loss = 0.00419195 (* 1 = 0.00419195 loss)
I0317 14:15:45.097412  3513 sgd_solver.cpp:106] Iteration 34580, lr = 0.01
I0317 14:15:52.429247  3513 solver.cpp:228] Iteration 34600, loss = 0.00239496
I0317 14:15:52.429383  3513 solver.cpp:244]     Train net output #0: loss = 0.00239499 (* 1 = 0.00239499 loss)
I0317 14:15:52.429397  3513 sgd_solver.cpp:106] Iteration 34600, lr = 0.01
I0317 14:15:59.753419  3513 solver.cpp:228] Iteration 34620, loss = 0.00833624
I0317 14:15:59.753487  3513 solver.cpp:244]     Train net output #0: loss = 0.00833628 (* 1 = 0.00833628 loss)
I0317 14:15:59.753500  3513 sgd_solver.cpp:106] Iteration 34620, lr = 0.01
I0317 14:16:07.065497  3513 solver.cpp:228] Iteration 34640, loss = 0.00504593
I0317 14:16:07.065567  3513 solver.cpp:244]     Train net output #0: loss = 0.00504596 (* 1 = 0.00504596 loss)
I0317 14:16:07.065579  3513 sgd_solver.cpp:106] Iteration 34640, lr = 0.01
I0317 14:16:14.388023  3513 solver.cpp:228] Iteration 34660, loss = 0.00465847
I0317 14:16:14.388092  3513 solver.cpp:244]     Train net output #0: loss = 0.0046585 (* 1 = 0.0046585 loss)
I0317 14:16:14.388104  3513 sgd_solver.cpp:106] Iteration 34660, lr = 0.01
I0317 14:16:21.710650  3513 solver.cpp:228] Iteration 34680, loss = 0.00204454
I0317 14:16:21.710717  3513 solver.cpp:244]     Train net output #0: loss = 0.00204457 (* 1 = 0.00204457 loss)
I0317 14:16:21.710731  3513 sgd_solver.cpp:106] Iteration 34680, lr = 0.01
I0317 14:16:29.029796  3513 solver.cpp:228] Iteration 34700, loss = 0.00600643
I0317 14:16:29.029992  3513 solver.cpp:244]     Train net output #0: loss = 0.00600646 (* 1 = 0.00600646 loss)
I0317 14:16:29.030015  3513 sgd_solver.cpp:106] Iteration 34700, lr = 0.01
I0317 14:16:36.357707  3513 solver.cpp:228] Iteration 34720, loss = 0.0039453
I0317 14:16:36.357782  3513 solver.cpp:244]     Train net output #0: loss = 0.00394533 (* 1 = 0.00394533 loss)
I0317 14:16:36.357797  3513 sgd_solver.cpp:106] Iteration 34720, lr = 0.01
I0317 14:16:43.677199  3513 solver.cpp:228] Iteration 34740, loss = 0.00444504
I0317 14:16:43.677263  3513 solver.cpp:244]     Train net output #0: loss = 0.00444507 (* 1 = 0.00444507 loss)
I0317 14:16:43.677276  3513 sgd_solver.cpp:106] Iteration 34740, lr = 0.01
I0317 14:16:46.972527  3513 solver.cpp:337] Iteration 34750, Testing net (#0)
I0317 14:18:40.820617  3513 solver.cpp:404]     Test net output #0: loss = 0.0567711 (* 1 = 0.0567711 loss)
I0317 14:18:40.820731  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65376 (* 1 = 0.65376 loss)
I0317 14:18:44.781265  3513 solver.cpp:228] Iteration 34760, loss = 0.00449911
I0317 14:18:44.781332  3513 solver.cpp:244]     Train net output #0: loss = 0.00449914 (* 1 = 0.00449914 loss)
I0317 14:18:44.781345  3513 sgd_solver.cpp:106] Iteration 34760, lr = 0.01
I0317 14:18:52.058496  3513 solver.cpp:228] Iteration 34780, loss = 0.00368028
I0317 14:18:52.058562  3513 solver.cpp:244]     Train net output #0: loss = 0.00368032 (* 1 = 0.00368032 loss)
I0317 14:18:52.058575  3513 sgd_solver.cpp:106] Iteration 34780, lr = 0.01
I0317 14:18:59.367816  3513 solver.cpp:228] Iteration 34800, loss = 0.00731726
I0317 14:18:59.367877  3513 solver.cpp:244]     Train net output #0: loss = 0.00731729 (* 1 = 0.00731729 loss)
I0317 14:18:59.367890  3513 sgd_solver.cpp:106] Iteration 34800, lr = 0.01
I0317 14:19:06.698724  3513 solver.cpp:228] Iteration 34820, loss = 0.00671736
I0317 14:19:06.698791  3513 solver.cpp:244]     Train net output #0: loss = 0.00671739 (* 1 = 0.00671739 loss)
I0317 14:19:06.698803  3513 sgd_solver.cpp:106] Iteration 34820, lr = 0.01
I0317 14:19:14.035199  3513 solver.cpp:228] Iteration 34840, loss = 0.00678113
I0317 14:19:14.035343  3513 solver.cpp:244]     Train net output #0: loss = 0.00678117 (* 1 = 0.00678117 loss)
I0317 14:19:14.035357  3513 sgd_solver.cpp:106] Iteration 34840, lr = 0.01
I0317 14:19:21.362802  3513 solver.cpp:228] Iteration 34860, loss = 0.00442365
I0317 14:19:21.362866  3513 solver.cpp:244]     Train net output #0: loss = 0.00442369 (* 1 = 0.00442369 loss)
I0317 14:19:21.362879  3513 sgd_solver.cpp:106] Iteration 34860, lr = 0.01
I0317 14:19:28.695291  3513 solver.cpp:228] Iteration 34880, loss = 0.00240556
I0317 14:19:28.695359  3513 solver.cpp:244]     Train net output #0: loss = 0.0024056 (* 1 = 0.0024056 loss)
I0317 14:19:28.695372  3513 sgd_solver.cpp:106] Iteration 34880, lr = 0.01
I0317 14:19:36.022092  3513 solver.cpp:228] Iteration 34900, loss = 0.00290993
I0317 14:19:36.022156  3513 solver.cpp:244]     Train net output #0: loss = 0.00290996 (* 1 = 0.00290996 loss)
I0317 14:19:36.022168  3513 sgd_solver.cpp:106] Iteration 34900, lr = 0.01
I0317 14:19:43.349514  3513 solver.cpp:228] Iteration 34920, loss = 0.00286939
I0317 14:19:43.349576  3513 solver.cpp:244]     Train net output #0: loss = 0.00286942 (* 1 = 0.00286942 loss)
I0317 14:19:43.349589  3513 sgd_solver.cpp:106] Iteration 34920, lr = 0.01
I0317 14:19:50.682126  3513 solver.cpp:228] Iteration 34940, loss = 0.00455914
I0317 14:19:50.682263  3513 solver.cpp:244]     Train net output #0: loss = 0.00455917 (* 1 = 0.00455917 loss)
I0317 14:19:50.682277  3513 sgd_solver.cpp:106] Iteration 34940, lr = 0.01
I0317 14:19:58.008184  3513 solver.cpp:228] Iteration 34960, loss = 0.00271718
I0317 14:19:58.008249  3513 solver.cpp:244]     Train net output #0: loss = 0.00271721 (* 1 = 0.00271721 loss)
I0317 14:19:58.008261  3513 sgd_solver.cpp:106] Iteration 34960, lr = 0.01
I0317 14:20:05.331146  3513 solver.cpp:228] Iteration 34980, loss = 0.00666398
I0317 14:20:05.331214  3513 solver.cpp:244]     Train net output #0: loss = 0.00666401 (* 1 = 0.00666401 loss)
I0317 14:20:05.331228  3513 sgd_solver.cpp:106] Iteration 34980, lr = 0.01
I0317 14:20:12.287719  3513 solver.cpp:454] Snapshotting to binary proto file ./caffe_alexnet_train_iter_35000.caffemodel
I0317 14:20:13.953470  3513 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./caffe_alexnet_train_iter_35000.solverstate
I0317 14:20:14.362417  3513 solver.cpp:337] Iteration 35000, Testing net (#0)
I0317 14:22:08.172102  3513 solver.cpp:404]     Test net output #0: loss = 0.0650454 (* 1 = 0.0650454 loss)
I0317 14:22:08.172241  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6636 (* 1 = 0.6636 loss)
I0317 14:22:08.507902  3513 solver.cpp:228] Iteration 35000, loss = 0.00459962
I0317 14:22:08.507966  3513 solver.cpp:244]     Train net output #0: loss = 0.00459966 (* 1 = 0.00459966 loss)
I0317 14:22:08.507978  3513 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I0317 14:22:15.744726  3513 solver.cpp:228] Iteration 35020, loss = 0.00315242
I0317 14:22:15.744804  3513 solver.cpp:244]     Train net output #0: loss = 0.00315246 (* 1 = 0.00315246 loss)
I0317 14:22:15.744817  3513 sgd_solver.cpp:106] Iteration 35020, lr = 0.01
I0317 14:22:23.027976  3513 solver.cpp:228] Iteration 35040, loss = 0.00273168
I0317 14:22:23.028046  3513 solver.cpp:244]     Train net output #0: loss = 0.00273171 (* 1 = 0.00273171 loss)
I0317 14:22:23.028059  3513 sgd_solver.cpp:106] Iteration 35040, lr = 0.01
I0317 14:22:30.336568  3513 solver.cpp:228] Iteration 35060, loss = 0.00248941
I0317 14:22:30.336633  3513 solver.cpp:244]     Train net output #0: loss = 0.00248945 (* 1 = 0.00248945 loss)
I0317 14:22:30.336645  3513 sgd_solver.cpp:106] Iteration 35060, lr = 0.01
I0317 14:22:37.654641  3513 solver.cpp:228] Iteration 35080, loss = 0.00278095
I0317 14:22:37.654711  3513 solver.cpp:244]     Train net output #0: loss = 0.00278098 (* 1 = 0.00278098 loss)
I0317 14:22:37.654722  3513 sgd_solver.cpp:106] Iteration 35080, lr = 0.01
I0317 14:22:44.985963  3513 solver.cpp:228] Iteration 35100, loss = 0.00302139
I0317 14:22:44.986114  3513 solver.cpp:244]     Train net output #0: loss = 0.00302143 (* 1 = 0.00302143 loss)
I0317 14:22:44.986127  3513 sgd_solver.cpp:106] Iteration 35100, lr = 0.01
I0317 14:22:52.309856  3513 solver.cpp:228] Iteration 35120, loss = 0.0053754
I0317 14:22:52.309926  3513 solver.cpp:244]     Train net output #0: loss = 0.00537543 (* 1 = 0.00537543 loss)
I0317 14:22:52.309939  3513 sgd_solver.cpp:106] Iteration 35120, lr = 0.01
I0317 14:22:59.643824  3513 solver.cpp:228] Iteration 35140, loss = 0.00158761
I0317 14:22:59.643892  3513 solver.cpp:244]     Train net output #0: loss = 0.00158764 (* 1 = 0.00158764 loss)
I0317 14:22:59.643904  3513 sgd_solver.cpp:106] Iteration 35140, lr = 0.01
I0317 14:23:06.973147  3513 solver.cpp:228] Iteration 35160, loss = 0.00561576
I0317 14:23:06.973225  3513 solver.cpp:244]     Train net output #0: loss = 0.0056158 (* 1 = 0.0056158 loss)
I0317 14:23:06.973238  3513 sgd_solver.cpp:106] Iteration 35160, lr = 0.01
I0317 14:23:14.301048  3513 solver.cpp:228] Iteration 35180, loss = 0.00576149
I0317 14:23:14.301112  3513 solver.cpp:244]     Train net output #0: loss = 0.00576153 (* 1 = 0.00576153 loss)
I0317 14:23:14.301126  3513 sgd_solver.cpp:106] Iteration 35180, lr = 0.01
I0317 14:23:21.633131  3513 solver.cpp:228] Iteration 35200, loss = 0.00634904
I0317 14:23:21.633301  3513 solver.cpp:244]     Train net output #0: loss = 0.00634908 (* 1 = 0.00634908 loss)
I0317 14:23:21.633316  3513 sgd_solver.cpp:106] Iteration 35200, lr = 0.01
I0317 14:23:28.966246  3513 solver.cpp:228] Iteration 35220, loss = 0.00142125
I0317 14:23:28.966312  3513 solver.cpp:244]     Train net output #0: loss = 0.00142129 (* 1 = 0.00142129 loss)
I0317 14:23:28.966325  3513 sgd_solver.cpp:106] Iteration 35220, lr = 0.01
I0317 14:23:36.291797  3513 solver.cpp:228] Iteration 35240, loss = 0.00271613
I0317 14:23:36.291868  3513 solver.cpp:244]     Train net output #0: loss = 0.00271617 (* 1 = 0.00271617 loss)
I0317 14:23:36.291882  3513 sgd_solver.cpp:106] Iteration 35240, lr = 0.01
I0317 14:23:39.589009  3513 solver.cpp:337] Iteration 35250, Testing net (#0)
I0317 14:25:33.466747  3513 solver.cpp:404]     Test net output #0: loss = 0.0594522 (* 1 = 0.0594522 loss)
I0317 14:25:33.466919  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6538 (* 1 = 0.6538 loss)
I0317 14:25:37.411351  3513 solver.cpp:228] Iteration 35260, loss = 0.00196091
I0317 14:25:37.411423  3513 solver.cpp:244]     Train net output #0: loss = 0.00196095 (* 1 = 0.00196095 loss)
I0317 14:25:37.411437  3513 sgd_solver.cpp:106] Iteration 35260, lr = 0.01
I0317 14:25:44.680619  3513 solver.cpp:228] Iteration 35280, loss = 0.00296385
I0317 14:25:44.680682  3513 solver.cpp:244]     Train net output #0: loss = 0.00296388 (* 1 = 0.00296388 loss)
I0317 14:25:44.680696  3513 sgd_solver.cpp:106] Iteration 35280, lr = 0.01
I0317 14:25:51.983026  3513 solver.cpp:228] Iteration 35300, loss = 0.00625871
I0317 14:25:51.983110  3513 solver.cpp:244]     Train net output #0: loss = 0.00625874 (* 1 = 0.00625874 loss)
I0317 14:25:51.983124  3513 sgd_solver.cpp:106] Iteration 35300, lr = 0.01
I0317 14:25:59.296857  3513 solver.cpp:228] Iteration 35320, loss = 0.00334569
I0317 14:25:59.296921  3513 solver.cpp:244]     Train net output #0: loss = 0.00334572 (* 1 = 0.00334572 loss)
I0317 14:25:59.296933  3513 sgd_solver.cpp:106] Iteration 35320, lr = 0.01
I0317 14:26:06.625922  3513 solver.cpp:228] Iteration 35340, loss = 0.00665216
I0317 14:26:06.626078  3513 solver.cpp:244]     Train net output #0: loss = 0.00665219 (* 1 = 0.00665219 loss)
I0317 14:26:06.626092  3513 sgd_solver.cpp:106] Iteration 35340, lr = 0.01
I0317 14:26:13.949813  3513 solver.cpp:228] Iteration 35360, loss = 0.00740591
I0317 14:26:13.949883  3513 solver.cpp:244]     Train net output #0: loss = 0.00740594 (* 1 = 0.00740594 loss)
I0317 14:26:13.949898  3513 sgd_solver.cpp:106] Iteration 35360, lr = 0.01
I0317 14:26:21.271196  3513 solver.cpp:228] Iteration 35380, loss = 0.00382216
I0317 14:26:21.271266  3513 solver.cpp:244]     Train net output #0: loss = 0.0038222 (* 1 = 0.0038222 loss)
I0317 14:26:21.271280  3513 sgd_solver.cpp:106] Iteration 35380, lr = 0.01
I0317 14:26:28.600080  3513 solver.cpp:228] Iteration 35400, loss = 0.00428858
I0317 14:26:28.600148  3513 solver.cpp:244]     Train net output #0: loss = 0.00428861 (* 1 = 0.00428861 loss)
I0317 14:26:28.600162  3513 sgd_solver.cpp:106] Iteration 35400, lr = 0.01
I0317 14:26:35.922672  3513 solver.cpp:228] Iteration 35420, loss = 0.00323628
I0317 14:26:35.922740  3513 solver.cpp:244]     Train net output #0: loss = 0.00323632 (* 1 = 0.00323632 loss)
I0317 14:26:35.922754  3513 sgd_solver.cpp:106] Iteration 35420, lr = 0.01
I0317 14:26:43.253314  3513 solver.cpp:228] Iteration 35440, loss = 0.00436225
I0317 14:26:43.253456  3513 solver.cpp:244]     Train net output #0: loss = 0.00436229 (* 1 = 0.00436229 loss)
I0317 14:26:43.253470  3513 sgd_solver.cpp:106] Iteration 35440, lr = 0.01
I0317 14:26:50.579790  3513 solver.cpp:228] Iteration 35460, loss = 0.00210876
I0317 14:26:50.579869  3513 solver.cpp:244]     Train net output #0: loss = 0.00210879 (* 1 = 0.00210879 loss)
I0317 14:26:50.579882  3513 sgd_solver.cpp:106] Iteration 35460, lr = 0.01
I0317 14:26:57.910893  3513 solver.cpp:228] Iteration 35480, loss = 0.00382504
I0317 14:26:57.910962  3513 solver.cpp:244]     Train net output #0: loss = 0.00382507 (* 1 = 0.00382507 loss)
I0317 14:26:57.910975  3513 sgd_solver.cpp:106] Iteration 35480, lr = 0.01
I0317 14:27:04.872283  3513 solver.cpp:337] Iteration 35500, Testing net (#0)
I0317 14:28:58.762073  3513 solver.cpp:404]     Test net output #0: loss = 0.0608216 (* 1 = 0.0608216 loss)
I0317 14:28:58.762251  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673079 (* 1 = 0.673079 loss)
I0317 14:28:59.098671  3513 solver.cpp:228] Iteration 35500, loss = 0.00333944
I0317 14:28:59.098734  3513 solver.cpp:244]     Train net output #0: loss = 0.00333948 (* 1 = 0.00333948 loss)
I0317 14:28:59.098748  3513 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I0317 14:29:06.337131  3513 solver.cpp:228] Iteration 35520, loss = 0.00611822
I0317 14:29:06.337211  3513 solver.cpp:244]     Train net output #0: loss = 0.00611826 (* 1 = 0.00611826 loss)
I0317 14:29:06.337225  3513 sgd_solver.cpp:106] Iteration 35520, lr = 0.01
I0317 14:29:13.630996  3513 solver.cpp:228] Iteration 35540, loss = 0.00370157
I0317 14:29:13.631063  3513 solver.cpp:244]     Train net output #0: loss = 0.0037016 (* 1 = 0.0037016 loss)
I0317 14:29:13.631077  3513 sgd_solver.cpp:106] Iteration 35540, lr = 0.01
I0317 14:29:20.952144  3513 solver.cpp:228] Iteration 35560, loss = 0.00385263
I0317 14:29:20.952215  3513 solver.cpp:244]     Train net output #0: loss = 0.00385266 (* 1 = 0.00385266 loss)
I0317 14:29:20.952229  3513 sgd_solver.cpp:106] Iteration 35560, lr = 0.01
I0317 14:29:28.273234  3513 solver.cpp:228] Iteration 35580, loss = 0.00249684
I0317 14:29:28.273299  3513 solver.cpp:244]     Train net output #0: loss = 0.00249688 (* 1 = 0.00249688 loss)
I0317 14:29:28.273313  3513 sgd_solver.cpp:106] Iteration 35580, lr = 0.01
I0317 14:29:35.596407  3513 solver.cpp:228] Iteration 35600, loss = 0.00228096
I0317 14:29:35.596595  3513 solver.cpp:244]     Train net output #0: loss = 0.002281 (* 1 = 0.002281 loss)
I0317 14:29:35.596611  3513 sgd_solver.cpp:106] Iteration 35600, lr = 0.01
I0317 14:29:42.928781  3513 solver.cpp:228] Iteration 35620, loss = 0.00294555
I0317 14:29:42.928850  3513 solver.cpp:244]     Train net output #0: loss = 0.00294558 (* 1 = 0.00294558 loss)
I0317 14:29:42.928864  3513 sgd_solver.cpp:106] Iteration 35620, lr = 0.01
I0317 14:29:50.258334  3513 solver.cpp:228] Iteration 35640, loss = 0.00348851
I0317 14:29:50.258407  3513 solver.cpp:244]     Train net output #0: loss = 0.00348855 (* 1 = 0.00348855 loss)
I0317 14:29:50.258420  3513 sgd_solver.cpp:106] Iteration 35640, lr = 0.01
I0317 14:29:57.592099  3513 solver.cpp:228] Iteration 35660, loss = 0.00447851
I0317 14:29:57.592164  3513 solver.cpp:244]     Train net output #0: loss = 0.00447854 (* 1 = 0.00447854 loss)
I0317 14:29:57.592176  3513 sgd_solver.cpp:106] Iteration 35660, lr = 0.01
I0317 14:30:04.915091  3513 solver.cpp:228] Iteration 35680, loss = 0.00311024
I0317 14:30:04.915158  3513 solver.cpp:244]     Train net output #0: loss = 0.00311028 (* 1 = 0.00311028 loss)
I0317 14:30:04.915171  3513 sgd_solver.cpp:106] Iteration 35680, lr = 0.01
I0317 14:30:12.236980  3513 solver.cpp:228] Iteration 35700, loss = 0.00604392
I0317 14:30:12.237141  3513 solver.cpp:244]     Train net output #0: loss = 0.00604395 (* 1 = 0.00604395 loss)
I0317 14:30:12.237155  3513 sgd_solver.cpp:106] Iteration 35700, lr = 0.01
I0317 14:30:19.558151  3513 solver.cpp:228] Iteration 35720, loss = 0.00450765
I0317 14:30:19.558219  3513 solver.cpp:244]     Train net output #0: loss = 0.00450769 (* 1 = 0.00450769 loss)
I0317 14:30:19.558233  3513 sgd_solver.cpp:106] Iteration 35720, lr = 0.01
I0317 14:30:26.884367  3513 solver.cpp:228] Iteration 35740, loss = 0.00387405
I0317 14:30:26.884429  3513 solver.cpp:244]     Train net output #0: loss = 0.00387408 (* 1 = 0.00387408 loss)
I0317 14:30:26.884441  3513 sgd_solver.cpp:106] Iteration 35740, lr = 0.01
I0317 14:30:30.179697  3513 solver.cpp:337] Iteration 35750, Testing net (#0)
I0317 14:32:24.054044  3513 solver.cpp:404]     Test net output #0: loss = 0.0577255 (* 1 = 0.0577255 loss)
I0317 14:32:24.054177  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.66352 (* 1 = 0.66352 loss)
I0317 14:32:28.002804  3513 solver.cpp:228] Iteration 35760, loss = 0.00305771
I0317 14:32:28.002873  3513 solver.cpp:244]     Train net output #0: loss = 0.00305775 (* 1 = 0.00305775 loss)
I0317 14:32:28.002887  3513 sgd_solver.cpp:106] Iteration 35760, lr = 0.01
I0317 14:32:35.261627  3513 solver.cpp:228] Iteration 35780, loss = 0.00269687
I0317 14:32:35.261696  3513 solver.cpp:244]     Train net output #0: loss = 0.00269691 (* 1 = 0.00269691 loss)
I0317 14:32:35.261710  3513 sgd_solver.cpp:106] Iteration 35780, lr = 0.01
I0317 14:32:42.574614  3513 solver.cpp:228] Iteration 35800, loss = 0.00239079
I0317 14:32:42.574681  3513 solver.cpp:244]     Train net output #0: loss = 0.00239082 (* 1 = 0.00239082 loss)
I0317 14:32:42.574694  3513 sgd_solver.cpp:106] Iteration 35800, lr = 0.01
I0317 14:32:49.891149  3513 solver.cpp:228] Iteration 35820, loss = 0.00273298
I0317 14:32:49.891217  3513 solver.cpp:244]     Train net output #0: loss = 0.00273301 (* 1 = 0.00273301 loss)
I0317 14:32:49.891230  3513 sgd_solver.cpp:106] Iteration 35820, lr = 0.01
I0317 14:32:57.212285  3513 solver.cpp:228] Iteration 35840, loss = 0.00372506
I0317 14:32:57.212488  3513 solver.cpp:244]     Train net output #0: loss = 0.0037251 (* 1 = 0.0037251 loss)
I0317 14:32:57.212502  3513 sgd_solver.cpp:106] Iteration 35840, lr = 0.01
I0317 14:33:04.532091  3513 solver.cpp:228] Iteration 35860, loss = 0.00426092
I0317 14:33:04.532160  3513 solver.cpp:244]     Train net output #0: loss = 0.00426095 (* 1 = 0.00426095 loss)
I0317 14:33:04.532172  3513 sgd_solver.cpp:106] Iteration 35860, lr = 0.01
I0317 14:33:11.856472  3513 solver.cpp:228] Iteration 35880, loss = 0.00334793
I0317 14:33:11.856540  3513 solver.cpp:244]     Train net output #0: loss = 0.00334797 (* 1 = 0.00334797 loss)
I0317 14:33:11.856554  3513 sgd_solver.cpp:106] Iteration 35880, lr = 0.01
I0317 14:33:19.195130  3513 solver.cpp:228] Iteration 35900, loss = 0.00554261
I0317 14:33:19.195194  3513 solver.cpp:244]     Train net output #0: loss = 0.00554264 (* 1 = 0.00554264 loss)
I0317 14:33:19.195209  3513 sgd_solver.cpp:106] Iteration 35900, lr = 0.01
I0317 14:33:26.522521  3513 solver.cpp:228] Iteration 35920, loss = 0.0073973
I0317 14:33:26.522600  3513 solver.cpp:244]     Train net output #0: loss = 0.00739733 (* 1 = 0.00739733 loss)
I0317 14:33:26.522614  3513 sgd_solver.cpp:106] Iteration 35920, lr = 0.01
I0317 14:33:33.845098  3513 solver.cpp:228] Iteration 35940, loss = 0.00488393
I0317 14:33:33.845280  3513 solver.cpp:244]     Train net output #0: loss = 0.00488397 (* 1 = 0.00488397 loss)
I0317 14:33:33.845294  3513 sgd_solver.cpp:106] Iteration 35940, lr = 0.01
I0317 14:33:41.169435  3513 solver.cpp:228] Iteration 35960, loss = 0.00101156
I0317 14:33:41.169502  3513 solver.cpp:244]     Train net output #0: loss = 0.00101159 (* 1 = 0.00101159 loss)
I0317 14:33:41.169515  3513 sgd_solver.cpp:106] Iteration 35960, lr = 0.01
I0317 14:33:48.493530  3513 solver.cpp:228] Iteration 35980, loss = 0.00588089
I0317 14:33:48.493598  3513 solver.cpp:244]     Train net output #0: loss = 0.00588092 (* 1 = 0.00588092 loss)
I0317 14:33:48.493612  3513 sgd_solver.cpp:106] Iteration 35980, lr = 0.01
I0317 14:33:55.450206  3513 solver.cpp:337] Iteration 36000, Testing net (#0)
I0317 14:35:49.299935  3513 solver.cpp:404]     Test net output #0: loss = 0.0590285 (* 1 = 0.0590285 loss)
I0317 14:35:49.300051  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65376 (* 1 = 0.65376 loss)
I0317 14:35:49.635648  3513 solver.cpp:228] Iteration 36000, loss = 0.00359694
I0317 14:35:49.635713  3513 solver.cpp:244]     Train net output #0: loss = 0.00359698 (* 1 = 0.00359698 loss)
I0317 14:35:49.635726  3513 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I0317 14:35:56.876824  3513 solver.cpp:228] Iteration 36020, loss = 0.00464729
I0317 14:35:56.876891  3513 solver.cpp:244]     Train net output #0: loss = 0.00464733 (* 1 = 0.00464733 loss)
I0317 14:35:56.876904  3513 sgd_solver.cpp:106] Iteration 36020, lr = 0.01
I0317 14:36:04.172924  3513 solver.cpp:228] Iteration 36040, loss = 0.00606258
I0317 14:36:04.172992  3513 solver.cpp:244]     Train net output #0: loss = 0.00606262 (* 1 = 0.00606262 loss)
I0317 14:36:04.173005  3513 sgd_solver.cpp:106] Iteration 36040, lr = 0.01
I0317 14:36:11.495121  3513 solver.cpp:228] Iteration 36060, loss = 0.00516236
I0317 14:36:11.495188  3513 solver.cpp:244]     Train net output #0: loss = 0.00516239 (* 1 = 0.00516239 loss)
I0317 14:36:11.495201  3513 sgd_solver.cpp:106] Iteration 36060, lr = 0.01
I0317 14:36:18.824698  3513 solver.cpp:228] Iteration 36080, loss = 0.00369647
I0317 14:36:18.824762  3513 solver.cpp:244]     Train net output #0: loss = 0.00369651 (* 1 = 0.00369651 loss)
I0317 14:36:18.824775  3513 sgd_solver.cpp:106] Iteration 36080, lr = 0.01
I0317 14:36:26.156699  3513 solver.cpp:228] Iteration 36100, loss = 0.00715405
I0317 14:36:26.156872  3513 solver.cpp:244]     Train net output #0: loss = 0.00715408 (* 1 = 0.00715408 loss)
I0317 14:36:26.156886  3513 sgd_solver.cpp:106] Iteration 36100, lr = 0.01
I0317 14:36:33.488773  3513 solver.cpp:228] Iteration 36120, loss = 0.00253633
I0317 14:36:33.488837  3513 solver.cpp:244]     Train net output #0: loss = 0.00253636 (* 1 = 0.00253636 loss)
I0317 14:36:33.488849  3513 sgd_solver.cpp:106] Iteration 36120, lr = 0.01
I0317 14:36:40.815230  3513 solver.cpp:228] Iteration 36140, loss = 0.00255264
I0317 14:36:40.815296  3513 solver.cpp:244]     Train net output #0: loss = 0.00255268 (* 1 = 0.00255268 loss)
I0317 14:36:40.815310  3513 sgd_solver.cpp:106] Iteration 36140, lr = 0.01
I0317 14:36:48.141070  3513 solver.cpp:228] Iteration 36160, loss = 0.0017987
I0317 14:36:48.141136  3513 solver.cpp:244]     Train net output #0: loss = 0.00179873 (* 1 = 0.00179873 loss)
I0317 14:36:48.141149  3513 sgd_solver.cpp:106] Iteration 36160, lr = 0.01
I0317 14:36:55.474967  3513 solver.cpp:228] Iteration 36180, loss = 0.00281975
I0317 14:36:55.475035  3513 solver.cpp:244]     Train net output #0: loss = 0.00281979 (* 1 = 0.00281979 loss)
I0317 14:36:55.475049  3513 sgd_solver.cpp:106] Iteration 36180, lr = 0.01
I0317 14:37:02.804193  3513 solver.cpp:228] Iteration 36200, loss = 0.00586644
I0317 14:37:02.804352  3513 solver.cpp:244]     Train net output #0: loss = 0.00586648 (* 1 = 0.00586648 loss)
I0317 14:37:02.804365  3513 sgd_solver.cpp:106] Iteration 36200, lr = 0.01
I0317 14:37:10.130079  3513 solver.cpp:228] Iteration 36220, loss = 0.0045705
I0317 14:37:10.130156  3513 solver.cpp:244]     Train net output #0: loss = 0.00457053 (* 1 = 0.00457053 loss)
I0317 14:37:10.130168  3513 sgd_solver.cpp:106] Iteration 36220, lr = 0.01
I0317 14:37:17.459025  3513 solver.cpp:228] Iteration 36240, loss = 0.00839966
I0317 14:37:17.459092  3513 solver.cpp:244]     Train net output #0: loss = 0.00839969 (* 1 = 0.00839969 loss)
I0317 14:37:17.459108  3513 sgd_solver.cpp:106] Iteration 36240, lr = 0.01
I0317 14:37:20.760334  3513 solver.cpp:337] Iteration 36250, Testing net (#0)
I0317 14:39:14.635578  3513 solver.cpp:404]     Test net output #0: loss = 0.0606193 (* 1 = 0.0606193 loss)
I0317 14:39:14.635695  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64424 (* 1 = 0.64424 loss)
I0317 14:39:18.585081  3513 solver.cpp:228] Iteration 36260, loss = 0.00761094
I0317 14:39:18.585145  3513 solver.cpp:244]     Train net output #0: loss = 0.00761097 (* 1 = 0.00761097 loss)
I0317 14:39:18.585170  3513 sgd_solver.cpp:106] Iteration 36260, lr = 0.01
I0317 14:39:25.851764  3513 solver.cpp:228] Iteration 36280, loss = 0.00492787
I0317 14:39:25.851830  3513 solver.cpp:244]     Train net output #0: loss = 0.0049279 (* 1 = 0.0049279 loss)
I0317 14:39:25.851842  3513 sgd_solver.cpp:106] Iteration 36280, lr = 0.01
I0317 14:39:33.148219  3513 solver.cpp:228] Iteration 36300, loss = 0.00318344
I0317 14:39:33.148299  3513 solver.cpp:244]     Train net output #0: loss = 0.00318348 (* 1 = 0.00318348 loss)
I0317 14:39:33.148313  3513 sgd_solver.cpp:106] Iteration 36300, lr = 0.01
I0317 14:39:40.451771  3513 solver.cpp:228] Iteration 36320, loss = 0.00261278
I0317 14:39:40.451840  3513 solver.cpp:244]     Train net output #0: loss = 0.00261282 (* 1 = 0.00261282 loss)
I0317 14:39:40.451853  3513 sgd_solver.cpp:106] Iteration 36320, lr = 0.01
I0317 14:39:47.755568  3513 solver.cpp:228] Iteration 36340, loss = 0.00228505
I0317 14:39:47.755753  3513 solver.cpp:244]     Train net output #0: loss = 0.00228508 (* 1 = 0.00228508 loss)
I0317 14:39:47.755769  3513 sgd_solver.cpp:106] Iteration 36340, lr = 0.01
I0317 14:39:55.068112  3513 solver.cpp:228] Iteration 36360, loss = 0.00287367
I0317 14:39:55.068181  3513 solver.cpp:244]     Train net output #0: loss = 0.00287371 (* 1 = 0.00287371 loss)
I0317 14:39:55.068197  3513 sgd_solver.cpp:106] Iteration 36360, lr = 0.01
I0317 14:40:02.384070  3513 solver.cpp:228] Iteration 36380, loss = 0.00351093
I0317 14:40:02.384141  3513 solver.cpp:244]     Train net output #0: loss = 0.00351096 (* 1 = 0.00351096 loss)
I0317 14:40:02.384155  3513 sgd_solver.cpp:106] Iteration 36380, lr = 0.01
I0317 14:40:09.710953  3513 solver.cpp:228] Iteration 36400, loss = 0.00257188
I0317 14:40:09.711027  3513 solver.cpp:244]     Train net output #0: loss = 0.00257191 (* 1 = 0.00257191 loss)
I0317 14:40:09.711040  3513 sgd_solver.cpp:106] Iteration 36400, lr = 0.01
I0317 14:40:17.039991  3513 solver.cpp:228] Iteration 36420, loss = 0.00852853
I0317 14:40:17.040060  3513 solver.cpp:244]     Train net output #0: loss = 0.00852856 (* 1 = 0.00852856 loss)
I0317 14:40:17.040072  3513 sgd_solver.cpp:106] Iteration 36420, lr = 0.01
I0317 14:40:24.360956  3513 solver.cpp:228] Iteration 36440, loss = 0.00416695
I0317 14:40:24.361102  3513 solver.cpp:244]     Train net output #0: loss = 0.00416698 (* 1 = 0.00416698 loss)
I0317 14:40:24.361115  3513 sgd_solver.cpp:106] Iteration 36440, lr = 0.01
I0317 14:40:31.685571  3513 solver.cpp:228] Iteration 36460, loss = 0.00422293
I0317 14:40:31.685634  3513 solver.cpp:244]     Train net output #0: loss = 0.00422296 (* 1 = 0.00422296 loss)
I0317 14:40:31.685647  3513 sgd_solver.cpp:106] Iteration 36460, lr = 0.01
I0317 14:40:39.007483  3513 solver.cpp:228] Iteration 36480, loss = 0.00390177
I0317 14:40:39.007546  3513 solver.cpp:244]     Train net output #0: loss = 0.0039018 (* 1 = 0.0039018 loss)
I0317 14:40:39.007560  3513 sgd_solver.cpp:106] Iteration 36480, lr = 0.01
I0317 14:40:45.965392  3513 solver.cpp:337] Iteration 36500, Testing net (#0)
I0317 14:42:39.845316  3513 solver.cpp:404]     Test net output #0: loss = 0.0587571 (* 1 = 0.0587571 loss)
I0317 14:42:39.845432  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.63472 (* 1 = 0.63472 loss)
I0317 14:42:40.181210  3513 solver.cpp:228] Iteration 36500, loss = 0.00244372
I0317 14:42:40.181277  3513 solver.cpp:244]     Train net output #0: loss = 0.00244375 (* 1 = 0.00244375 loss)
I0317 14:42:40.181289  3513 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I0317 14:42:47.423058  3513 solver.cpp:228] Iteration 36520, loss = 0.00269611
I0317 14:42:47.423121  3513 solver.cpp:244]     Train net output #0: loss = 0.00269614 (* 1 = 0.00269614 loss)
I0317 14:42:47.423135  3513 sgd_solver.cpp:106] Iteration 36520, lr = 0.01
I0317 14:42:54.723125  3513 solver.cpp:228] Iteration 36540, loss = 0.00367383
I0317 14:42:54.723194  3513 solver.cpp:244]     Train net output #0: loss = 0.00367387 (* 1 = 0.00367387 loss)
I0317 14:42:54.723206  3513 sgd_solver.cpp:106] Iteration 36540, lr = 0.01
I0317 14:43:02.040676  3513 solver.cpp:228] Iteration 36560, loss = 0.00473114
I0317 14:43:02.040746  3513 solver.cpp:244]     Train net output #0: loss = 0.00473117 (* 1 = 0.00473117 loss)
I0317 14:43:02.040760  3513 sgd_solver.cpp:106] Iteration 36560, lr = 0.01
I0317 14:43:09.364240  3513 solver.cpp:228] Iteration 36580, loss = 0.00419903
I0317 14:43:09.364305  3513 solver.cpp:244]     Train net output #0: loss = 0.00419906 (* 1 = 0.00419906 loss)
I0317 14:43:09.364317  3513 sgd_solver.cpp:106] Iteration 36580, lr = 0.01
I0317 14:43:16.694156  3513 solver.cpp:228] Iteration 36600, loss = 0.0060657
I0317 14:43:16.694293  3513 solver.cpp:244]     Train net output #0: loss = 0.00606574 (* 1 = 0.00606574 loss)
I0317 14:43:16.694305  3513 sgd_solver.cpp:106] Iteration 36600, lr = 0.01
I0317 14:43:24.018978  3513 solver.cpp:228] Iteration 36620, loss = 0.00417753
I0317 14:43:24.019042  3513 solver.cpp:244]     Train net output #0: loss = 0.00417757 (* 1 = 0.00417757 loss)
I0317 14:43:24.019055  3513 sgd_solver.cpp:106] Iteration 36620, lr = 0.01
I0317 14:43:31.335865  3513 solver.cpp:228] Iteration 36640, loss = 0.00658348
I0317 14:43:31.335932  3513 solver.cpp:244]     Train net output #0: loss = 0.00658352 (* 1 = 0.00658352 loss)
I0317 14:43:31.335945  3513 sgd_solver.cpp:106] Iteration 36640, lr = 0.01
I0317 14:43:38.660787  3513 solver.cpp:228] Iteration 36660, loss = 0.00204014
I0317 14:43:38.660859  3513 solver.cpp:244]     Train net output #0: loss = 0.00204017 (* 1 = 0.00204017 loss)
I0317 14:43:38.660872  3513 sgd_solver.cpp:106] Iteration 36660, lr = 0.01
I0317 14:43:45.976308  3513 solver.cpp:228] Iteration 36680, loss = 0.0016354
I0317 14:43:45.976377  3513 solver.cpp:244]     Train net output #0: loss = 0.00163543 (* 1 = 0.00163543 loss)
I0317 14:43:45.976389  3513 sgd_solver.cpp:106] Iteration 36680, lr = 0.01
I0317 14:43:53.282395  3513 solver.cpp:228] Iteration 36700, loss = 0.00211303
I0317 14:43:53.282565  3513 solver.cpp:244]     Train net output #0: loss = 0.00211306 (* 1 = 0.00211306 loss)
I0317 14:43:53.282580  3513 sgd_solver.cpp:106] Iteration 36700, lr = 0.01
I0317 14:44:00.595865  3513 solver.cpp:228] Iteration 36720, loss = 0.00252439
I0317 14:44:00.595933  3513 solver.cpp:244]     Train net output #0: loss = 0.00252442 (* 1 = 0.00252442 loss)
I0317 14:44:00.595947  3513 sgd_solver.cpp:106] Iteration 36720, lr = 0.01
I0317 14:44:07.910524  3513 solver.cpp:228] Iteration 36740, loss = 0.00730235
I0317 14:44:07.910605  3513 solver.cpp:244]     Train net output #0: loss = 0.00730238 (* 1 = 0.00730238 loss)
I0317 14:44:07.910619  3513 sgd_solver.cpp:106] Iteration 36740, lr = 0.01
I0317 14:44:11.203413  3513 solver.cpp:337] Iteration 36750, Testing net (#0)
I0317 14:46:05.069329  3513 solver.cpp:404]     Test net output #0: loss = 0.0586823 (* 1 = 0.0586823 loss)
I0317 14:46:05.069443  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64412 (* 1 = 0.64412 loss)
I0317 14:46:09.015236  3513 solver.cpp:228] Iteration 36760, loss = 0.00441519
I0317 14:46:09.015300  3513 solver.cpp:244]     Train net output #0: loss = 0.00441523 (* 1 = 0.00441523 loss)
I0317 14:46:09.015312  3513 sgd_solver.cpp:106] Iteration 36760, lr = 0.01
I0317 14:46:16.282668  3513 solver.cpp:228] Iteration 36780, loss = 0.00653687
I0317 14:46:16.282735  3513 solver.cpp:244]     Train net output #0: loss = 0.00653691 (* 1 = 0.00653691 loss)
I0317 14:46:16.282749  3513 sgd_solver.cpp:106] Iteration 36780, lr = 0.01
I0317 14:46:23.581168  3513 solver.cpp:228] Iteration 36800, loss = 0.00599496
I0317 14:46:23.581235  3513 solver.cpp:244]     Train net output #0: loss = 0.005995 (* 1 = 0.005995 loss)
I0317 14:46:23.581248  3513 sgd_solver.cpp:106] Iteration 36800, lr = 0.01
I0317 14:46:30.902930  3513 solver.cpp:228] Iteration 36820, loss = 0.0048874
I0317 14:46:30.902997  3513 solver.cpp:244]     Train net output #0: loss = 0.00488744 (* 1 = 0.00488744 loss)
I0317 14:46:30.903009  3513 sgd_solver.cpp:106] Iteration 36820, lr = 0.01
I0317 14:46:38.237545  3513 solver.cpp:228] Iteration 36840, loss = 0.00297598
I0317 14:46:38.237686  3513 solver.cpp:244]     Train net output #0: loss = 0.00297601 (* 1 = 0.00297601 loss)
I0317 14:46:38.237700  3513 sgd_solver.cpp:106] Iteration 36840, lr = 0.01
I0317 14:46:45.566640  3513 solver.cpp:228] Iteration 36860, loss = 0.00354814
I0317 14:46:45.566712  3513 solver.cpp:244]     Train net output #0: loss = 0.00354817 (* 1 = 0.00354817 loss)
I0317 14:46:45.566733  3513 sgd_solver.cpp:106] Iteration 36860, lr = 0.01
I0317 14:46:52.891057  3513 solver.cpp:228] Iteration 36880, loss = 0.00326093
I0317 14:46:52.891125  3513 solver.cpp:244]     Train net output #0: loss = 0.00326096 (* 1 = 0.00326096 loss)
I0317 14:46:52.891139  3513 sgd_solver.cpp:106] Iteration 36880, lr = 0.01
I0317 14:47:00.217398  3513 solver.cpp:228] Iteration 36900, loss = 0.00263752
I0317 14:47:00.217468  3513 solver.cpp:244]     Train net output #0: loss = 0.00263755 (* 1 = 0.00263755 loss)
I0317 14:47:00.217483  3513 sgd_solver.cpp:106] Iteration 36900, lr = 0.01
I0317 14:47:07.537226  3513 solver.cpp:228] Iteration 36920, loss = 0.00599256
I0317 14:47:07.537294  3513 solver.cpp:244]     Train net output #0: loss = 0.00599259 (* 1 = 0.00599259 loss)
I0317 14:47:07.537307  3513 sgd_solver.cpp:106] Iteration 36920, lr = 0.01
I0317 14:47:14.857126  3513 solver.cpp:228] Iteration 36940, loss = 0.00350593
I0317 14:47:14.857334  3513 solver.cpp:244]     Train net output #0: loss = 0.00350596 (* 1 = 0.00350596 loss)
I0317 14:47:14.857348  3513 sgd_solver.cpp:106] Iteration 36940, lr = 0.01
I0317 14:47:22.176679  3513 solver.cpp:228] Iteration 36960, loss = 0.00557804
I0317 14:47:22.176751  3513 solver.cpp:244]     Train net output #0: loss = 0.00557807 (* 1 = 0.00557807 loss)
I0317 14:47:22.176764  3513 sgd_solver.cpp:106] Iteration 36960, lr = 0.01
I0317 14:47:29.501359  3513 solver.cpp:228] Iteration 36980, loss = 0.00609745
I0317 14:47:29.501425  3513 solver.cpp:244]     Train net output #0: loss = 0.00609748 (* 1 = 0.00609748 loss)
I0317 14:47:29.501438  3513 sgd_solver.cpp:106] Iteration 36980, lr = 0.01
I0317 14:47:36.462260  3513 solver.cpp:337] Iteration 37000, Testing net (#0)
I0317 14:49:30.352555  3513 solver.cpp:404]     Test net output #0: loss = 0.0630761 (* 1 = 0.0630761 loss)
I0317 14:49:30.352679  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65388 (* 1 = 0.65388 loss)
I0317 14:49:30.688436  3513 solver.cpp:228] Iteration 37000, loss = 0.00416122
I0317 14:49:30.688503  3513 solver.cpp:244]     Train net output #0: loss = 0.00416125 (* 1 = 0.00416125 loss)
I0317 14:49:30.688515  3513 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I0317 14:49:37.928426  3513 solver.cpp:228] Iteration 37020, loss = 0.00378562
I0317 14:49:37.928493  3513 solver.cpp:244]     Train net output #0: loss = 0.00378565 (* 1 = 0.00378565 loss)
I0317 14:49:37.928508  3513 sgd_solver.cpp:106] Iteration 37020, lr = 0.01
I0317 14:49:45.215309  3513 solver.cpp:228] Iteration 37040, loss = 0.00165032
I0317 14:49:45.215379  3513 solver.cpp:244]     Train net output #0: loss = 0.00165035 (* 1 = 0.00165035 loss)
I0317 14:49:45.215392  3513 sgd_solver.cpp:106] Iteration 37040, lr = 0.01
I0317 14:49:52.527962  3513 solver.cpp:228] Iteration 37060, loss = 0.00103401
I0317 14:49:52.528029  3513 solver.cpp:244]     Train net output #0: loss = 0.00103404 (* 1 = 0.00103404 loss)
I0317 14:49:52.528043  3513 sgd_solver.cpp:106] Iteration 37060, lr = 0.01
I0317 14:49:59.855615  3513 solver.cpp:228] Iteration 37080, loss = 0.00368413
I0317 14:49:59.855687  3513 solver.cpp:244]     Train net output #0: loss = 0.00368416 (* 1 = 0.00368416 loss)
I0317 14:49:59.855701  3513 sgd_solver.cpp:106] Iteration 37080, lr = 0.01
I0317 14:50:07.184020  3513 solver.cpp:228] Iteration 37100, loss = 0.0034465
I0317 14:50:07.184165  3513 solver.cpp:244]     Train net output #0: loss = 0.00344654 (* 1 = 0.00344654 loss)
I0317 14:50:07.184178  3513 sgd_solver.cpp:106] Iteration 37100, lr = 0.01
I0317 14:50:14.518201  3513 solver.cpp:228] Iteration 37120, loss = 0.00441189
I0317 14:50:14.518273  3513 solver.cpp:244]     Train net output #0: loss = 0.00441193 (* 1 = 0.00441193 loss)
I0317 14:50:14.518286  3513 sgd_solver.cpp:106] Iteration 37120, lr = 0.01
I0317 14:50:21.852515  3513 solver.cpp:228] Iteration 37140, loss = 0.00619075
I0317 14:50:21.852587  3513 solver.cpp:244]     Train net output #0: loss = 0.00619078 (* 1 = 0.00619078 loss)
I0317 14:50:21.852602  3513 sgd_solver.cpp:106] Iteration 37140, lr = 0.01
I0317 14:50:29.182093  3513 solver.cpp:228] Iteration 37160, loss = 0.00412209
I0317 14:50:29.182158  3513 solver.cpp:244]     Train net output #0: loss = 0.00412212 (* 1 = 0.00412212 loss)
I0317 14:50:29.182171  3513 sgd_solver.cpp:106] Iteration 37160, lr = 0.01
I0317 14:50:36.505574  3513 solver.cpp:228] Iteration 37180, loss = 0.00285728
I0317 14:50:36.505646  3513 solver.cpp:244]     Train net output #0: loss = 0.00285731 (* 1 = 0.00285731 loss)
I0317 14:50:36.505659  3513 sgd_solver.cpp:106] Iteration 37180, lr = 0.01
I0317 14:50:43.825907  3513 solver.cpp:228] Iteration 37200, loss = 0.00250717
I0317 14:50:43.826107  3513 solver.cpp:244]     Train net output #0: loss = 0.0025072 (* 1 = 0.0025072 loss)
I0317 14:50:43.826120  3513 sgd_solver.cpp:106] Iteration 37200, lr = 0.01
I0317 14:50:51.150252  3513 solver.cpp:228] Iteration 37220, loss = 0.00254032
I0317 14:50:51.150319  3513 solver.cpp:244]     Train net output #0: loss = 0.00254036 (* 1 = 0.00254036 loss)
I0317 14:50:51.150332  3513 sgd_solver.cpp:106] Iteration 37220, lr = 0.01
I0317 14:50:58.471729  3513 solver.cpp:228] Iteration 37240, loss = 0.00433874
I0317 14:50:58.471797  3513 solver.cpp:244]     Train net output #0: loss = 0.00433877 (* 1 = 0.00433877 loss)
I0317 14:50:58.471817  3513 sgd_solver.cpp:106] Iteration 37240, lr = 0.01
I0317 14:51:01.763715  3513 solver.cpp:337] Iteration 37250, Testing net (#0)
I0317 14:52:55.624516  3513 solver.cpp:404]     Test net output #0: loss = 0.0616697 (* 1 = 0.0616697 loss)
I0317 14:52:55.624642  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.63456 (* 1 = 0.63456 loss)
I0317 14:52:59.582801  3513 solver.cpp:228] Iteration 37260, loss = 0.00482514
I0317 14:52:59.582870  3513 solver.cpp:244]     Train net output #0: loss = 0.00482517 (* 1 = 0.00482517 loss)
I0317 14:52:59.582882  3513 sgd_solver.cpp:106] Iteration 37260, lr = 0.01
I0317 14:53:06.865686  3513 solver.cpp:228] Iteration 37280, loss = 0.00541553
I0317 14:53:06.865753  3513 solver.cpp:244]     Train net output #0: loss = 0.00541556 (* 1 = 0.00541556 loss)
I0317 14:53:06.865768  3513 sgd_solver.cpp:106] Iteration 37280, lr = 0.01
I0317 14:53:14.172317  3513 solver.cpp:228] Iteration 37300, loss = 0.00525071
I0317 14:53:14.172384  3513 solver.cpp:244]     Train net output #0: loss = 0.00525074 (* 1 = 0.00525074 loss)
I0317 14:53:14.172396  3513 sgd_solver.cpp:106] Iteration 37300, lr = 0.01
I0317 14:53:21.499513  3513 solver.cpp:228] Iteration 37320, loss = 0.00541187
I0317 14:53:21.499581  3513 solver.cpp:244]     Train net output #0: loss = 0.0054119 (* 1 = 0.0054119 loss)
I0317 14:53:21.499595  3513 sgd_solver.cpp:106] Iteration 37320, lr = 0.01
I0317 14:53:28.829216  3513 solver.cpp:228] Iteration 37340, loss = 0.00384834
I0317 14:53:28.829361  3513 solver.cpp:244]     Train net output #0: loss = 0.00384837 (* 1 = 0.00384837 loss)
I0317 14:53:28.829376  3513 sgd_solver.cpp:106] Iteration 37340, lr = 0.01
I0317 14:53:36.154810  3513 solver.cpp:228] Iteration 37360, loss = 0.00446455
I0317 14:53:36.154873  3513 solver.cpp:244]     Train net output #0: loss = 0.00446458 (* 1 = 0.00446458 loss)
I0317 14:53:36.154886  3513 sgd_solver.cpp:106] Iteration 37360, lr = 0.01
I0317 14:53:43.479286  3513 solver.cpp:228] Iteration 37380, loss = 0.00289052
I0317 14:53:43.479357  3513 solver.cpp:244]     Train net output #0: loss = 0.00289056 (* 1 = 0.00289056 loss)
I0317 14:53:43.479372  3513 sgd_solver.cpp:106] Iteration 37380, lr = 0.01
I0317 14:53:50.806355  3513 solver.cpp:228] Iteration 37400, loss = 0.00219168
I0317 14:53:50.806422  3513 solver.cpp:244]     Train net output #0: loss = 0.00219171 (* 1 = 0.00219171 loss)
I0317 14:53:50.806434  3513 sgd_solver.cpp:106] Iteration 37400, lr = 0.01
I0317 14:53:58.148068  3513 solver.cpp:228] Iteration 37420, loss = 0.00327309
I0317 14:53:58.148139  3513 solver.cpp:244]     Train net output #0: loss = 0.00327313 (* 1 = 0.00327313 loss)
I0317 14:53:58.148152  3513 sgd_solver.cpp:106] Iteration 37420, lr = 0.01
I0317 14:54:05.483461  3513 solver.cpp:228] Iteration 37440, loss = 0.00346741
I0317 14:54:05.483603  3513 solver.cpp:244]     Train net output #0: loss = 0.00346744 (* 1 = 0.00346744 loss)
I0317 14:54:05.483618  3513 sgd_solver.cpp:106] Iteration 37440, lr = 0.01
I0317 14:54:12.804975  3513 solver.cpp:228] Iteration 37460, loss = 0.00593178
I0317 14:54:12.805038  3513 solver.cpp:244]     Train net output #0: loss = 0.00593181 (* 1 = 0.00593181 loss)
I0317 14:54:12.805052  3513 sgd_solver.cpp:106] Iteration 37460, lr = 0.01
I0317 14:54:20.131881  3513 solver.cpp:228] Iteration 37480, loss = 0.00407224
I0317 14:54:20.131944  3513 solver.cpp:244]     Train net output #0: loss = 0.00407228 (* 1 = 0.00407228 loss)
I0317 14:54:20.131956  3513 sgd_solver.cpp:106] Iteration 37480, lr = 0.01
I0317 14:54:27.083384  3513 solver.cpp:337] Iteration 37500, Testing net (#0)
I0317 14:56:20.964859  3513 solver.cpp:404]     Test net output #0: loss = 0.0613202 (* 1 = 0.0613202 loss)
I0317 14:56:20.965029  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.63464 (* 1 = 0.63464 loss)
I0317 14:56:21.302001  3513 solver.cpp:228] Iteration 37500, loss = 0.00500327
I0317 14:56:21.302067  3513 solver.cpp:244]     Train net output #0: loss = 0.0050033 (* 1 = 0.0050033 loss)
I0317 14:56:21.302080  3513 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I0317 14:56:28.546144  3513 solver.cpp:228] Iteration 37520, loss = 0.00581272
I0317 14:56:28.546211  3513 solver.cpp:244]     Train net output #0: loss = 0.00581276 (* 1 = 0.00581276 loss)
I0317 14:56:28.546223  3513 sgd_solver.cpp:106] Iteration 37520, lr = 0.01
I0317 14:56:35.830015  3513 solver.cpp:228] Iteration 37540, loss = 0.0047377
I0317 14:56:35.830085  3513 solver.cpp:244]     Train net output #0: loss = 0.00473773 (* 1 = 0.00473773 loss)
I0317 14:56:35.830097  3513 sgd_solver.cpp:106] Iteration 37540, lr = 0.01
I0317 14:56:43.134959  3513 solver.cpp:228] Iteration 37560, loss = 0.00419883
I0317 14:56:43.135026  3513 solver.cpp:244]     Train net output #0: loss = 0.00419886 (* 1 = 0.00419886 loss)
I0317 14:56:43.135040  3513 sgd_solver.cpp:106] Iteration 37560, lr = 0.01
I0317 14:56:50.450664  3513 solver.cpp:228] Iteration 37580, loss = 0.00442752
I0317 14:56:50.450731  3513 solver.cpp:244]     Train net output #0: loss = 0.00442755 (* 1 = 0.00442755 loss)
I0317 14:56:50.450747  3513 sgd_solver.cpp:106] Iteration 37580, lr = 0.01
I0317 14:56:57.761447  3513 solver.cpp:228] Iteration 37600, loss = 0.00255118
I0317 14:56:57.761602  3513 solver.cpp:244]     Train net output #0: loss = 0.00255121 (* 1 = 0.00255121 loss)
I0317 14:56:57.761618  3513 sgd_solver.cpp:106] Iteration 37600, lr = 0.01
I0317 14:57:05.085217  3513 solver.cpp:228] Iteration 37620, loss = 0.00109384
I0317 14:57:05.085284  3513 solver.cpp:244]     Train net output #0: loss = 0.00109387 (* 1 = 0.00109387 loss)
I0317 14:57:05.085297  3513 sgd_solver.cpp:106] Iteration 37620, lr = 0.01
I0317 14:57:12.403695  3513 solver.cpp:228] Iteration 37640, loss = 0.00757823
I0317 14:57:12.403762  3513 solver.cpp:244]     Train net output #0: loss = 0.00757826 (* 1 = 0.00757826 loss)
I0317 14:57:12.403775  3513 sgd_solver.cpp:106] Iteration 37640, lr = 0.01
I0317 14:57:19.728869  3513 solver.cpp:228] Iteration 37660, loss = 0.0026578
I0317 14:57:19.728937  3513 solver.cpp:244]     Train net output #0: loss = 0.00265783 (* 1 = 0.00265783 loss)
I0317 14:57:19.728950  3513 sgd_solver.cpp:106] Iteration 37660, lr = 0.01
I0317 14:57:27.054002  3513 solver.cpp:228] Iteration 37680, loss = 0.0059756
I0317 14:57:27.054064  3513 solver.cpp:244]     Train net output #0: loss = 0.00597563 (* 1 = 0.00597563 loss)
I0317 14:57:27.054077  3513 sgd_solver.cpp:106] Iteration 37680, lr = 0.01
I0317 14:57:34.377454  3513 solver.cpp:228] Iteration 37700, loss = 0.00423656
I0317 14:57:34.377598  3513 solver.cpp:244]     Train net output #0: loss = 0.0042366 (* 1 = 0.0042366 loss)
I0317 14:57:34.377611  3513 sgd_solver.cpp:106] Iteration 37700, lr = 0.01
I0317 14:57:41.701968  3513 solver.cpp:228] Iteration 37720, loss = 0.00580284
I0317 14:57:41.702033  3513 solver.cpp:244]     Train net output #0: loss = 0.00580287 (* 1 = 0.00580287 loss)
I0317 14:57:41.702044  3513 sgd_solver.cpp:106] Iteration 37720, lr = 0.01
I0317 14:57:49.030278  3513 solver.cpp:228] Iteration 37740, loss = 0.00274511
I0317 14:57:49.030339  3513 solver.cpp:244]     Train net output #0: loss = 0.00274514 (* 1 = 0.00274514 loss)
I0317 14:57:49.030351  3513 sgd_solver.cpp:106] Iteration 37740, lr = 0.01
I0317 14:57:52.326800  3513 solver.cpp:337] Iteration 37750, Testing net (#0)
I0317 14:59:46.179855  3513 solver.cpp:404]     Test net output #0: loss = 0.0592717 (* 1 = 0.0592717 loss)
I0317 14:59:46.180022  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.62508 (* 1 = 0.62508 loss)
I0317 14:59:50.140537  3513 solver.cpp:228] Iteration 37760, loss = 0.00115479
I0317 14:59:50.140601  3513 solver.cpp:244]     Train net output #0: loss = 0.00115482 (* 1 = 0.00115482 loss)
I0317 14:59:50.140614  3513 sgd_solver.cpp:106] Iteration 37760, lr = 0.01
I0317 14:59:57.422015  3513 solver.cpp:228] Iteration 37780, loss = 0.00474944
I0317 14:59:57.422083  3513 solver.cpp:244]     Train net output #0: loss = 0.00474947 (* 1 = 0.00474947 loss)
I0317 14:59:57.422101  3513 sgd_solver.cpp:106] Iteration 37780, lr = 0.01
I0317 15:00:04.728298  3513 solver.cpp:228] Iteration 37800, loss = 0.00196959
I0317 15:00:04.728365  3513 solver.cpp:244]     Train net output #0: loss = 0.00196962 (* 1 = 0.00196962 loss)
I0317 15:00:04.728379  3513 sgd_solver.cpp:106] Iteration 37800, lr = 0.01
I0317 15:00:12.049485  3513 solver.cpp:228] Iteration 37820, loss = 0.00439596
I0317 15:00:12.049553  3513 solver.cpp:244]     Train net output #0: loss = 0.004396 (* 1 = 0.004396 loss)
I0317 15:00:12.049566  3513 sgd_solver.cpp:106] Iteration 37820, lr = 0.01
I0317 15:00:19.375438  3513 solver.cpp:228] Iteration 37840, loss = 0.00387795
I0317 15:00:19.375628  3513 solver.cpp:244]     Train net output #0: loss = 0.00387798 (* 1 = 0.00387798 loss)
I0317 15:00:19.375643  3513 sgd_solver.cpp:106] Iteration 37840, lr = 0.01
I0317 15:00:26.706203  3513 solver.cpp:228] Iteration 37860, loss = 0.0033545
I0317 15:00:26.706266  3513 solver.cpp:244]     Train net output #0: loss = 0.00335453 (* 1 = 0.00335453 loss)
I0317 15:00:26.706279  3513 sgd_solver.cpp:106] Iteration 37860, lr = 0.01
I0317 15:00:34.038028  3513 solver.cpp:228] Iteration 37880, loss = 0.00556006
I0317 15:00:34.038096  3513 solver.cpp:244]     Train net output #0: loss = 0.0055601 (* 1 = 0.0055601 loss)
I0317 15:00:34.038110  3513 sgd_solver.cpp:106] Iteration 37880, lr = 0.01
I0317 15:00:41.363023  3513 solver.cpp:228] Iteration 37900, loss = 0.00670199
I0317 15:00:41.363085  3513 solver.cpp:244]     Train net output #0: loss = 0.00670202 (* 1 = 0.00670202 loss)
I0317 15:00:41.363097  3513 sgd_solver.cpp:106] Iteration 37900, lr = 0.01
I0317 15:00:48.690871  3513 solver.cpp:228] Iteration 37920, loss = 0.00408333
I0317 15:00:48.690937  3513 solver.cpp:244]     Train net output #0: loss = 0.00408336 (* 1 = 0.00408336 loss)
I0317 15:00:48.690951  3513 sgd_solver.cpp:106] Iteration 37920, lr = 0.01
I0317 15:00:56.019688  3513 solver.cpp:228] Iteration 37940, loss = 0.00390467
I0317 15:00:56.019836  3513 solver.cpp:244]     Train net output #0: loss = 0.0039047 (* 1 = 0.0039047 loss)
I0317 15:00:56.019850  3513 sgd_solver.cpp:106] Iteration 37940, lr = 0.01
I0317 15:01:03.353339  3513 solver.cpp:228] Iteration 37960, loss = 0.00225347
I0317 15:01:03.353407  3513 solver.cpp:244]     Train net output #0: loss = 0.0022535 (* 1 = 0.0022535 loss)
I0317 15:01:03.353420  3513 sgd_solver.cpp:106] Iteration 37960, lr = 0.01
I0317 15:01:10.682742  3513 solver.cpp:228] Iteration 37980, loss = 0.00431832
I0317 15:01:10.682802  3513 solver.cpp:244]     Train net output #0: loss = 0.00431835 (* 1 = 0.00431835 loss)
I0317 15:01:10.682814  3513 sgd_solver.cpp:106] Iteration 37980, lr = 0.01
I0317 15:01:17.649879  3513 solver.cpp:337] Iteration 38000, Testing net (#0)
I0317 15:03:11.503028  3513 solver.cpp:404]     Test net output #0: loss = 0.0617525 (* 1 = 0.0617525 loss)
I0317 15:03:11.503149  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.672999 (* 1 = 0.672999 loss)
I0317 15:03:11.839138  3513 solver.cpp:228] Iteration 38000, loss = 0.00271519
I0317 15:03:11.839215  3513 solver.cpp:244]     Train net output #0: loss = 0.00271522 (* 1 = 0.00271522 loss)
I0317 15:03:11.839227  3513 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I0317 15:03:19.089715  3513 solver.cpp:228] Iteration 38020, loss = 0.00226595
I0317 15:03:19.089777  3513 solver.cpp:244]     Train net output #0: loss = 0.00226598 (* 1 = 0.00226598 loss)
I0317 15:03:19.089790  3513 sgd_solver.cpp:106] Iteration 38020, lr = 0.01
I0317 15:03:26.395797  3513 solver.cpp:228] Iteration 38040, loss = 0.0044549
I0317 15:03:26.395859  3513 solver.cpp:244]     Train net output #0: loss = 0.00445493 (* 1 = 0.00445493 loss)
I0317 15:03:26.395872  3513 sgd_solver.cpp:106] Iteration 38040, lr = 0.01
I0317 15:03:33.718116  3513 solver.cpp:228] Iteration 38060, loss = 0.00382906
I0317 15:03:33.718189  3513 solver.cpp:244]     Train net output #0: loss = 0.00382909 (* 1 = 0.00382909 loss)
I0317 15:03:33.718204  3513 sgd_solver.cpp:106] Iteration 38060, lr = 0.01
I0317 15:03:41.045498  3513 solver.cpp:228] Iteration 38080, loss = 0.00647135
I0317 15:03:41.045559  3513 solver.cpp:244]     Train net output #0: loss = 0.00647138 (* 1 = 0.00647138 loss)
I0317 15:03:41.045572  3513 sgd_solver.cpp:106] Iteration 38080, lr = 0.01
I0317 15:03:48.379611  3513 solver.cpp:228] Iteration 38100, loss = 0.00301151
I0317 15:03:48.379799  3513 solver.cpp:244]     Train net output #0: loss = 0.00301154 (* 1 = 0.00301154 loss)
I0317 15:03:48.379813  3513 sgd_solver.cpp:106] Iteration 38100, lr = 0.01
I0317 15:03:55.715937  3513 solver.cpp:228] Iteration 38120, loss = 0.00288349
I0317 15:03:55.716006  3513 solver.cpp:244]     Train net output #0: loss = 0.00288352 (* 1 = 0.00288352 loss)
I0317 15:03:55.716018  3513 sgd_solver.cpp:106] Iteration 38120, lr = 0.01
I0317 15:04:03.045788  3513 solver.cpp:228] Iteration 38140, loss = 0.0039384
I0317 15:04:03.045861  3513 solver.cpp:244]     Train net output #0: loss = 0.00393843 (* 1 = 0.00393843 loss)
I0317 15:04:03.045882  3513 sgd_solver.cpp:106] Iteration 38140, lr = 0.01
I0317 15:04:10.376029  3513 solver.cpp:228] Iteration 38160, loss = 0.00543323
I0317 15:04:10.376093  3513 solver.cpp:244]     Train net output #0: loss = 0.00543326 (* 1 = 0.00543326 loss)
I0317 15:04:10.376106  3513 sgd_solver.cpp:106] Iteration 38160, lr = 0.01
I0317 15:04:17.709214  3513 solver.cpp:228] Iteration 38180, loss = 0.00383523
I0317 15:04:17.709280  3513 solver.cpp:244]     Train net output #0: loss = 0.00383526 (* 1 = 0.00383526 loss)
I0317 15:04:17.709293  3513 sgd_solver.cpp:106] Iteration 38180, lr = 0.01
I0317 15:04:25.044991  3513 solver.cpp:228] Iteration 38200, loss = 0.00277061
I0317 15:04:25.045140  3513 solver.cpp:244]     Train net output #0: loss = 0.00277064 (* 1 = 0.00277064 loss)
I0317 15:04:25.045155  3513 sgd_solver.cpp:106] Iteration 38200, lr = 0.01
I0317 15:04:32.376668  3513 solver.cpp:228] Iteration 38220, loss = 0.00606639
I0317 15:04:32.376737  3513 solver.cpp:244]     Train net output #0: loss = 0.00606642 (* 1 = 0.00606642 loss)
I0317 15:04:32.376749  3513 sgd_solver.cpp:106] Iteration 38220, lr = 0.01
I0317 15:04:39.707247  3513 solver.cpp:228] Iteration 38240, loss = 0.00329988
I0317 15:04:39.707316  3513 solver.cpp:244]     Train net output #0: loss = 0.00329991 (* 1 = 0.00329991 loss)
I0317 15:04:39.707329  3513 sgd_solver.cpp:106] Iteration 38240, lr = 0.01
I0317 15:04:43.005434  3513 solver.cpp:337] Iteration 38250, Testing net (#0)
I0317 15:06:36.884263  3513 solver.cpp:404]     Test net output #0: loss = 0.0634676 (* 1 = 0.0634676 loss)
I0317 15:06:36.884397  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64432 (* 1 = 0.64432 loss)
I0317 15:06:40.823369  3513 solver.cpp:228] Iteration 38260, loss = 0.00647946
I0317 15:06:40.823436  3513 solver.cpp:244]     Train net output #0: loss = 0.00647949 (* 1 = 0.00647949 loss)
I0317 15:06:40.823449  3513 sgd_solver.cpp:106] Iteration 38260, lr = 0.01
I0317 15:06:48.085306  3513 solver.cpp:228] Iteration 38280, loss = 0.00202145
I0317 15:06:48.085373  3513 solver.cpp:244]     Train net output #0: loss = 0.00202148 (* 1 = 0.00202148 loss)
I0317 15:06:48.085386  3513 sgd_solver.cpp:106] Iteration 38280, lr = 0.01
I0317 15:06:55.397516  3513 solver.cpp:228] Iteration 38300, loss = 0.00465648
I0317 15:06:55.397579  3513 solver.cpp:244]     Train net output #0: loss = 0.00465651 (* 1 = 0.00465651 loss)
I0317 15:06:55.397593  3513 sgd_solver.cpp:106] Iteration 38300, lr = 0.01
I0317 15:07:02.720103  3513 solver.cpp:228] Iteration 38320, loss = 0.00289503
I0317 15:07:02.720170  3513 solver.cpp:244]     Train net output #0: loss = 0.00289505 (* 1 = 0.00289505 loss)
I0317 15:07:02.720183  3513 sgd_solver.cpp:106] Iteration 38320, lr = 0.01
I0317 15:07:10.049021  3513 solver.cpp:228] Iteration 38340, loss = 0.00125818
I0317 15:07:10.049227  3513 solver.cpp:244]     Train net output #0: loss = 0.00125821 (* 1 = 0.00125821 loss)
I0317 15:07:10.049252  3513 sgd_solver.cpp:106] Iteration 38340, lr = 0.01
I0317 15:07:17.376557  3513 solver.cpp:228] Iteration 38360, loss = 0.00603041
I0317 15:07:17.376621  3513 solver.cpp:244]     Train net output #0: loss = 0.00603044 (* 1 = 0.00603044 loss)
I0317 15:07:17.376634  3513 sgd_solver.cpp:106] Iteration 38360, lr = 0.01
I0317 15:07:24.702003  3513 solver.cpp:228] Iteration 38380, loss = 0.00266398
I0317 15:07:24.702074  3513 solver.cpp:244]     Train net output #0: loss = 0.00266401 (* 1 = 0.00266401 loss)
I0317 15:07:24.702086  3513 sgd_solver.cpp:106] Iteration 38380, lr = 0.01
I0317 15:07:32.022863  3513 solver.cpp:228] Iteration 38400, loss = 0.00442216
I0317 15:07:32.022927  3513 solver.cpp:244]     Train net output #0: loss = 0.00442219 (* 1 = 0.00442219 loss)
I0317 15:07:32.022939  3513 sgd_solver.cpp:106] Iteration 38400, lr = 0.01
I0317 15:07:39.338521  3513 solver.cpp:228] Iteration 38420, loss = 0.00544207
I0317 15:07:39.338593  3513 solver.cpp:244]     Train net output #0: loss = 0.0054421 (* 1 = 0.0054421 loss)
I0317 15:07:39.338614  3513 sgd_solver.cpp:106] Iteration 38420, lr = 0.01
I0317 15:07:46.652673  3513 solver.cpp:228] Iteration 38440, loss = 0.00644042
I0317 15:07:46.652840  3513 solver.cpp:244]     Train net output #0: loss = 0.00644045 (* 1 = 0.00644045 loss)
I0317 15:07:46.652854  3513 sgd_solver.cpp:106] Iteration 38440, lr = 0.01
I0317 15:07:53.966020  3513 solver.cpp:228] Iteration 38460, loss = 0.00400035
I0317 15:07:53.966090  3513 solver.cpp:244]     Train net output #0: loss = 0.00400038 (* 1 = 0.00400038 loss)
I0317 15:07:53.966104  3513 sgd_solver.cpp:106] Iteration 38460, lr = 0.01
I0317 15:08:01.286305  3513 solver.cpp:228] Iteration 38480, loss = 0.00122631
I0317 15:08:01.286373  3513 solver.cpp:244]     Train net output #0: loss = 0.00122634 (* 1 = 0.00122634 loss)
I0317 15:08:01.286387  3513 sgd_solver.cpp:106] Iteration 38480, lr = 0.01
I0317 15:08:08.244200  3513 solver.cpp:337] Iteration 38500, Testing net (#0)
I0317 15:10:02.111918  3513 solver.cpp:404]     Test net output #0: loss = 0.0612127 (* 1 = 0.0612127 loss)
I0317 15:10:02.112004  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.6538 (* 1 = 0.6538 loss)
I0317 15:10:02.448403  3513 solver.cpp:228] Iteration 38500, loss = 0.00214815
I0317 15:10:02.448477  3513 solver.cpp:244]     Train net output #0: loss = 0.00214818 (* 1 = 0.00214818 loss)
I0317 15:10:02.448492  3513 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I0317 15:10:09.700641  3513 solver.cpp:228] Iteration 38520, loss = 0.00521369
I0317 15:10:09.700711  3513 solver.cpp:244]     Train net output #0: loss = 0.00521371 (* 1 = 0.00521371 loss)
I0317 15:10:09.700723  3513 sgd_solver.cpp:106] Iteration 38520, lr = 0.01
I0317 15:10:17.003049  3513 solver.cpp:228] Iteration 38540, loss = 0.0042578
I0317 15:10:17.003129  3513 solver.cpp:244]     Train net output #0: loss = 0.00425783 (* 1 = 0.00425783 loss)
I0317 15:10:17.003141  3513 sgd_solver.cpp:106] Iteration 38540, lr = 0.01
I0317 15:10:24.326671  3513 solver.cpp:228] Iteration 38560, loss = 0.00376957
I0317 15:10:24.326738  3513 solver.cpp:244]     Train net output #0: loss = 0.00376959 (* 1 = 0.00376959 loss)
I0317 15:10:24.326751  3513 sgd_solver.cpp:106] Iteration 38560, lr = 0.01
I0317 15:10:31.649930  3513 solver.cpp:228] Iteration 38580, loss = 0.00461768
I0317 15:10:31.650002  3513 solver.cpp:244]     Train net output #0: loss = 0.00461771 (* 1 = 0.00461771 loss)
I0317 15:10:31.650017  3513 sgd_solver.cpp:106] Iteration 38580, lr = 0.01
I0317 15:10:38.972209  3513 solver.cpp:228] Iteration 38600, loss = 0.0031757
I0317 15:10:38.972362  3513 solver.cpp:244]     Train net output #0: loss = 0.00317573 (* 1 = 0.00317573 loss)
I0317 15:10:38.972375  3513 sgd_solver.cpp:106] Iteration 38600, lr = 0.01
I0317 15:10:46.303741  3513 solver.cpp:228] Iteration 38620, loss = 0.00463434
I0317 15:10:46.303805  3513 solver.cpp:244]     Train net output #0: loss = 0.00463436 (* 1 = 0.00463436 loss)
I0317 15:10:46.303818  3513 sgd_solver.cpp:106] Iteration 38620, lr = 0.01
I0317 15:10:53.635903  3513 solver.cpp:228] Iteration 38640, loss = 0.00516525
I0317 15:10:53.635972  3513 solver.cpp:244]     Train net output #0: loss = 0.00516528 (* 1 = 0.00516528 loss)
I0317 15:10:53.635985  3513 sgd_solver.cpp:106] Iteration 38640, lr = 0.01
I0317 15:11:00.964550  3513 solver.cpp:228] Iteration 38660, loss = 0.00206493
I0317 15:11:00.964617  3513 solver.cpp:244]     Train net output #0: loss = 0.00206496 (* 1 = 0.00206496 loss)
I0317 15:11:00.964630  3513 sgd_solver.cpp:106] Iteration 38660, lr = 0.01
I0317 15:11:08.290992  3513 solver.cpp:228] Iteration 38680, loss = 0.00195852
I0317 15:11:08.291059  3513 solver.cpp:244]     Train net output #0: loss = 0.00195855 (* 1 = 0.00195855 loss)
I0317 15:11:08.291071  3513 sgd_solver.cpp:106] Iteration 38680, lr = 0.01
I0317 15:11:15.614933  3513 solver.cpp:228] Iteration 38700, loss = 0.00499143
I0317 15:11:15.615146  3513 solver.cpp:244]     Train net output #0: loss = 0.00499146 (* 1 = 0.00499146 loss)
I0317 15:11:15.615170  3513 sgd_solver.cpp:106] Iteration 38700, lr = 0.01
I0317 15:11:22.929343  3513 solver.cpp:228] Iteration 38720, loss = 0.00398766
I0317 15:11:22.929405  3513 solver.cpp:244]     Train net output #0: loss = 0.00398769 (* 1 = 0.00398769 loss)
I0317 15:11:22.929419  3513 sgd_solver.cpp:106] Iteration 38720, lr = 0.01
I0317 15:11:30.261179  3513 solver.cpp:228] Iteration 38740, loss = 0.00292055
I0317 15:11:30.261245  3513 solver.cpp:244]     Train net output #0: loss = 0.00292058 (* 1 = 0.00292058 loss)
I0317 15:11:30.261257  3513 sgd_solver.cpp:106] Iteration 38740, lr = 0.01
I0317 15:11:33.558945  3513 solver.cpp:337] Iteration 38750, Testing net (#0)
I0317 15:13:27.452277  3513 solver.cpp:404]     Test net output #0: loss = 0.0621558 (* 1 = 0.0621558 loss)
I0317 15:13:27.452420  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65384 (* 1 = 0.65384 loss)
I0317 15:13:31.394044  3513 solver.cpp:228] Iteration 38760, loss = 0.00675381
I0317 15:13:31.394111  3513 solver.cpp:244]     Train net output #0: loss = 0.00675384 (* 1 = 0.00675384 loss)
I0317 15:13:31.394124  3513 sgd_solver.cpp:106] Iteration 38760, lr = 0.01
I0317 15:13:38.669442  3513 solver.cpp:228] Iteration 38780, loss = 0.00424567
I0317 15:13:38.669505  3513 solver.cpp:244]     Train net output #0: loss = 0.0042457 (* 1 = 0.0042457 loss)
I0317 15:13:38.669518  3513 sgd_solver.cpp:106] Iteration 38780, lr = 0.01
I0317 15:13:45.979267  3513 solver.cpp:228] Iteration 38800, loss = 0.00643681
I0317 15:13:45.979336  3513 solver.cpp:244]     Train net output #0: loss = 0.00643684 (* 1 = 0.00643684 loss)
I0317 15:13:45.979347  3513 sgd_solver.cpp:106] Iteration 38800, lr = 0.01
I0317 15:13:53.294582  3513 solver.cpp:228] Iteration 38820, loss = 0.00162763
I0317 15:13:53.294646  3513 solver.cpp:244]     Train net output #0: loss = 0.00162766 (* 1 = 0.00162766 loss)
I0317 15:13:53.294657  3513 sgd_solver.cpp:106] Iteration 38820, lr = 0.01
I0317 15:14:00.624040  3513 solver.cpp:228] Iteration 38840, loss = 0.00221226
I0317 15:14:00.624191  3513 solver.cpp:244]     Train net output #0: loss = 0.00221229 (* 1 = 0.00221229 loss)
I0317 15:14:00.624205  3513 sgd_solver.cpp:106] Iteration 38840, lr = 0.01
I0317 15:14:07.955654  3513 solver.cpp:228] Iteration 38860, loss = 0.00387607
I0317 15:14:07.955726  3513 solver.cpp:244]     Train net output #0: loss = 0.0038761 (* 1 = 0.0038761 loss)
I0317 15:14:07.955739  3513 sgd_solver.cpp:106] Iteration 38860, lr = 0.01
I0317 15:14:15.287235  3513 solver.cpp:228] Iteration 38880, loss = 0.00402389
I0317 15:14:15.287303  3513 solver.cpp:244]     Train net output #0: loss = 0.00402392 (* 1 = 0.00402392 loss)
I0317 15:14:15.287317  3513 sgd_solver.cpp:106] Iteration 38880, lr = 0.01
I0317 15:14:22.612620  3513 solver.cpp:228] Iteration 38900, loss = 0.00356305
I0317 15:14:22.612686  3513 solver.cpp:244]     Train net output #0: loss = 0.00356308 (* 1 = 0.00356308 loss)
I0317 15:14:22.612699  3513 sgd_solver.cpp:106] Iteration 38900, lr = 0.01
I0317 15:14:29.942307  3513 solver.cpp:228] Iteration 38920, loss = 0.00307356
I0317 15:14:29.942385  3513 solver.cpp:244]     Train net output #0: loss = 0.00307359 (* 1 = 0.00307359 loss)
I0317 15:14:29.942400  3513 sgd_solver.cpp:106] Iteration 38920, lr = 0.01
I0317 15:14:37.272325  3513 solver.cpp:228] Iteration 38940, loss = 0.00596113
I0317 15:14:37.272526  3513 solver.cpp:244]     Train net output #0: loss = 0.00596116 (* 1 = 0.00596116 loss)
I0317 15:14:37.272539  3513 sgd_solver.cpp:106] Iteration 38940, lr = 0.01
I0317 15:14:44.600162  3513 solver.cpp:228] Iteration 38960, loss = 0.00464018
I0317 15:14:44.600234  3513 solver.cpp:244]     Train net output #0: loss = 0.00464022 (* 1 = 0.00464022 loss)
I0317 15:14:44.600247  3513 sgd_solver.cpp:106] Iteration 38960, lr = 0.01
I0317 15:14:51.928020  3513 solver.cpp:228] Iteration 38980, loss = 0.00498238
I0317 15:14:51.928094  3513 solver.cpp:244]     Train net output #0: loss = 0.00498241 (* 1 = 0.00498241 loss)
I0317 15:14:51.928107  3513 sgd_solver.cpp:106] Iteration 38980, lr = 0.01
I0317 15:14:58.889907  3513 solver.cpp:337] Iteration 39000, Testing net (#0)
I0317 15:16:52.752315  3513 solver.cpp:404]     Test net output #0: loss = 0.0549125 (* 1 = 0.0549125 loss)
I0317 15:16:52.752434  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.60588 (* 1 = 0.60588 loss)
I0317 15:16:53.088802  3513 solver.cpp:228] Iteration 39000, loss = 0.00309535
I0317 15:16:53.088870  3513 solver.cpp:244]     Train net output #0: loss = 0.00309539 (* 1 = 0.00309539 loss)
I0317 15:16:53.088882  3513 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I0317 15:17:00.337878  3513 solver.cpp:228] Iteration 39020, loss = 0.00307752
I0317 15:17:00.337963  3513 solver.cpp:244]     Train net output #0: loss = 0.00307755 (* 1 = 0.00307755 loss)
I0317 15:17:00.337977  3513 sgd_solver.cpp:106] Iteration 39020, lr = 0.01
I0317 15:17:07.627049  3513 solver.cpp:228] Iteration 39040, loss = 0.0014425
I0317 15:17:07.627117  3513 solver.cpp:244]     Train net output #0: loss = 0.00144253 (* 1 = 0.00144253 loss)
I0317 15:17:07.627130  3513 sgd_solver.cpp:106] Iteration 39040, lr = 0.01
I0317 15:17:14.937584  3513 solver.cpp:228] Iteration 39060, loss = 0.00294353
I0317 15:17:14.937652  3513 solver.cpp:244]     Train net output #0: loss = 0.00294356 (* 1 = 0.00294356 loss)
I0317 15:17:14.937665  3513 sgd_solver.cpp:106] Iteration 39060, lr = 0.01
I0317 15:17:22.260905  3513 solver.cpp:228] Iteration 39080, loss = 0.00386839
I0317 15:17:22.260987  3513 solver.cpp:244]     Train net output #0: loss = 0.00386843 (* 1 = 0.00386843 loss)
I0317 15:17:22.261000  3513 sgd_solver.cpp:106] Iteration 39080, lr = 0.01
I0317 15:17:29.585446  3513 solver.cpp:228] Iteration 39100, loss = 0.00249452
I0317 15:17:29.585587  3513 solver.cpp:244]     Train net output #0: loss = 0.00249455 (* 1 = 0.00249455 loss)
I0317 15:17:29.585602  3513 sgd_solver.cpp:106] Iteration 39100, lr = 0.01
I0317 15:17:36.911703  3513 solver.cpp:228] Iteration 39120, loss = 0.00682256
I0317 15:17:36.911767  3513 solver.cpp:244]     Train net output #0: loss = 0.0068226 (* 1 = 0.0068226 loss)
I0317 15:17:36.911779  3513 sgd_solver.cpp:106] Iteration 39120, lr = 0.01
I0317 15:17:44.244290  3513 solver.cpp:228] Iteration 39140, loss = 0.00457944
I0317 15:17:44.244360  3513 solver.cpp:244]     Train net output #0: loss = 0.00457947 (* 1 = 0.00457947 loss)
I0317 15:17:44.244374  3513 sgd_solver.cpp:106] Iteration 39140, lr = 0.01
I0317 15:17:51.580678  3513 solver.cpp:228] Iteration 39160, loss = 0.00621959
I0317 15:17:51.580741  3513 solver.cpp:244]     Train net output #0: loss = 0.00621963 (* 1 = 0.00621963 loss)
I0317 15:17:51.580754  3513 sgd_solver.cpp:106] Iteration 39160, lr = 0.01
I0317 15:17:58.907191  3513 solver.cpp:228] Iteration 39180, loss = 0.00279171
I0317 15:17:58.907258  3513 solver.cpp:244]     Train net output #0: loss = 0.00279175 (* 1 = 0.00279175 loss)
I0317 15:17:58.907270  3513 sgd_solver.cpp:106] Iteration 39180, lr = 0.01
I0317 15:18:06.235913  3513 solver.cpp:228] Iteration 39200, loss = 0.00207958
I0317 15:18:06.236142  3513 solver.cpp:244]     Train net output #0: loss = 0.00207962 (* 1 = 0.00207962 loss)
I0317 15:18:06.236158  3513 sgd_solver.cpp:106] Iteration 39200, lr = 0.01
I0317 15:18:13.560313  3513 solver.cpp:228] Iteration 39220, loss = 0.00399533
I0317 15:18:13.560381  3513 solver.cpp:244]     Train net output #0: loss = 0.00399536 (* 1 = 0.00399536 loss)
I0317 15:18:13.560395  3513 sgd_solver.cpp:106] Iteration 39220, lr = 0.01
I0317 15:18:20.886062  3513 solver.cpp:228] Iteration 39240, loss = 0.00423637
I0317 15:18:20.886132  3513 solver.cpp:244]     Train net output #0: loss = 0.0042364 (* 1 = 0.0042364 loss)
I0317 15:18:20.886144  3513 sgd_solver.cpp:106] Iteration 39240, lr = 0.01
I0317 15:18:24.181790  3513 solver.cpp:337] Iteration 39250, Testing net (#0)
I0317 15:20:18.045861  3513 solver.cpp:404]     Test net output #0: loss = 0.0598413 (* 1 = 0.0598413 loss)
I0317 15:20:18.045999  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.65376 (* 1 = 0.65376 loss)
I0317 15:20:21.998750  3513 solver.cpp:228] Iteration 39260, loss = 0.00426939
I0317 15:20:21.998821  3513 solver.cpp:244]     Train net output #0: loss = 0.00426943 (* 1 = 0.00426943 loss)
I0317 15:20:21.998833  3513 sgd_solver.cpp:106] Iteration 39260, lr = 0.01
I0317 15:20:29.268103  3513 solver.cpp:228] Iteration 39280, loss = 0.00439214
I0317 15:20:29.268177  3513 solver.cpp:244]     Train net output #0: loss = 0.00439218 (* 1 = 0.00439218 loss)
I0317 15:20:29.268190  3513 sgd_solver.cpp:106] Iteration 39280, lr = 0.01
I0317 15:20:36.575173  3513 solver.cpp:228] Iteration 39300, loss = 0.00564642
I0317 15:20:36.575242  3513 solver.cpp:244]     Train net output #0: loss = 0.00564645 (* 1 = 0.00564645 loss)
I0317 15:20:36.575254  3513 sgd_solver.cpp:106] Iteration 39300, lr = 0.01
I0317 15:20:43.904287  3513 solver.cpp:228] Iteration 39320, loss = 0.00291627
I0317 15:20:43.904361  3513 solver.cpp:244]     Train net output #0: loss = 0.0029163 (* 1 = 0.0029163 loss)
I0317 15:20:43.904373  3513 sgd_solver.cpp:106] Iteration 39320, lr = 0.01
I0317 15:20:51.228217  3513 solver.cpp:228] Iteration 39340, loss = 0.00615507
I0317 15:20:51.228350  3513 solver.cpp:244]     Train net output #0: loss = 0.00615511 (* 1 = 0.00615511 loss)
I0317 15:20:51.228364  3513 sgd_solver.cpp:106] Iteration 39340, lr = 0.01
I0317 15:20:58.552654  3513 solver.cpp:228] Iteration 39360, loss = 0.00252361
I0317 15:20:58.552719  3513 solver.cpp:244]     Train net output #0: loss = 0.00252364 (* 1 = 0.00252364 loss)
I0317 15:20:58.552733  3513 sgd_solver.cpp:106] Iteration 39360, lr = 0.01
I0317 15:21:05.881666  3513 solver.cpp:228] Iteration 39380, loss = 0.00129585
I0317 15:21:05.881734  3513 solver.cpp:244]     Train net output #0: loss = 0.00129588 (* 1 = 0.00129588 loss)
I0317 15:21:05.881747  3513 sgd_solver.cpp:106] Iteration 39380, lr = 0.01
I0317 15:21:13.216867  3513 solver.cpp:228] Iteration 39400, loss = 0.00193669
I0317 15:21:13.216934  3513 solver.cpp:244]     Train net output #0: loss = 0.00193672 (* 1 = 0.00193672 loss)
I0317 15:21:13.216948  3513 sgd_solver.cpp:106] Iteration 39400, lr = 0.01
I0317 15:21:20.543864  3513 solver.cpp:228] Iteration 39420, loss = 0.00323942
I0317 15:21:20.543926  3513 solver.cpp:244]     Train net output #0: loss = 0.00323946 (* 1 = 0.00323946 loss)
I0317 15:21:20.543939  3513 sgd_solver.cpp:106] Iteration 39420, lr = 0.01
I0317 15:21:27.868932  3513 solver.cpp:228] Iteration 39440, loss = 0.00556771
I0317 15:21:27.869082  3513 solver.cpp:244]     Train net output #0: loss = 0.00556774 (* 1 = 0.00556774 loss)
I0317 15:21:27.869096  3513 sgd_solver.cpp:106] Iteration 39440, lr = 0.01
I0317 15:21:35.190912  3513 solver.cpp:228] Iteration 39460, loss = 0.00567127
I0317 15:21:35.190976  3513 solver.cpp:244]     Train net output #0: loss = 0.0056713 (* 1 = 0.0056713 loss)
I0317 15:21:35.190989  3513 sgd_solver.cpp:106] Iteration 39460, lr = 0.01
I0317 15:21:42.512706  3513 solver.cpp:228] Iteration 39480, loss = 0.0103342
I0317 15:21:42.512773  3513 solver.cpp:244]     Train net output #0: loss = 0.0103343 (* 1 = 0.0103343 loss)
I0317 15:21:42.512786  3513 sgd_solver.cpp:106] Iteration 39480, lr = 0.01
I0317 15:21:49.480581  3513 solver.cpp:337] Iteration 39500, Testing net (#0)
I0317 15:23:43.355136  3513 solver.cpp:404]     Test net output #0: loss = 0.0626385 (* 1 = 0.0626385 loss)
I0317 15:23:43.355294  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.673119 (* 1 = 0.673119 loss)
I0317 15:23:43.692204  3513 solver.cpp:228] Iteration 39500, loss = 0.00441039
I0317 15:23:43.692272  3513 solver.cpp:244]     Train net output #0: loss = 0.00441042 (* 1 = 0.00441042 loss)
I0317 15:23:43.692286  3513 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I0317 15:23:50.925312  3513 solver.cpp:228] Iteration 39520, loss = 0.00553809
I0317 15:23:50.925379  3513 solver.cpp:244]     Train net output #0: loss = 0.00553812 (* 1 = 0.00553812 loss)
I0317 15:23:50.925390  3513 sgd_solver.cpp:106] Iteration 39520, lr = 0.01
I0317 15:23:58.217527  3513 solver.cpp:228] Iteration 39540, loss = 0.0038677
I0317 15:23:58.217597  3513 solver.cpp:244]     Train net output #0: loss = 0.00386773 (* 1 = 0.00386773 loss)
I0317 15:23:58.217608  3513 sgd_solver.cpp:106] Iteration 39540, lr = 0.01
I0317 15:24:05.532477  3513 solver.cpp:228] Iteration 39560, loss = 0.00386043
I0317 15:24:05.532552  3513 solver.cpp:244]     Train net output #0: loss = 0.00386047 (* 1 = 0.00386047 loss)
I0317 15:24:05.532564  3513 sgd_solver.cpp:106] Iteration 39560, lr = 0.01
I0317 15:24:12.856235  3513 solver.cpp:228] Iteration 39580, loss = 0.00287422
I0317 15:24:12.856302  3513 solver.cpp:244]     Train net output #0: loss = 0.00287425 (* 1 = 0.00287425 loss)
I0317 15:24:12.856317  3513 sgd_solver.cpp:106] Iteration 39580, lr = 0.01
I0317 15:24:20.188503  3513 solver.cpp:228] Iteration 39600, loss = 0.00615472
I0317 15:24:20.188661  3513 solver.cpp:244]     Train net output #0: loss = 0.00615475 (* 1 = 0.00615475 loss)
I0317 15:24:20.188676  3513 sgd_solver.cpp:106] Iteration 39600, lr = 0.01
I0317 15:24:27.514194  3513 solver.cpp:228] Iteration 39620, loss = 0.00498856
I0317 15:24:27.514257  3513 solver.cpp:244]     Train net output #0: loss = 0.00498859 (* 1 = 0.00498859 loss)
I0317 15:24:27.514271  3513 sgd_solver.cpp:106] Iteration 39620, lr = 0.01
I0317 15:24:34.831727  3513 solver.cpp:228] Iteration 39640, loss = 0.00294222
I0317 15:24:34.831802  3513 solver.cpp:244]     Train net output #0: loss = 0.00294225 (* 1 = 0.00294225 loss)
I0317 15:24:34.831815  3513 sgd_solver.cpp:106] Iteration 39640, lr = 0.01
I0317 15:24:42.147778  3513 solver.cpp:228] Iteration 39660, loss = 0.00494497
I0317 15:24:42.147841  3513 solver.cpp:244]     Train net output #0: loss = 0.00494501 (* 1 = 0.00494501 loss)
I0317 15:24:42.147855  3513 sgd_solver.cpp:106] Iteration 39660, lr = 0.01
I0317 15:24:49.476366  3513 solver.cpp:228] Iteration 39680, loss = 0.00389579
I0317 15:24:49.476444  3513 solver.cpp:244]     Train net output #0: loss = 0.00389583 (* 1 = 0.00389583 loss)
I0317 15:24:49.476457  3513 sgd_solver.cpp:106] Iteration 39680, lr = 0.01
I0317 15:24:56.816481  3513 solver.cpp:228] Iteration 39700, loss = 0.00321576
I0317 15:24:56.816624  3513 solver.cpp:244]     Train net output #0: loss = 0.00321579 (* 1 = 0.00321579 loss)
I0317 15:24:56.816638  3513 sgd_solver.cpp:106] Iteration 39700, lr = 0.01
I0317 15:25:04.148885  3513 solver.cpp:228] Iteration 39720, loss = 0.00422449
I0317 15:25:04.148952  3513 solver.cpp:244]     Train net output #0: loss = 0.00422452 (* 1 = 0.00422452 loss)
I0317 15:25:04.148964  3513 sgd_solver.cpp:106] Iteration 39720, lr = 0.01
I0317 15:25:11.467614  3513 solver.cpp:228] Iteration 39740, loss = 0.00177858
I0317 15:25:11.467682  3513 solver.cpp:244]     Train net output #0: loss = 0.00177861 (* 1 = 0.00177861 loss)
I0317 15:25:11.467695  3513 sgd_solver.cpp:106] Iteration 39740, lr = 0.01
I0317 15:25:14.763835  3513 solver.cpp:337] Iteration 39750, Testing net (#0)
I0317 15:27:08.626344  3513 solver.cpp:404]     Test net output #0: loss = 0.0618599 (* 1 = 0.0618599 loss)
I0317 15:27:08.626533  3513 solver.cpp:404]     Test net output #1: siamese_accuracy = 0.64432 (* 1 = 0.64432 loss)
I0317 15:27:12.578311  3513 solver.cpp:228] Iteration 39760, loss = 0.00362698
I0317 15:27:12.578373  3513 solver.cpp:244]     Train net output #0: loss = 0.00362701 (* 1 = 0.00362701 loss)
I0317 15:27:12.578387  3513 sgd_solver.cpp:106] Iteration 39760, lr = 0.01
I0317 15:27:19.862048  3513 solver.cpp:228] Iteration 39780, loss = 0.00662758
I0317 15:27:19.862118  3513 solver.cpp:244]     Train net output #0: loss = 0.00662761 (* 1 = 0.00662761 loss)
I0317 15:27:19.862130  3513 sgd_solver.cpp:106] Iteration 39780, lr = 0.01
I0317 15:27:27.177743  3513 solver.cpp:228] Iteration 39800, loss = 0.00544231
I0317 15:27:27.177810  3513 solver.cpp:244]     Train net output #0: loss = 0.00544235 (* 1 = 0.00544235 loss)
I0317 15:27:27.177824  3513 sgd_solver.cpp:106] Iteration 39800, lr = 0.01
I0317 15:27:34.505921  3513 solver.cpp:228] Iteration 39820, loss = 0.00402975
I0317 15:27:34.506000  3513 solver.cpp:244]     Train net output #0: loss = 0.00402978 (* 1 = 0.00402978 loss)
I0317 15:27:34.506014  3513 sgd_solver.cpp:106] Iteration 39820, lr = 0.01
I0317 15:27:41.834022  3513 solver.cpp:228] Iteration 39840, loss = 0.00671199
I0317 15:27:41.834182  3513 solver.cpp:244]     Train net output #0: loss = 0.00671202 (* 1 = 0.00671202 loss)
I0317 15:27:41.834197  3513 sgd_solver.cpp:106] Iteration 39840, lr = 0.01
